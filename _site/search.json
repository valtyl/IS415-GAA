[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "",
    "text": "In this section, I will install and load tidyverse and sf packages.\n\npacman::p_load(tidyverse, sf)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-a-polygon-feature-data-in-shapefile-format",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-a-polygon-feature-data-in-shapefile-format",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.2.1 Importing a polygon feature data in shapefile format",
    "text": "1.2.1 Importing a polygon feature data in shapefile format\nMP14_SUBZONE_WEB_PL is a polygon feature layer in ESRI shapefile format.\n\nmpsz <- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\valtyl\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe message shows:\n\nmpsz simple feature data frame\nthe geospatial objects are multipolygon features\n323 multipolygon features\n15 fields\nmpsz is in svy21 projected coordinates systems\nbounding box provides x extend and y extend of data"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-a-polyline-feature-data-in-shapefile-format",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-a-polyline-feature-data-in-shapefile-format",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.2.2 Importing a polyline feature data in shapefile format",
    "text": "1.2.2 Importing a polyline feature data in shapefile format\nCyclingPath is a line feature layer in ESRI shapefile format.\n\ncyclingpath <- st_read(dsn = \"data/geospatial\", layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\valtyl\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 2248 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42626.09 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThe message shows:\n\ncyclingpath linestring feature data frame\n2248 features\n2 fields\ncyclingpath is in svy21 projected coordinates systems\nbounding box provides x extend and y extend of data"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-gis-data-in-kml-format",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-gis-data-in-kml-format",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.2.3 Importing GIS data in kml format",
    "text": "1.2.3 Importing GIS data in kml format\nPreSchool is a point feature layer in kml file format.\n\npreschool <- st_read(\"data/geospatial/preschools-location.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\valtyl\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\preschools-location.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThe message shows:\n\npreschool point feature data frame\n1925 features\n2 fields\npreschool is in wgs84 projected coordinates systems\nbounding box provides x extend and y extend of data"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-st_geometry",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-st_geometry",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.3.1 Working with st_geometry()",
    "text": "1.3.1 Working with st_geometry()\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nThe message shows:\n\nbasic information (type of geometry, geographic extent of features, coordinate system, etc.)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-glimpse",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-glimpse",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.3.2 Working with glimpse()",
    "text": "1.3.2 Working with glimpse()\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO <int> 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  <chr> \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  <chr> \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     <chr> \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N <chr> \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C <chr> \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   <chr> \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   <chr> \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    <chr> \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D <date> 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     <dbl> 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     <dbl> 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng <dbl> 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area <dbl> 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   <MULTIPOLYGON [m]> MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\nThe message shows:\n\nbasic information\nassociated attribute information (+ data type of each fields e.g. FMEL_UPD_D field is in date data type VS X_ADDR, Y_ADDR, SHAPE_LENG, SHAPE_AREA fields are double-precision values)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-head",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#working-with-head",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.3.3 Working with head()",
    "text": "1.3.3 Working with head()\n\nhead(mpsz, n=5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nThe message shows:\n\ncomplete information\nallows user to select number of records to display (via the n argument)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#assigning-epsg-code-to-a-simple-feature-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.5.1 Assigning EPSG code to a simple feature data frame",
    "text": "1.5.1 Assigning EPSG code to a simple feature data frame\nChecking coordinate system:\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAssigning correct coordinate system:\n\nmpsz3414 <- st_set_crs(mpsz, 3414)\n\nChecking coordinate system after:\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nEPSG code changed from 9001 to 3414."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#transforming-the-projection-of-preschool-from-wgs84-to-svy21",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.5.2 Transforming the projection of preschool from wgs84 to svy21",
    "text": "1.5.2 Transforming the projection of preschool from wgs84 to svy21\n\ntransform original data’s geographic coordinate system TO projected coordinate system\nreason: geographic coordinate system is not appropriate if analysis need to use distance or/and area measurements\n\nTaking a look at preschool’s coordinate system:\n\nst_geometry(preschool)\n\nGeometry set for 1925 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\n\nCANNOT use st_set_crs()\nuse st_transform() instead\nreason: need to reproject preschool from one coordinate system to another coordinate system mathematically\nnote: find out appropriate project coordinate system to use first\n\nProjection Transformation:\n\npreschool3414 <- st_transform(preschool, crs=3414)\n\nLook at preschool’s coordinate system again:\n\nst_geometry(preschool3414)\n\nGeometry set for 1925 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11203.01 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:\n\n\n\nprojected coordinate system: svy21\nbounding box: values are greater than 0-360 range of decimal degree commonly used by most of the geographic coordinate systems"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-aspatial-data",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.6.1 Importing the Aspatial Data",
    "text": "1.6.1 Importing the Aspatial Data\nImporting into R environment and saving it as tibble data frame.\nImporting:\n\nlistings <- read_csv(\"data/aspatial/listings.csv\")\n\nCheck if imported:\n\nlist(listings)\n\n[[1]]\n# A tibble: 4,161 × 18\n       id name     host_id host_…¹ neigh…² neigh…³ latit…⁴ longi…⁵ room_…⁶ price\n    <dbl> <chr>      <dbl> <chr>   <chr>   <chr>     <dbl>   <dbl> <chr>   <dbl>\n 1  50646 Pleasan…  227796 Sujatha Centra… Bukit …    1.33    104. Privat…    80\n 2  71609 Ensuite…  367042 Belinda East R… Tampin…    1.35    104. Privat…   145\n 3  71896 B&B  Ro…  367042 Belinda East R… Tampin…    1.35    104. Privat…    85\n 4  71903 Room 2-…  367042 Belinda East R… Tampin…    1.35    104. Privat…    85\n 5 275344 15 mins… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    49\n 6 289234 Booking…  367042 Belinda East R… Tampin…    1.34    104. Privat…   184\n 7 294281 5 mins … 1521514 Elizab… Centra… Newton     1.31    104. Privat…    79\n 8 324945 Cozy Bl… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    49\n 9 330089 Cozy Bl… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    55\n10 330095 10 mins… 1439258 Kay     Centra… Bukit …    1.29    104. Privat…    55\n# … with 4,151 more rows, 8 more variables: minimum_nights <dbl>,\n#   number_of_reviews <dbl>, last_review <date>, reviews_per_month <dbl>,\n#   calculated_host_listings_count <dbl>, availability_365 <dbl>,\n#   number_of_reviews_ltm <dbl>, license <chr>, and abbreviated variable names\n#   ¹​host_name, ²​neighbourhood_group, ³​neighbourhood, ⁴​latitude, ⁵​longitude,\n#   ⁶​room_type\n\n\nThe message shows:\n\nlisting tibble data frame\n4161 rows, 18 columns\nuseful fields: latitude and longitude (in decimal degree format)\nAssumption: wgs84 Geographic Coordinate System"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#creating-a-simple-feature-data-frame-from-an-aspatial-data-frame",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.6.2 Creating a simple feature data frame from an aspatial data frame",
    "text": "1.6.2 Creating a simple feature data frame from an aspatial data frame\nConverting listing data frame into a simple feature data frame (using st_as_sf() of sf packages):\n\nlistings_sf <- st_as_sf(listings, coords = c(\"longitude\", \"latitude\"), crs=4326) %>% st_transform(crs = 3414)\n\nImportant:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%>% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nLook at the newly created simple feature data frame:\n\nglimpse(listings_sf)\n\nRows: 4,161\nColumns: 17\n$ id                             <dbl> 50646, 71609, 71896, 71903, 275344, 289…\n$ name                           <chr> \"Pleasant Room along Bukit Timah\", \"Ens…\n$ host_id                        <dbl> 227796, 367042, 367042, 367042, 1439258…\n$ host_name                      <chr> \"Sujatha\", \"Belinda\", \"Belinda\", \"Belin…\n$ neighbourhood_group            <chr> \"Central Region\", \"East Region\", \"East …\n$ neighbourhood                  <chr> \"Bukit Timah\", \"Tampines\", \"Tampines\", …\n$ room_type                      <chr> \"Private room\", \"Private room\", \"Privat…\n$ price                          <dbl> 80, 145, 85, 85, 49, 184, 79, 49, 55, 5…\n$ minimum_nights                 <dbl> 92, 92, 92, 92, 60, 92, 92, 60, 60, 60,…\n$ number_of_reviews              <dbl> 18, 20, 24, 47, 14, 12, 133, 17, 12, 3,…\n$ last_review                    <date> 2014-12-26, 2020-01-17, 2019-10-13, 20…\n$ reviews_per_month              <dbl> 0.18, 0.15, 0.18, 0.34, 0.11, 0.10, 1.0…\n$ calculated_host_listings_count <dbl> 1, 6, 6, 6, 44, 6, 7, 44, 44, 44, 6, 7,…\n$ availability_365               <dbl> 365, 340, 265, 365, 296, 285, 365, 181,…\n$ number_of_reviews_ltm          <dbl> 0, 0, 0, 0, 1, 0, 0, 3, 2, 0, 1, 0, 0, …\n$ license                        <chr> NA, NA, NA, NA, \"S0399\", NA, NA, \"S0399…\n$ geometry                       <POINT [m]> POINT (22646.02 35167.9), POINT (…\n\n\n\nnew column geometry added into data frame\nlongitude and latitude columns dropped from data frame"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#buffering",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.7.1 Buffering",
    "text": "1.7.1 Buffering\nScenario:\n\nAuthority plans to upgrade existing cycling path\nNeeds to acquire 5 metres of reserved land on both sides of current cycling path\nTask: Determine the extent of land needed to be acquired and their total area\n\nSolution:\nStep 1 - compute 5 metres buffers around cycling path\n\nbuffer_cycling <- st_buffer(cyclingpath, dist=5, nQuadSegs=30)\n\nStep 2 - calculate area of buffers\n\nbuffer_cycling$AREA <- st_area(buffer_cycling)\n\nStep 3 - derive total land involved\n\nsum(buffer_cycling$AREA)\n\n1556978 [m^2]"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#point-in-polygon-count",
    "title": "Hands-on Exercise 1: Geospatial Data Wrangling with R",
    "section": "1.7.2 Point-in-polygon count",
    "text": "1.7.2 Point-in-polygon count\nScenario:\n\nA pre-school service group wants to find out the number of pre-schools in each Planning Subzone.\n\nSolution:\nStep 1 - Identify pre-schools located inside each Planning Subzone using st_intersects() and use length() of Base R to calculate the number of pre-schools that fall inside each Planning Subzone\n\nmpsz3414$`PreSch Count` <- lengths(st_intersects(mpsz3414, preschool3414))\n\n\nst_intersects() and st_intersection() ARE DIFF\n\nStep 2 - Check summary statistics of newly derived PreSch Count field\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    3.00    5.96    9.00   58.00 \n\n\nStep 3 - List the Planning Subzone with the most number of pre-schools\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           58\n\n\nExtra - Calculate the density of pre-school by Planning Subzone\nSolution:\nStep 1 - Derive area of each Planning Subzone\n\nmpsz3414$Area <- mpsz3414 %>% st_area()\n\nStep 2 - Compute the density\n\nmpsz3414 <- mpsz3414 %>% mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "",
    "text": "Packages needed:\n\ntmap\nreadr for importing delimited text file\ntidyr for tidying data\ndplyr for wrangling data\nsf for handling geospatial data\n\n\n\nInstalling and loading the packages:\n\npacman::p_load(tmap, tidyverse, sf)\n\n\nreadr, tidyr, dplyr are part of tidyverse"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-geospatial-data",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.2.1 Importing Geospatial Data",
    "text": "2.2.1 Importing Geospatial Data\n\nmpsz <- st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\valtyl\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nContent of mpsz:\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29..."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-attribute-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#importing-attribute-data",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.2.2 Importing Attribute Data",
    "text": "2.2.2 Importing Attribute Data\n\npopdata <- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-preparation",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.2.3 Data Preparation",
    "text": "2.2.3 Data Preparation\nWe need to prepare a data table with year 2020 values before we can prepare a thematic map.\nData Table to include the following variables: PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age group 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\n2.2.3.1 Data wrangling\nData wrangling and transformation functions used:\n\npivot_wider() of tidyr package\nmutate(), filter(), group_by(), select() of dplyr package\n\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%>%\nmutate(`AGED`=rowSums(.[16:21])) %>%\nmutate(`TOTAL`=rowSums(.[3:21])) %>%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n2.2.3.2 Joining the attribute data and geospatial data\n\nPA and SZ fields: upper and lower case\nSUBZONE_N and PLN_AREA_N: uppercase\nneed to convert PA and SZ to uppercase\n\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\n\nuse left_join() of dplyr to join geographical data and attribute table\nuse planning subzone name as common identifier (SUBZONE_N and SZ)\nleft_join() of dplyr is used with mpsz simple feature data as the left data table is to ensure that the output will be a simple feature data frame\n\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-a-choropleth-map-quickly-using-qtm",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#plotting-a-choropleth-map-quickly-using-qtm",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.3.1 Plotting a choropleth map quickly using qtm()",
    "text": "2.3.1 Plotting a choropleth map quickly using qtm()\nqtm() is:\n\nconcise\nprovides good default visualisation\neasiest and quickest way to draw a choropleth map\n\ndisadvantage of qtm(): makes aesthetics of individual layers harder to control\nDrawing a cartographic standard choropleth map:\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\nTo learn from code above:\n\ntmap_mode() with “plot” option is used to produce a static map\nuse “view” option for interactive mode\nfill argument is used to map the attribute (i.e. DEPENDENCY)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-choropleth-map-using-tmaps-elements",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#creating-a-choropleth-map-using-tmaps-elements",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.3.2 Creating a choropleth map using tmap’s elements",
    "text": "2.3.2 Creating a choropleth map using tmap’s elements\nuse tmap’s drawing elements to draw high quality cartographic choropleth map:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n2.3.2.1 Drawing a base map\n\ntmap function used: tm_shape()\ntm_shape() is the basic building block\nfollowed by 1 or more layer elements: tm_fill(), tm_polygons()\n\nDefining input data (mpsz_pop2020) using tm_shape() and using tm_polygons() to draw planning subzone polygons:\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n2.3.2.2 Drawing a choropleth map using tm_polygons()\nTo draw a choropleth map showing the geographical distribution of a selected variable by planning subzone:\nAssign target variable (eg Dependency) to tm_polygons()\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\nTo learn about tm_polygons():\n\n“pretty” is the default interval binning to draw choropleth maps\nYlOrRd of ColorBrewer is the default colour scheme\nmissing values will be shaded in grey by default\n\n\n\n2.3.2.3 Drawing a choropleth map using tm_fill() and tm_border()\n\ntm_polygons() is a wrapper of tm_fill() and tm_border()\ntm_fill() shades polygons using default colour scheme\ntm_borders() adds borders of shapefile onto the choropleth map\n\nDrawing choropleth using tm_fill() only:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\nAdding boundary of planning subzones using tm_borders():\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\nthe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent)\nby default, alpha value of the col is used (normally 1)\n\nArguments for tm_borders():\n\ncol = border colour\nlwd = border line width (default = 1)\nlty = border line type (default = ‘solid’)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#data-classification-methods-of-tmap",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.3.3 Data classification methods of tmap",
    "text": "2.3.3 Data classification methods of tmap\nMost choropleth maps employ some methods of data classification.\nThe point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n2.3.3.1 Plotting choropleth maps with built-in classification methods\nQuantile data classification using 5 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nUsing equal data classification method:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote: the distribution of quantile data classification method is more evenly distributed than equal data classification method\n\n\n\n\n[DIY] Preparing choropleth maps using other tmap classification methods:\nUsing fisher:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nUsing sd:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nUsing kmeans:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nUsing hclust:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nUsing bclust:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"bclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nCommittee Member: 1(1) 2(1) 3(1) 4(1) 5(1) 6(1) 7(1) 8(1) 9(1) 10(1)\nComputing Hierarchical Clustering\n\n\nUsing quantile:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nTheir differences:\n\n\n[DIY] Preparing choropleth maps with similar classification (jenks) but different numbers of classes\nUsing 2 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nUsing 6 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nUsing 10 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nUsing 20 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n2.3.3.2 Plotting choropleth map with custom break\n\nFor all the built-in styles, the category breaks are computed internally.\nIn order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill().\nIt is important to note that, in tmap the breaks include a minimum and maximum.\nAs a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\n\nGetting descriptive statistics on the variable before setting the break points:\nComputing and Displaying statistics of DEPENDENCY field:\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\nWith reference to the results above:\n\nset break point at 0.60, 0.70, 0.80, and 0.90\ninclude a minimum and maximum, which we set at 0 and 100\nbreaks vector is c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\n\nPlotting choropleth map:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#colour-scheme",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#colour-scheme",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.3.4 Colour Scheme",
    "text": "2.3.4 Colour Scheme\ntmap supports colour ramps:\n\ndefined by user\npredefined set of colour ramps from RColorBrewer package\n\n\n2.3.4.1 Using ColourBrewer palette\nuse palette argument in tm_fill()\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nTo reverse colour shading, add a “-” prefix:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-layouts",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#map-layouts",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.3.5 Map Layouts",
    "text": "2.3.5 Map Layouts\n\nMap layout refers to the combination of all map elements into a cohensive map.\nMap elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios.\nColour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\n\n2.3.5.1 Map Legend\nuse legend options to change placement, format and appearance of the legend\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n2.3.5.2 Map Style using tmap_style()\nto change a wide variety of layout settings\nUsing classic style:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n2.3.5.3 Cartographic Furniture\nwe can draw other map furniture:\n\ncompass using tm_compass()\nscale bar using tm_scale_bar()\ngrid lines using tm_grid()\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\nTo reset default style:\n\ntmap_style(\"white\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#drawing-small-multiple-choropleth-maps",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#drawing-small-multiple-choropleth-maps",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.3.6 Drawing Small Multiple Choropleth Maps",
    "text": "2.3.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\nby assigning multiple values to at least one of the asthetic arguments, by defining a group-by variable in tm_facets(), and by creating multiple stand-alone maps with tmap_arrange().\n\n2.3.6.1 By assigning multiple values to at least one of the aesthetic arguments\nCreating small multiple choropleth maps by defining ncols in tm_fill():\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n2.3.6.2 By defining a group-by variable in tm_facets()\nCreating small multiple choropleth maps using tm_facets():\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n2.3.6.3 By creating multiple stand-alone maps with tmap_arrange()\nCreating small multiple choropleth maps by creating multiple stand-alone maps using tmap_arrange():\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#mapping-spatial-object-meeting-a-selection-criterion",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#mapping-spatial-object-meeting-a-selection-criterion",
    "title": "Hands-on Exercise 2: Choropleth Mapping with R",
    "section": "2.3.7 Mapping Spatial Object Meeting a Selection Criterion",
    "text": "2.3.7 Mapping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth map, you can also use selection function to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\n\nevents such as crime, traffic accident and disease onset, or\nbusiness services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\n\nUsing appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-the-spatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-the-spatial-data",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.4.1 Importing the spatial data",
    "text": "4.4.1 Importing the spatial data\n\nchildcare_sf <- st_read(\"data/child-care-services-geojson.geojson\") %>%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\valtyl\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex04\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf <- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\valtyl\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex04\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf <- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\valtyl\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex04\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n[DIY] Retrieve the referencing system information of these geospatial data\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\n\n[DIY] Assign the correct CRS to mpsz_sf and sg_sf simple feature data frames\n\nsg_sf_3414 <- st_transform(sg_sf, crs=3414)\nst_crs(sg_sf_3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nmpsz_sf_3414 <- st_transform(mpsz_sf, crs=3414)\nst_crs(mpsz_sf_3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n[DIY] If necessary, change the referencing system to Singapore national projected coordinate system"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#mapping-the-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#mapping-the-geospatial-data-sets",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.4.2 Mapping the geospatial data sets",
    "text": "4.4.2 Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\n\ntmap_mode(\"plot\")\nqtm(childcare_sf)\n\n\n\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, we can also prepare a pin map by using the code chunk below.\n\nsf_use_s2(FALSE)\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots(alpha = 0.5, size=0.01)+\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\ntmap_mode('plot')\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\nReminder: Always remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. You should also avoid displaying ecessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publish on Netlify.\n\n\nalpha controls the intensity of the colour, if the value is closer to 1, the colour will be darker. if the value is closer to 0, the colour will be brighter\ntm_dots(): usually used if we don’t assign any value to the dots\ntm_bubbles(): usually used if we want to create proportional bubbles\nset.zoom.limits in tm_view(): to prevent too far zooming in and out\nset.bounds in tm_view(): set boundaries of the map to prevent it from ‘running away’"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#converting-sf-data-frames-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#converting-sf-data-frames-to-sps-spatial-class",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.5.1 Converting sf data frames to sp’s Spatial* class",
    "text": "4.5.1 Converting sf data frames to sp’s Spatial* class\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>018989</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>08F73931F4A691F4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \nmax values  : kml_999,                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>829646</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>RAFFLES KIDZ @ PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>379D017BF244B0FA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.5.2 Converting the Spatial* class into generic sp format",
    "text": "4.5.2 Converting the Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\nThe codes chunk below converts the Spatial* classes into generic sp objects.\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\nNext, you should display the sp objects properties as shown below.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.5.3 Converting the generic sp format into spatstat’s ppp format",
    "text": "4.5.3 Converting the generic sp format into spatstat’s ppp format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let us plot childcare_ppp and examine the different.\n\nplot(childcare_ppp)\n\n\n\n\nYou can take a quick look at the summary statistics of the newly created ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#handling-duplicated-points",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.5.4 Handling duplicated points",
    "text": "4.5.4 Handling duplicated points\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\n\nusually SG don’t use GPS for points so there are duplicate points. SG uses postal codes and the postal codes are geocoded. SG uses the online geocoding function to retrieve the xy coordinates.\n\nTo count the number of co-indicence point, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) > 1)\n\n[1] 128\n\n\nThe output shows that there are 128 duplicated point events.\nTo view the locations of these duplicate point events, we will plot childcare data by using the code chunk below.\n\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots(alpha=0.4,\n          size=0.05)\n\n\n\n\n\n\n\ntmap_mode('plot')\n\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit <- rjitter(childcare_ppp,\n                             retry=TRUE,\n                             nsim=1,\n                             drop=TRUE)\n\n\njittering means that you differentiate the duplicate points with a bit of distance to make them different\n\nCheck if any duplicated point is in this geospatial data\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#creating-owin-object",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.5.5 Creating owin object",
    "text": "4.5.5 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin <- as(sg_sp, \"owin\")\n\nThe ouput object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\nand summary() function of Base R\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#combining-point-events-object-and-owin-object",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.5.6 Combining point events object and owin object",
    "text": "4.5.6 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nowin layer helps to confine the boundary to use only those points in the owin map\n\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.063463e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414\n\n\n\n[DIY] Plot the newly derived childcareSG_ppp\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#kernel-density-estimation",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#kernel-density-estimation",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.6.1 Kernel Density Estimation",
    "text": "4.6.1 Kernel Density Estimation\nIn this section, you will learn how to compute the kernel density estimation (KDE) of childcare services in Singapore.\n\n4.6.1.1 Computing kernel density estimation using automatic bandwidth selection method\nThe code chunk below computes a kernel density by using the following configurations of density() of spatstat:\n\nbw.diggle() automatic bandwidth selection method. Other recommended methods are bw.CvL(), bw.scott() or bw.ppl().\n\nThe smoothing kernel used is gaussian, which is the default. Other smoothing methods are: “epanechnikov”, “quartic” or “disc”.\n\nThe intensity estimate is corrected for edge effect bias by using method described by Jones (1993) and Diggle (2010, equation 18.9). The default is FALSE.\n\n\nkde_childcareSG_bw <- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\")\n\nThe plot() function of Base R is then used to display the kernel density derived.\n\nplot(kde_childcareSG_bw)\n\n\n\n\nThe density values of the output range from 0 to 0.000035 which is way too small to comprehend. This is because the default unit of measurement of svy21 is in meter. As a result, the density values computed is in “number of points per square meter”.\nBefore we move on to next section, it is good to know that you can retrieve the bandwidth used to compute the kde layer by using the code chunk below.\n\nbw <- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n4.6.1.2 Rescalling KDE values\nIn the code chunk below, rescale() is used to covert the unit of measurement from meter to kilometer.\n\nSVY21 uses meter which makes the map units too small to see so we want to convert to km\nwrite on the map: unit per meter square CHANGED TO unit per kilometer square\n\n\nchildcareSG_ppp.km <- rescale(childcareSG_ppp, 1000, \"km\")\n\nNow, we can re-run density() using the resale data set and plot the output kde map.\n\nkde_childcareSG.bw <- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)\n\n\n\n\nNotice that output image looks identical to the earlier version, the only changes in the data values (refer to the legend)."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#working-with-different-automatic-badwidth-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#working-with-different-automatic-badwidth-methods",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.6.2 Working with different automatic badwidth methods",
    "text": "4.6.2 Working with different automatic badwidth methods\nBeside bw.diggle(), there are three other spatstat functions can be used to determine the bandwidth, they are: bw.CvL(), bw.scott(), and bw.ppl().\nLet us take a look at the bandwidth return by these automatic bandwidth calculation methods by using the code chunk below.\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because in ther experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters. But they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\nThe code chunk beow will be used to compare the output of using bw.diggle and bw.ppl methods.\n\nppl method appears to be smoother since the sigma is greater by 100m compared to the diggle method which seems more pixelised\nif you choose a method like diggle, choose the same method again. eg. use diggle for comparing both functional water points and non-functional water points\nlocation - well distributed, no difference in distribution patterns >> use fixed distance\nlocation - many residential areas, all the childcare centres will be cluttered >> use adaptive cause the kernel changes\n\n\nkde_childcareSG.ppl <- density(childcareSG_ppp.km,\n                               sigma=bw.ppl,\n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#working-with-different-kernel-methods",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#working-with-different-kernel-methods",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.6.3 Working with different kernel methods",
    "text": "4.6.3 Working with different kernel methods\nBy default, the kernel method used in density.ppp() is gaussian. But there are three other options, namely: Epanechnikov, Quartic and Dics.\nThe code chunk below will be used to compute three more kernel density estimations by using these three kernel function.\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"epanechnikov\"),\n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"quartic\"),\n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km,\n             sigma=bw.ppl,\n             edge=TRUE,\n             kernel=\"disc\"),\n     main=\"Disc\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-kde-by-using-fixed-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-kde-by-using-fixed-bandwidth",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.7.1 Computing KDE by using fixed bandwidth",
    "text": "4.7.1 Computing KDE by using fixed bandwidth\nNext, you will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\n\nkde_childcareSG_600 <- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-kde-by-using-adaptive-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-kde-by-using-adaptive-bandwidth",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.7.2 Computing KDE by using adaptive bandwidth",
    "text": "4.7.2 Computing KDE by using adaptive bandwidth\nFixed bandwidth method is very sensitive to highly skew distribution of spatial point patterns over geographical units for example urban versus rural. One way to overcome this problem is by using adaptive bandwidth instead.\nIn this section, you will learn how to derive adaptive kernel density estimation by using density.adaptive() of spatstat.\n\ndensity.adaptive() has attributes densityVoronoi (tends to be more pixelised) and densityAdaptiveKernel (tends to be smoother)\n\n\nkde_childcareSG_adaptive <- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\nWe can compare the fixed and adaptive kernel density estimation outputs by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#converting-kde-output-into-grid-object",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#converting-kde-output-into-grid-object",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.7.3 Converting KDE output into grid object",
    "text": "4.7.3 Converting KDE output into grid object\nThe result is the same, we just convert it so that it is suitable for mapping purposes\n\nwe need to convert to grid object (squarish pixels) because previously the output was an image that does not have coordinates\n\n\ngridded_kde_childcareSG_bw <- as.SpatialGridDataFrame.im(kde_childcareSG.bw)\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n4.7.3.1 Converting gridded output into raster\nNext, we will convert the gridded kernal density objects into RasterLayer object by using raster() of raster package.\n\nraster is specially designed to deal with grid outputs\n\n\nkde_childcareSG_bw_raster <- raster(gridded_kde_childcareSG_bw)\n\nLet us take a look at the properties of kde_childcareSG_bw_raster RasterLayer.\n\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNotice that the crs property is NA.\n\n\n4.7.3.2 Assigning projection systems\nThe code chunk below will be used to include the CRS information on kde_childcareSG_bw_raster RasterLayer.\n\nprojection(kde_childcareSG_bw_raster) <- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +init=EPSG:3414 \nsource     : memory\nnames      : v \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\nNotice that the crs property is completed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-the-output-in-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#visualising-the-output-in-tmap",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.7.4 Visualising the output in tmap",
    "text": "4.7.4 Visualising the output in tmap\nFinally, we will display the raster in cartographic quality map using tmap package.\n\ntm_shape(kde_childcareSG_bw_raster) +\n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#comparing-spatial-point-patterns-using-kde",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#comparing-spatial-point-patterns-using-kde",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.7.5 Comparing Spatial Point Patterns using KDE",
    "text": "4.7.5 Comparing Spatial Point Patterns using KDE\nIn this section, you will learn how to compare KDE of childcare at Punggol, Tampines, Chua Chu Kang and Jurong West planning areas.\n\n4.7.5.1 Extracting study area\nThe code chunk below will be used to extract the target planning areas.\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\nPlotting target planning areas\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Punggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n4.7.5.2 Converting the spatial point data frame into generic sp format\nNext, we will convert these SpatialPolygonsDataFrame layers into generic spatialpolygons layers.\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n\n4.7.5.3 Creating owin object\nNow, we will convert these SpatialPolygons objects into owin objects that is required by spatstat.\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n\n\n4.7.5.4 Combining childcare points and the study area\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale() function is used to transform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n4.7.5.5 Computing KDE\nThe code chunk below will be used to compute the KDE of these four planning area. bw.diggle method is used to derive the bandwidth of each\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km,\n             sigma=bw.diggle,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km,\n             sigma=bw.diggle,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km,\n             sigma=bw.diggle,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km,\n             sigma=bw.diggle,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\n\n\n\n\n\n\n4.7.5.6 Computing fixed bandwidth KDE\nFor comparison purposes, we will use 250m as the bandwidth.\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km,\n             sigma=0.25,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km,\n             sigma=0.25,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km,\n             sigma=0.25,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km,\n             sigma=0.25,\n             edge=TRUE,\n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#testing-spatial-point-patterns-using-clark-and-evans-test",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.8.1 Testing spatial point patterns using Clark and Evans Test",
    "text": "4.8.1 Testing spatial point patterns using Clark and Evans Test\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 99 simulations of CSR with fixed n\n\ndata:  childcareSG_ppp\nR = 0.54756, p-value = 0.01\nalternative hypothesis: clustered (R < 1)\n\n\nWhat conclusion can you draw from the test result?\n\nSince p-value = 0.01 < 0.05, we reject the null hypothesis that the spatial point patterns are randomly distributed\nSince R = 0.54756 < 1 (looking at Nearest Neighbour Index), the patterns exhibits clustering"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#clark-and-evans-test-choa-chu-kang-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#clark-and-evans-test-choa-chu-kang-planning-area",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.8.2 Clark and Evans Test: Choa Chu Kang planning area",
    "text": "4.8.2 Clark and Evans Test: Choa Chu Kang planning area\nIn the code chunk below, clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Choa Chu Kang planning area.\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_ck_ppp\nR = 0.91897, p-value = 0.06\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#clark-and-evans-test-tampines-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#clark-and-evans-test-tampines-planning-area",
    "title": "Hands-on Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "4.8.3 Clark and Evans Test: Tampines planning area",
    "text": "4.8.3 Clark and Evans Test: Tampines planning area\nIn the code chunk below, the similar test is used to analyse the spatial point patterns of childcare centre in Tampines planning area.\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Monte Carlo test based on 999 simulations of CSR with fixed n\n\ndata:  childcare_tm_ppp\nR = 0.79776, p-value = 0.002\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\n\nevents such as crime, traffic accident and disease onset, or\nbusiness services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\n\nUsing appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-the-spatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#importing-the-spatial-data",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.4.1 Importing the spatial data",
    "text": "5.4.1 Importing the spatial data\n\nchildcare_sf <- st_read(\"data/child-care-services-geojson.geojson\") %>%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\valtyl\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf <- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\valtyl\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf <- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\valtyl\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex05\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n[DIY] Retrieve the referencing system information of these geospatial data\n\nst_crs(childcare_sf)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nst_crs(sg_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\nst_crs(mpsz_sf)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\n\n\n[DIY] Assign the correct CRS to mpsz_sf and sg_sf simple feature data frames\n\nsg_sf_3414 <- st_transform(sg_sf, crs=3414)\nst_crs(sg_sf_3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\nmpsz_sf_3414 <- st_transform(mpsz_sf, crs=3414)\nst_crs(mpsz_sf_3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\n\n\n[DIY] If necessary, change the referencing system to Singapore national projected coordinate system"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#mapping-the-geospatial-data-sets",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#mapping-the-geospatial-data-sets",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.4.2 Mapping the geospatial data sets",
    "text": "5.4.2 Mapping the geospatial data sets\nAfter checking the referencing system of each geospatial data data frame, it is also useful for us to plot a map to show their spatial patterns.\n\ntmap_mode(\"plot\")\nqtm(childcare_sf)\n\n\n\n\nNotice that all the geospatial layers are within the same map extend. This shows that their referencing system and coordinate values are referred to similar spatial context. This is very important in any geospatial analysis.\nAlternatively, we can also prepare a pin map by using the code chunk below.\n\nsf_use_s2(FALSE)\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\n\ntmap_mode('plot')\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas.\n\nReminder: Always remember to switch back to plot mode after the interactive map. This is because, each interactive mode will consume a connection. You should also avoid displaying ecessive numbers of interactive maps (i.e. not more than 10) in one RMarkdown document when publish on Netlify."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#converting-sf-data-frames-to-sps-spatial-class",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#converting-sf-data-frames-to-sps-spatial-class",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.5.1 Converting sf data frames to sp’s Spatial* class",
    "text": "5.5.1 Converting sf data frames to sp’s Spatial* class\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>018989</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>08F73931F4A691F4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \nmax values  : kml_999,                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>829646</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>RAFFLES KIDZ @ PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>379D017BF244B0FA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.5.2 Converting the Spatial* class into generic sp format",
    "text": "5.5.2 Converting the Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\nThe codes chunk below converts the Spatial* classes into generic sp objects.\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\nNext, you should display the sp objects properties as shown below.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.5.3 Converting the generic sp format into spatstat’s ppp format",
    "text": "5.5.3 Converting the generic sp format into spatstat’s ppp format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let us plot childcare_ppp and examine the different.\n\nplot(childcare_ppp)\n\n\n\n\nYou can take a quick look at the summary statistics of the newly created ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#handling-duplicated-points",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#handling-duplicated-points",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.5.4 Handling duplicated points",
    "text": "5.5.4 Handling duplicated points\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of co-indicence point, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) > 1)\n\n[1] 128\n\n\nThe output shows that there are 128 duplicated point events.\nTo view the locations of these duplicate point events, we will plot childcare data by using the code chunk below.\n\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots(alpha=0.4,\n          size=0.05)\n\n\n\n\n\n\n\ntmap_mode('plot')\n\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit <- rjitter(childcare_ppp,\n                             retry=TRUE,\n                             nsim=1,\n                             drop=TRUE)\n\nCheck if any duplicated point is in this geospatial data\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#creating-owin-object",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.5.5 Creating owin object",
    "text": "5.5.5 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin <- as(sg_sp, \"owin\")\n\nThe ouput object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\nand summary() function of Base R\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#combining-point-events-object-and-owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#combining-point-events-object-and-owin-object",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.5.6 Combining point events object and owin object",
    "text": "5.5.6 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.063463e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414\n\n\n\n[DIY] Plot the newly derived childcareSG_ppp\n\n\n5.5.6.1 Extracting study area\nThe code chunk below will be used to extract the target planning areas.\n\npg = mpsz[mpsz@data$PLN_AREA_N == \"PUNGGOL\",]\ntm = mpsz[mpsz@data$PLN_AREA_N == \"TAMPINES\",]\nck = mpsz[mpsz@data$PLN_AREA_N == \"CHOA CHU KANG\",]\njw = mpsz[mpsz@data$PLN_AREA_N == \"JURONG WEST\",]\n\nPlotting target planning areas\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\nplot(tm, main = \"Tampines\")\nplot(ck, main = \"Choa Chu Kang\")\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n5.5.6.2 Converting the spatial point data frame into generic sp format\nNext, we will convert these SpatialPolygonsDataFrame layers into generic spatialpolygons layers.\n\npg_sp = as(pg, \"SpatialPolygons\")\ntm_sp = as(tm, \"SpatialPolygons\")\nck_sp = as(ck, \"SpatialPolygons\")\njw_sp = as(jw, \"SpatialPolygons\")\n\n\n\n5.5.6.3 Creating owin object\nNow, we will convert these SpatialPolygons objects into owin objects that is required by spatstat.\n\npg_owin = as(pg_sp, \"owin\")\ntm_owin = as(tm_sp, \"owin\")\nck_owin = as(ck_sp, \"owin\")\njw_owin = as(jw_sp, \"owin\")\n\n\n\n5.5.6.4 Combining childcare points and the study area\nBy using the code chunk below, we are able to extract childcare that is within the specific region to do our analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nNext, rescale() function is used to trasnform the unit of measurement from metre to kilometre.\n\nchildcare_pg_ppp.km = rescale(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale(childcare_jw_ppp, 1000, \"km\")\n\nThe code chunk below is used to plot these four study areas and the locations of the childcare centres.\n\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#choa-chu-kang-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#choa-chu-kang-planning-area",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.7.1 Choa Chu Kang planning area",
    "text": "5.7.1 Choa Chu Kang planning area\n\n5.7.1.1 Computing G-function estimation\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n5.7.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-function\n\nG_CK.csr <- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(G_CK.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#tampines-planning-area",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#tampines-planning-area",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.7.2 Tampines planning area",
    "text": "5.7.2 Tampines planning area\n\n5.7.2.1 Computing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n5.7.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nG_tm.csr <- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#choa-chu-kang-planning-area-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#choa-chu-kang-planning-area-1",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.8.1 Choa Chu Kang planning area",
    "text": "5.8.1 Choa Chu Kang planning area\n\n5.8.1.1 Computing F-function estimation\nThe code chunk below is used to compute F-function using Fest() of spatat package.\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#performing-complete-spatial-randomness-test-2",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#performing-complete-spatial-randomness-test-2",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.8.2 Performing Complete Spatial Randomness Test",
    "text": "5.8.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-function\n\nF_CK.csr <- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(F_CK.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#tampines-planning-area-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#tampines-planning-area-1",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.8.3 Tampines planning area",
    "text": "5.8.3 Tampines planning area\n\n5.8.3.1 Computing F-function estimation\nMonte Carlo test with F-function\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n5.8.3.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nF_tm.csr <- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60........\n.70.........80.........90.........100.........110.........120.........130......\n...140.........150.........160.........170.........180.........190.........200....\n.....210.........220.........230.........240.........250.........260.........270..\n.......280.........290.........300.........310.........320.........330.........340\n.........350.........360.........370.........380.........390.........400........\n.410.........420.........430.........440.........450.........460.........470......\n...480.........490.........500.........510.........520.........530.........540....\n.....550.........560.........570.........580.........590.........600.........610..\n.......620.........630.........640.........650.........660.........670.........680\n.........690.........700.........710.........720.........730.........740........\n.750.........760.........770.........780.........790.........800.........810......\n...820.........830.........840.........850.........860.........870.........880....\n.....890.........900.........910.........920.........930.........940.........950..\n.......960.........970.........980.........990........ 999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#choa-chu-kang-planning-area-2",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#choa-chu-kang-planning-area-2",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.9.1 Choa Chu Kang planning area",
    "text": "5.9.1 Choa Chu Kang planning area\n\n5.9.1.1 Computing K-function estimate\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n5.9.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_ck.csr <- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#tampines-planning-area-2",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#tampines-planning-area-2",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.9.2 Tampines planning area",
    "text": "5.9.2 Tampines planning area\n\n5.9.2.1 Computing K-function estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n5.9.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_tm.csr <- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#choa-chu-kang-planning-area-3",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#choa-chu-kang-planning-area-3",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.10.1 Choa Chu Kang planning area",
    "text": "5.10.1 Choa Chu Kang planning area\n\n5.10.1.1 Computing L Function estimation\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\nedge correction via the correction attribute is Lest() is to take care of the modified edge defect\nin the algorithm, the boundary is extended slightly, so that we can include the points at the edge\nanything above red line is clustering\nanything below red line is regular pattern\nbut we don’t know if the clustering or regular pattern is statistically confident\nto draw the conclusion, we need the envelope to run simulations\n\n\n\n5.10.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value if smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_ck.csr <- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\naltho the envelope looks like a grey area, it is actualy made up of lines\nthe envelope is made up of 100 grey lines since 99 simulations are run\nto use 95% confidence interval, need to run 49 simulations\nfor 99% confidence interval, run 99 simulations\nfor 99.9% confidence interval, run 999 simulations\nconclusion: don’t have enough statistical evidence to reject null, fail to reject the null hypothesis at 99% confidence interval bc they are not all outside the envelope\nanything that fall inside envelope, cannot reject null, outside then have enough stats evidence to reject the null\nConclusion: null hypothesis says that the childcare centres are randomly distributed > but from the graph, there is a portion where the black line is in the white area > this means that at a certain distance, the childcare centres are clustered > if the whole black line is OUTSIDE the envelope, it will mean that the childcare centres are clustered. if the whole black lines is INSIDE the envelope, it will mean that the childcare centres are randomly distributed. > unless the whole black line is outside, we cannot reject the null hypothesis (cannot say that it is not randomly distributed). only if the whole black line is outside, we can say it is clustered and we can accept H1 that it is not random, then reject H0\nat about 480km between childcare centres, the childcare centres show since of clustering (white area)\nblack line is alpha value, black lines protrude means p-value is smaller than alpha value"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#tampines-planning-area-3",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#tampines-planning-area-3",
    "title": "Hands-on Exercise 5: 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "5.10.2 Tampines planning area",
    "text": "5.10.2 Tampines planning area\n\n5.10.2.1 Computing L-function estimate\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n5.10.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below will be used to perform the hypothesis testing.\n\nL_tm.csr <- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98,  99.\n\nDone.\n\n\nThen, plot the model output by using the code chunk below.\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "",
    "text": "Water is an important resource to mankind. Clean and accessible water is critical to human health. It provides a healthy environment, a sustainable economy, reduces poverty and ensures peace and security. Yet over 40% of the global population does not have access to sufficient clean water. By 2025, 1.8 billion people will be living in countries or regions with absolute water scarcity, according to UN-Water. The lack of water poses a major threat to several sectors, including food security. Agriculture uses about 70% of the world’s accessible freshwater.\nDeveloping countries are most affected by water shortages and poor water quality. Up to 80% of illnesses in the developing world are linked to inadequate water and sanitation. Despite technological advancement, providing clean water to the rural community is still a major development issues in many countries globally, especially countries in the Africa continent.\nTo address the issue of providing clean and sustainable water supply to the rural community, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas at the water point or small water scheme level and share the data via WPdx Data Repository, a cloud-based data library. What is so special of this project is that data are collected based on WPDx Data Standard.\n\n\n\nGeospatial analytics hold tremendous potential to address complex problems facing society. In this study, you are tasked to apply appropriate geospatial data wrangling methods to prepare the data for water point mapping study. For the purpose of this study, Nigeria will be used as the study country.\n\n\n\n\n\nFor the purpose of this assignment, data from WPdx Global Data Repositories will be used. There are two versions of the data. They are: WPdx-Basic and WPdx+. You are required to use WPdx+ data set.\n\n\n\nNigeria Level-2 Administrative Boundary (also known as Local Government Area) polygon features GIS data will be used in this take-home exercise. The data can be downloaded either from The Humanitarian Data Exchange portal or geoBoundaries.\n\n\n\n\nThe specific tasks of this take-home exercise are as follows:\nUsing appropriate sf method, import the shapefile into R and save it in a simple feature data frame format. Note that there are three Projected Coordinate Systems of Nigeria, they are: EPSG: 26391, 26392, and 26303. You can use any one of them. Using appropriate tidyr and dplyr methods, derive the number of functional and non-functional water points at LGA level. Combining the geospatial and aspatial data frame into simple feature data frame. Visualising the distribution of water point by using appropriate statistical methods."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#installing-and-loading-r-packages",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#installing-and-loading-r-packages",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "2.1 Installing and Loading R packages",
    "text": "2.1 Installing and Loading R packages\nInstall and load sf, tidyverse, funModeling:\n\n\nShow the code!\npacman::p_load(tidyverse, sf, funModeling)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-the-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#importing-the-data",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "2.2 Importing the Data",
    "text": "2.2 Importing the Data\n\n2.2.1 Importing Geospatial Data\nNigeria data from Humanitarian Data Exchange (The NGA Data Set):\n\nNGA <- st_read(dsn = \"data/geospatial/\", layer = \"nga_admbnda_adm2\") %>% st_transform(crs=26392)\n\nReading layer `nga_admbnda_adm2' from data source \n  `C:\\valtyl\\IS415-GAA\\In-class_Ex\\In-class_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nThe geoBoundaries Data Set:\n\ngeoNGA <- st_read(dsn = \"data/geospatial/\", layer = \"geoBoundaries-NGA-ADM2\") %>% st_transform(crs = 26392)\n\nReading layer `geoBoundaries-NGA-ADM2' from data source \n  `C:\\valtyl\\IS415-GAA\\In-class_Ex\\In-class_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 5 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nThe message shows:\n\npolygon feature shapefile with 774 features and 5 fields\n%>% is a function called piping from tidyverse to emphasise a sequence of actions rather than the object that the actions are being performed on\nst_transform() to transform the data from WGS84 to the nigeria coordinate system\nwithout the transformation, the geometric data will have very small numbers (in decimal degree)\nEPSG: 26391, 26392 and 26303 are projected coordinate systems for different parts of Nigeria\nsince it is in WGS84, we should do the transformation!\n\n\n\n2.2.2 Importing Aspatial Data\n\nwp_nga <- read_csv(\"data/aspatial/WPdx.csv\") %>% filter(`#clean_country_name` == \"Nigeria\")\n\n\nfilter() is to select the rows that have ‘Nigeria’ under ‘#clean_country_name’ column\nuse ticks for field name, and quotes for values"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#converting-aspatial-data-into-geospatial-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#converting-aspatial-data-into-geospatial-data",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "2.3 Converting Aspatial Data into Geospatial Data",
    "text": "2.3 Converting Aspatial Data into Geospatial Data\nConverting the water point data into sf point features:\nStep 1 - Convert wkt field into sfc field using st_as_sfc() data type\n\nwp_nga$Geometry = st_as_sfc(wp_nga$`New Georeferenced Column`)\nwp_nga\n\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nStep 2 - Convert from tibble data frame into a point sf data frame using st_sf():\nImportant to include the referencing system of the data into the sf object\n\nwp_sf <- st_sf(wp_nga, crs=4326)\nwp_sf\n\nSimple feature collection with 95008 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 2.707441 ymin: 4.301812 xmax: 14.21828 ymax: 13.86568\nGeodetic CRS:  WGS 84\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\n\naspatial data don’t have spatial properties\nstep 1 - when we convert aspatial into geospatial we need to take note of the data type and convert it into the appropriate data type\nstep 2 - aspatial don’t have projection information so need to tell R what is the projected coordinate system that it is using\nuse crs = 4326 bc the coordinates in step 1 are in decimal degree and don’t have projection information, hence we need to put back original projection information first which is wgs84 and 4326 is the code used for wgs84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#projection-transformation",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#projection-transformation",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "2.4 Projection Transformation",
    "text": "2.4 Projection Transformation\nTransforming the projection from wgs84 to the appropriate projected coordinate system of Nigeria (26392):\naspatial data >> geospatial data >> Nigeria’s PCS\n\nwp_sf <- wp_sf %>% st_transform(crs=26392)\nwp_sf\n\nSimple feature collection with 95008 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 28907.91 ymin: 33736.93 xmax: 1293293 ymax: 1092883\nProjected CRS: Minna / Nigeria Mid Belt\n# A tibble: 95,008 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429068 GRID3             7.98    5.12 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2 222071 Federal Minis…    6.96    3.60 08/16/… Yes     Boreho… Well    Mechan…\n 3 160612 WaterAid          6.49    7.93 12/04/… Yes     Boreho… Well    Hand P…\n 4 160669 WaterAid          6.73    7.65 12/04/… Yes     Boreho… Well    <NA>   \n 5 160642 WaterAid          6.78    7.66 12/04/… Yes     Boreho… Well    Hand P…\n 6 160628 WaterAid          6.96    7.78 12/04/… Yes     Boreho… Well    Hand P…\n 7 160632 WaterAid          7.02    7.84 12/04/… Yes     Boreho… Well    Hand P…\n 8 642747 Living Water …    7.33    8.98 10/03/… Yes     Boreho… Well    Mechan…\n 9 642456 Living Water …    7.17    9.11 10/03/… Yes     Boreho… Well    Hand P…\n10 641347 Living Water …    7.20    9.22 03/28/… Yes     Boreho… Well    Hand P…\n# … with 94,998 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#excluding-redundant-fields",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#excluding-redundant-fields",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "3.1 Excluding redundant fields",
    "text": "3.1 Excluding redundant fields\nNGA sf data.frame consists of many redundant fields. The code chunk below uses select() of dplyr to retain column 3, 4, 8 and 9. Do you know why?\n\nNGA <- NGA %>%\n  select(c(3:4, 8:9))\n\n\nselect() - to select FIELDS we want to retain\nfilter() - to select ROWS we want to retain and we can include logical expression (eg. >, <, =, …)\ncol 3 (ADM2_EN) is the state name, col 4 (ADM2_PCODE) is the code name"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#checking-for-duplicate-name",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#checking-for-duplicate-name",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "3.2 Checking for duplicate name",
    "text": "3.2 Checking for duplicate name\nIt is always important to check for duplicate name in the data main data fields. Using duplicated() of Base R, we can flag out LGA names that might be duplicated as shown in the code chunk below.\n\nNGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\n[1] \"Bassa\"    \"Ifelodun\" \"Irepodun\" \"Nasarawa\" \"Obi\"      \"Surulere\"\n\n\nThe printout above shows that there are 6 LGAs with the same name. A Google search using the coordinates showed that there are LGAs with the same name but are located in different states. For instances, there is a Bassa LGA in Kogi State and a Bassa LGA in Plateau State.\nLet us correct these errors by using the code chunk below.\n\nNGA$ADM2_EN[94] <- \"Bassa, Kogi\"\nNGA$ADM2_EN[95] <- \"Bassa, Plateau\"\nNGA$ADM2_EN[304] <- \"Ifelodun, Kwara\"\nNGA$ADM2_EN[305] <- \"Ifelodun, Osun\"\nNGA$ADM2_EN[355] <- \"Irepodun, Kwara\"\nNGA$ADM2_EN[356] <- \"Irepodun, Osun\"\nNGA$ADM2_EN[519] <- \"Nasarawa, Kano\"\nNGA$ADM2_EN[520] <- \"Nasarawa, Nasarawa\"\nNGA$ADM2_EN[546] <- \"Obi, Benue\"\nNGA$ADM2_EN[547] <- \"Obi, Nasarawa\"\nNGA$ADM2_EN[693] <- \"Surulere, Lagos\"\nNGA$ADM2_EN[694] <- \"Surulere, Oyo\"\n\n\nrow number (eg. 94, 95) used to change the names. look into NGA data variable to see the row numbers\n\nNow, let us rerun the code chunk below to confirm that the duplicated name issue has been addressed.\n\nNGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\ncharacter(0)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#extracting-water-point-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#extracting-water-point-data",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.1 Extracting Water Point Data",
    "text": "4.1 Extracting Water Point Data\nNow we are ready to extract the water point data according to their status.\nThe code chunk below is used to extract functional water point.\n\nwp_functional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\n\ngrouped all the ‘functional’ together into a simple feature data file (saved in wp_functional)\n\nThe code chunk below is used to extract nonfunctional water point.\n\nwp_nonfunctional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Abandoned/Decommissioned\",\n             \"Abandoned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\"))\n\n\ngrouped all the ‘nonfunctional’ together into a simple feature data file (saved in wp_nonfunctional)\n\nThe code chunk below is used to extract water point with unknown status.\n\nwp_unknown <- wp_sf_nga %>%\n  filter(status_clean == \"unknown\")\n\n\ngrouped all the ‘unknown’ together into a simple feature data file (saved in wp_unknown)\n\nNext, the code chunk below is used to perform a quick EDA on the derived sf data.frames.\n\nfreq(data = wp_functional,\n     input = 'status_clean')\n\n\n\n\n                 status_clean frequency percentage cumulative_perc\n1                  Functional     45883      87.99           87.99\n2 Functional but needs repair      4579       8.78           96.77\n3   Functional but not in use      1686       3.23          100.00\n\n\n\nfreq(data = wp_nonfunctional,\ninput = 'status_clean')\n\n\n\n\n                      status_clean frequency percentage cumulative_perc\n1                   Non-Functional     29385      91.25           91.25\n2 Non-Functional due to dry season      2403       7.46           98.71\n3         Abandoned/Decommissioned       234       0.73           99.44\n4                        Abandoned       175       0.54           99.98\n5 Non functional due to dry season         7       0.02          100.00\n\n\n\nfreq(data = wp_unknown,\n     input = 'status_clean')\n\n\n\n\n  status_clean frequency percentage cumulative_perc\n1      unknown     10656        100             100"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#performing-point-in-polygon-count",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#performing-point-in-polygon-count",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.2 Performing Point-in-Polygon Count",
    "text": "4.2 Performing Point-in-Polygon Count\nNext, we want to find out the number of total, functional, nonfunctional and unknown water points in each LGA. This is performed in the following code chunk.\n\nFirst, it identifies the functional water points in each LGA by using st_intersects() of sf package.\nNext, length() is used to calculate the number of functional water points that fall inside each LGA.\n\n\nNGA_wp <- NGA %>% \n  mutate(`total_wp` = lengths(\n    st_intersects(NGA, wp_sf_nga))) %>%\n  mutate(`wp_functional` = lengths(\n    st_intersects(NGA, wp_functional))) %>%\n  mutate(`wp_nonfunctional` = lengths(\n    st_intersects(NGA, wp_nonfunctional))) %>%\n  mutate(`wp_unknown` = lengths(\n    st_intersects(NGA, wp_unknown)))\n\nNotice that four new derived fields have been added into NGA_wp sf data.frame.\n\nTotal of 5+4 = 9 fields now"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-attributes-by-using-statistical-graphs",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#visualising-attributes-by-using-statistical-graphs",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.3 Visualising attributes by using statistical graphs",
    "text": "4.3 Visualising attributes by using statistical graphs\nIn this code chunk below, appropriate functions of ggplot2 package is used to reveal the distribution of total water points by LGA in histogram.\n\nggplot(data = NGA_wp,\n       aes(x = total_wp)) + \n  geom_histogram(bins=20,\n                 color=\"black\",\n                 fill=\"light blue\") +\n  geom_vline(aes(xintercept=mean(\n    total_wp, na.rm=T)),\n             color=\"red\", \n             linetype=\"dashed\", \n             size=0.8) +\n  ggtitle(\"Distribution of total water points by LGA\") +\n  xlab(\"No. of water points\") +\n  ylab(\"No. of\\nLGAs\") +\n  theme(axis.title.y=element_text(angle = 0))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#saving-the-analytical-data-in-rds-format",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#saving-the-analytical-data-in-rds-format",
    "title": "In-class Exercise 2: Geospatial Data Wrangling",
    "section": "4.4 Saving the analytical data in rds format",
    "text": "4.4 Saving the analytical data in rds format\nIn order to retain the sf object structure for subsequent analysis, it is recommended to save the sf data.frame into rds format.\nIn the code chunk below, write_rds() of readr package is used to export an sf data.frame into rds format.\n\nwrite_rds(NGA_wp, \"data/rds/NGA_wp.rds\")\n\n\nrds data type allows us to retrain the data structure inside, keep the simple feature data properties"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "",
    "text": "In this in-class exercise, you will gain hands-on experience on using appropriate R methods to plot analytical maps. For the purpose of this exercise, Nigeria water point data prepared during In-class Exercise 2 will be used.\n\n\n\nBy the end of this in-class exercise, you will be able to use appropriate functions of tmap and tidyverse to perform the following tasks:\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#installing-and-loading-packages",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#installing-and-loading-packages",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "2.1 Installing and loading packages",
    "text": "2.1 Installing and loading packages\n\npacman::p_load(tmap, tidyverse, sf)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#importing-data",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#importing-data",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "2.2 Importing data",
    "text": "2.2 Importing data\n\nNGA_wp <- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-distribution-of-non-functional-water-point",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#visualising-distribution-of-non-functional-water-point",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "3.1 Visualising distribution of non-functional water point",
    "text": "3.1 Visualising distribution of non-functional water point\n\np1 <- tm_shape(NGA_wp) + \n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) + \n  tm_layout(main.title = \"Distribution of functional water point\", \n            legend.outside = FALSE)\n\n\ntm_shape() always takes spatial data, would initially be an empty map with boundary\ntm_fill() is needed to see smt in the map, n=10 means 10 classes, style provides the diff views, palette for colour scheme\ntm_border() to draw boundary, lwd means line width, alpha is the opacity/transparency of the boundary where 1 is black and 0.1 gets more transparent\n\n\np2 <- tm_shape(NGA_wp) + \n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) + \n  tm_layout(main.title = \"Distribution of total water point\", \n            legend.outside = FALSE)\n\n\ntmap_arrange(p2, p1, nrow=1)\n\n\n\n\n\nto place the 2 maps side by side in 1 row\nfunctional water point (wp) map is a subset of total wp map\nif we look at function wp only, could be misleading since we are plotting absolute value and functional wp is a subset of total wp\na better way of visualising would be to do distribution by rates"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#deriving-proportion-of-function-water-points-and-non-functional-water-points",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#deriving-proportion-of-function-water-points-and-non-functional-water-points",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "4.1 Deriving Proportion of Function Water Points and Non-Functional Water Points",
    "text": "4.1 Deriving Proportion of Function Water Points and Non-Functional Water Points\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp <- NGA_wp %>%\n  mutate(pct_functional = wp_functional/total_wp) %>%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#plotting-map-of-rate",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#plotting-map-of-rate",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "4.2 Plotting map of rate",
    "text": "4.2 Plotting map of rate\n\ntm_shape(NGA_wp) + \n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) + \n  tm_layout(main.title = \"Rate map of functional water point by LGAs\", \n            legend.outside = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#percentile-map",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#percentile-map",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "5.1 Percentile Map",
    "text": "5.1 Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\n5.1.1 Data Preparation\nStep 1: Exclude records with NA\n\nNGA_wp <- NGA_wp %>%\n  drop_na()\n\nStep 2: Creating customised classification and extracting values\n\npercent <- c(0, .01, .1, .5, .9, .99, 1)\nvar <- NGA_wp[\"pct_functional\"] %>%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\nst_set_geometry(NULL) is to drop the geometric field! a MUST to do else quantile() will give an error\nthis is because: When variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry.\n\n\n\n5.1.2 Why write functions?\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\n\n5.1.3 Creating the get var function\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var <- function(vname, df) {\n  v <- df[vname] %>%\n    st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\nvname - variable name\ndf - data frame\n\n\n\n5.1.4 A percentile mapping function\n\npercentmap <- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\") {\n  percent <- c(0, .01, .1, .5, .9, .99, 1)\n  var <- get.var(vnam, df)\n  bperc <- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() + \n  tm_shape(df) +\n    tm_fill(vnam,\n            title = legtitle,\n            breaks = bperc,\n            palette = \"Blues\",\n            labels = c(\"< 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"99% - 100%\")) +\n    tm_borders() +\n    tm_layout(main.title = mtitle,\n              title.position = c(\"right\", \"bottom\"))\n}\n\n\n\n5.1.5 Test drive the percentile mapping function\n\npercentmap(\"pct_functional\", NGA_wp)\n\n\n\n\n\nto customise, additional arguments such as title, legend positioning, etc. can be used"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#box-map",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#box-map",
    "title": "In-class Exercise 3: Analytical Mapping",
    "section": "5.2 Box Map",
    "text": "5.2 Box Map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) + \n  geom_boxplot()\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\n5.2.1 Creating the boxbreaks function\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks <- function(v,mult=1.5) {\n  qv <- unname(quantile(v))\n  iqr <- qv[4] - qv[2]\n  upfence <- qv[4] + mult * iqr\n  lofence <- qv[2] - mult * iqr\n  # initialize break points vector\n  bb <- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence < qv[1]) {  # no lower outliers\n    bb[1] <- lofence\n    bb[2] <- floor(qv[1])\n  } else {\n    bb[2] <- lofence\n    bb[1] <- qv[1]\n  }\n  if (upfence > qv[5]) { # no upper outliers\n    bb[7] <- upfence\n    bb[6] <- ceiling(qv[5])\n  } else {\n    bb[6] <- upfence\n    bb[7] <- qv[5]\n  }\n  bb[3:5] <- qv[2:4]\n  return(bb)\n}\n\n\n\n5.2.2 Creating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var <- function(vname,df) {\n  v <- df[vname] %>% st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\n\n5.2.3 Test drive the newly created function\nLet’s test the newly created function\n\nvar <- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\n5.2.4 Boxmap function\nThe code chunk below is an R function to create a box map.\n\narguments:\n\nvnam: variable name (as character, in quotes)\ndf: simple features polygon layer\nlegtitle: legend title\nmtitle: map title\nmult: multiplier for IQR\n\nreturns:\n\na tmap\nelement (plots a map)\n\n\n\nboxmap <- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var <- get.var(vnam,df)\n  bb <- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"< 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"> 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)\n\n\n\n\n\n\n5.2.5 Recode zero\nThe code chunk below is used to recode LGAs with zero total water point into NA.\n\nNGA_wp <- NGA_wp %>%\n  mutate(wp_functional = na_if(\n    total_wp, total_wp < 0))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "Spatial Point Pattern Analysis is the evaluation of the pattern or distribution, of a set of points on a surface. The point can be location of:\n\nevents such as crime, traffic accident and disease onset, or\nbusiness services (coffee and fastfood outlets) or facilities such as childcare and eldercare.\n\nUsing appropriate functions of spatstat, this hands-on exercise aims to discover the spatial point processes of childecare centres in Singapore.\nThe specific questions we would like to answer are as follows:\n\nare the childcare centres in Singapore randomly distributed throughout the country?\nif the answer is not, then the next logical question is where are the locations with higher concentration of childcare centres?"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importing-the-spatial-data",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#importing-the-spatial-data",
    "title": "In-class Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "1.4.1 Importing the spatial data",
    "text": "1.4.1 Importing the spatial data\n\nchildcare_sf <- st_read(\"data/child-care-services-geojson.geojson\") %>%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\valtyl\\IS415-GAA\\In-class_Ex\\In-class_Ex04\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf <- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\valtyl\\IS415-GAA\\In-class_Ex\\In-class_Ex04\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf <- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\valtyl\\IS415-GAA\\In-class_Ex\\In-class_Ex04\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-sf-data-frames-to-sps-spatial-class",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-sf-data-frames-to-sps-spatial-class",
    "title": "In-class Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "1.5.1 Converting sf data frames to sp’s Spatial* class",
    "text": "1.5.1 Converting sf data frames to sp’s Spatial* class\nThe code chunk below uses as_Spatial() of sf package to convert the three geospatial data from simple feature data frame to sp’s Spatial* class.\n\nchildcare <- as_Spatial(childcare_sf)\nmpsz <- as_Spatial(mpsz_sf)\nsg <- as_Spatial(sg_sf)\n\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>018989</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>08F73931F4A691F4</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \nmax values  : kml_999,                  <center><table><tr><th colspan='2' align='center'><em>Attributes</em></th></tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSBLOCKHOUSENUMBER</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSBUILDINGNAME</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSPOSTALCODE</th> <td>829646</td> </tr><tr bgcolor=\"\"> <th>ADDRESSSTREETNAME</th> <td>200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSTYPE</th> <td></td> </tr><tr bgcolor=\"\"> <th>DESCRIPTION</th> <td>Child Care Services</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>HYPERLINK</th> <td></td> </tr><tr bgcolor=\"\"> <th>LANDXADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>LANDYADDRESSPOINT</th> <td>0</td> </tr><tr bgcolor=\"\"> <th>NAME</th> <td>RAFFLES KIDZ @ PUNGGOL PTE LTD</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>PHOTOURL</th> <td></td> </tr><tr bgcolor=\"\"> <th>ADDRESSFLOORNUMBER</th> <td></td> </tr><tr bgcolor=\"#E3E3F3\"> <th>INC_CRC</th> <td>379D017BF244B0FA</td> </tr><tr bgcolor=\"\"> <th>FMEL_UPD_D</th> <td>20200826094036</td> </tr><tr bgcolor=\"#E3E3F3\"> <th>ADDRESSUNITNUMBER</th> <td></td> </tr></table></center> \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-the-spatial-class-into-generic-sp-format",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-the-spatial-class-into-generic-sp-format",
    "title": "In-class Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "1.5.2 Converting the Spatial* class into generic sp format",
    "text": "1.5.2 Converting the Spatial* class into generic sp format\nspatstat requires the analytical data in ppp object form. There is no direct way to convert a Spatial* classes into ppp object. We need to convert the Spatial classes* into Spatial object first.\nThe codes chunk below converts the Spatial* classes into generic sp objects.\n\nchildcare_sp <- as(childcare, \"SpatialPoints\")\nsg_sp <- as(sg, \"SpatialPolygons\")\n\nNext, you should display the sp objects properties as shown below.\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#converting-the-generic-sp-format-into-spatstats-ppp-format",
    "title": "In-class Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "1.5.3 Converting the generic sp format into spatstat’s ppp format",
    "text": "1.5.3 Converting the generic sp format into spatstat’s ppp format\nNow, we will use as.ppp() function of spatstat to convert the spatial data into spatstat’s ppp object format.\n\nchildcare_ppp <- as(childcare_sp, \"ppp\")\nchildcare_ppp\n\nPlanar point pattern: 1545 points\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let us plot childcare_ppp and examine the different.\n\nplot(childcare_ppp)\n\n\n\n\nYou can take a quick look at the summary statistics of the newly created ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/data/stores.html",
    "href": "In-class_Ex/In-class_Ex05/data/stores.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     \n\n\n        0 0     false"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/data/study_area.html",
    "href": "In-class_Ex/In-class_Ex05/data/study_area.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "Welcome to IS415 Geospatial Analytics and Applications.\nThis is the course website of IS415 that I am studying this term. You will find my course work on this website."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-Home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "",
    "text": "Water is an important resource to mankind. Clean and accessible water is critical to human health. It provides a healthy environment, a sustainable economy, reduces poverty and ensures peace and security. Yet over 40% of the global population does not have access to sufficient clean water. By 2025, 1.8 billion people will be living in countries or regions with absolute water scarcity, according to UN-Water. The lack of water poses a major threat to several sectors, including food security. Agriculture uses about 70% of the world’s accessible freshwater.\nDeveloping countries are most affected by water shortages and poor water quality. Up to 80% of illnesses in the developing world are linked to inadequate water and sanitation. Despite technological advancement, providing clean water to the rural community is still a major development issues in many countries globally, especially countries in the Africa continent.\nTo address the issue of providing clean and sustainable water supply to the rural community, a global Water Point Data Exchange (WPdx) project has been initiated. The main aim of this initiative is to collect water point related data from rural areas at the water point or small water scheme level and share the data via WPdx Data Repository, a cloud-based data library. What is so special of this project is that data are collected based on WPDx Data Standard."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#aspatial-data",
    "title": "Take-Home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "3.1 Aspatial Data",
    "text": "3.1 Aspatial Data\nFor the purpose of this assignment, data from WPdx Global Data Repositories will be used. There are two versions of the data. They are: WPdx-Basic and WPdx+. You are required to use WPdx+ data set."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-data",
    "title": "Take-Home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "3.2 Geospatial data",
    "text": "3.2 Geospatial data\nThis study will focus of Osun State, Nigeria. The state boundary GIS data of Nigeria can be downloaded either from The Humanitarian Data Exchange portal or geoBoundaries."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#installing-and-loading-r-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#installing-and-loading-r-packages",
    "title": "Take-Home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "4.1 Installing and Loading R packages",
    "text": "4.1 Installing and Loading R packages\n\nsf: to import, manage, and process geospatial data\ntidyverse: a collection of packages (readr for importing delimited text file, tidyr for tidying data, dplyr for wrangling data)\nspatstat: for point pattern analysis\nraster: reads, writes, manipulates, analyses and models gridded spatial data (i.e. raster)\nmaptools: a set of tools for manipulating geographic data\ntmap: provides functions for plotting cartographic quality static point patterns maps or interactive maps\nfunModeling: for visualisations\nsfdep: for spatial dependence of simple features\n\nTo install the R packages:\n\npacman::p_load(tidyverse, sf, spatstat, raster, maptools, tmap, funModeling, sfdep)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#importing-the-data",
    "title": "Take-Home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "4.2 Importing the Data",
    "text": "4.2 Importing the Data\n\n4.2.1 Importing the Geospatial Data\nNGA Data Set, Nigeria data from Humanitarian Data Exchange:\n\nst_read() used to import the data\nst_transform() used to transform the data from WGS84 to Nigeria’s Projected Coordinate System\n\n\nNGA <- st_read(dsn = \"data/geospatial/\", layer = \"nga_admbnda_adm2\") %>% st_transform(crs=26392) \n\nReading layer `nga_admbnda_adm2' from data source \n  `C:\\valtyl\\IS415-GAA\\Take-home_Ex\\Take-home_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 774 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2.668534 ymin: 4.273007 xmax: 14.67882 ymax: 13.89442\nGeodetic CRS:  WGS 84\n\n\nUse filter() to focus on Osun State, Nigeria\n\nNGA <- NGA %>% filter(NGA$ADM1_EN == \"Osun\")\nNGA\n\nSimple feature collection with 30 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 176503.2 ymin: 331434.7 xmax: 291043.8 ymax: 454520.1\nProjected CRS: Minna / Nigeria Mid Belt\nFirst 10 features:\n   Shape_Leng  Shape_Area        ADM2_EN ADM2_PCODE       ADM2_REF ADM2ALT1EN\n1   1.7951405 0.062436080       Aiyedade   NG030001       Aiyedade       <NA>\n2   0.7101503 0.024818478       Aiyedire   NG030002       Aiyedire       <NA>\n3   0.9199564 0.038002894 Atakumosa East   NG030003 Atakumosa East       <NA>\n4   0.8502782 0.030445804 Atakumosa West   NG030004 Atakumosa West       <NA>\n5   0.5212768 0.012213340     Boluwaduro   NG030005     Boluwaduro       <NA>\n6   0.6088930 0.011827501         Boripe   NG030006         Boripe       <NA>\n7   0.4714403 0.008343638      Ede North   NG030007      Ede North       <NA>\n8   0.5660235 0.017623677      Ede South   NG030008      Ede South       <NA>\n9   0.8273123 0.022026327       Egbedore   NG030009       Egbedore       <NA>\n10  1.1304849 0.029791275         Ejigbo   NG030010         Ejigbo       <NA>\n   ADM2ALT2EN ADM1_EN ADM1_PCODE ADM0_EN ADM0_PCODE       date    validOn\n1        <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n2        <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n3        <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n4        <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n5        <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n6        <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n7        <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n8        <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n9        <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n10       <NA>    Osun      NG030 Nigeria         NG 2016-11-29 2019-04-17\n   validTo        SD_EN SD_PCODE                       geometry\n1     <NA>    Osun West  NG03003 MULTIPOLYGON (((213526.6 34...\n2     <NA>    Osun West  NG03003 MULTIPOLYGON (((212542.6 40...\n3     <NA>    Osun East  NG03002 MULTIPOLYGON (((265746.8 37...\n4     <NA>    Osun East  NG03002 MULTIPOLYGON (((248871.4 40...\n5     <NA> Osun Central  NG03001 MULTIPOLYGON (((266092.2 43...\n6     <NA> Osun Central  NG03001 MULTIPOLYGON (((255072.5 43...\n7     <NA>    Osun West  NG03003 MULTIPOLYGON (((236386.9 41...\n8     <NA>    Osun West  NG03003 MULTIPOLYGON (((236386.9 41...\n9     <NA>    Osun West  NG03003 MULTIPOLYGON (((220756 4317...\n10    <NA>    Osun West  NG03003 MULTIPOLYGON (((214422.1 42...\n\n\n\n4.2.1.1 Geospatial Data Cleaning\nRemoval of redundant fields and duplicates\n\n4.2.1.1.1 Excluding redundant fields\nUse select() to retain columns that are relevant\n\nNGA <- NGA %>% dplyr::select(c(3:4, 8:9))\n\n\n\n4.2.1.1.2 Checking for duplicate names\nUse duplicated() to identify names at LGA level that might be duplicated\n\nNGA$ADM2_EN[duplicated(NGA$ADM2_EN)==TRUE]\n\ncharacter(0)\n\n\nThe above output shows that there are no duplicate LGAs in Osun State, Nigeria\n\n\n\n\n4.2.2 Importing the Aspatial Data\nWPdx+ Data Set:\n\nfilter() to focus on Osun State, Nigeria\n\n\nwp_nga <- read_csv(\"data/aspatial/WPdx.csv\") %>% filter(`#clean_country_name` == \"Nigeria\") %>% filter(`#clean_adm1` == \"Osun\")\n\n\n4.2.2.1 Converting the Aspatial Data into Geospatial Data\nConverting the water point data into sf point features requires 2 steps:\nStep 1 - Convert wkt field into sfc field using st_as_sfc() data type:\n\nwp_nga$Geometry = st_as_sfc(wp_nga$`New Georeferenced Column`)\nwp_nga\n\n# A tibble: 5,557 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n    <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429123 GRID3             8.02    5.06 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2  70566 Federal Minis…    7.32    4.79 05/11/… No      Protec… Well    Mechan…\n 3  70578 Federal Minis…    7.76    4.56 05/11/… No      Boreho… Well    Mechan…\n 4  66401 Federal Minis…    8.03    4.64 04/30/… No      Boreho… Well    Mechan…\n 5 422190 GRID3             7.87    4.88 08/29/… Unknown <NA>    <NA>    Tapsta…\n 6 422064 GRID3             7.7     4.89 08/29/… Unknown <NA>    <NA>    Tapsta…\n 7  65607 Federal Minis…    7.89    4.71 05/12/… No      Boreho… Well    Mechan…\n 8  68989 Federal Minis…    7.51    4.27 05/07/… No      Boreho… Well    <NA>   \n 9  67708 Federal Minis…    7.48    4.35 04/29/… Yes     Boreho… Well    Mechan…\n10  66419 Federal Minis…    7.63    4.50 05/08/… Yes     Boreho… Well    Hand P…\n# … with 5,547 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\nStep 2 - Convert from tibble data frame into sf point data frame using st_sf():\n\nSince Aspatial data does not have projection information, we need to specify the projected coordinate system\nCode 4326 is the code for WGS84\n\n\nwp_sf <- st_sf(wp_nga, crs=4326)\nwp_sf\n\nSimple feature collection with 5557 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 4.032004 ymin: 7.060309 xmax: 5.06 ymax: 8.061898\nGeodetic CRS:  WGS 84\n# A tibble: 5,557 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429123 GRID3             8.02    5.06 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2  70566 Federal Minis…    7.32    4.79 05/11/… No      Protec… Well    Mechan…\n 3  70578 Federal Minis…    7.76    4.56 05/11/… No      Boreho… Well    Mechan…\n 4  66401 Federal Minis…    8.03    4.64 04/30/… No      Boreho… Well    Mechan…\n 5 422190 GRID3             7.87    4.88 08/29/… Unknown <NA>    <NA>    Tapsta…\n 6 422064 GRID3             7.7     4.89 08/29/… Unknown <NA>    <NA>    Tapsta…\n 7  65607 Federal Minis…    7.89    4.71 05/12/… No      Boreho… Well    Mechan…\n 8  68989 Federal Minis…    7.51    4.27 05/07/… No      Boreho… Well    <NA>   \n 9  67708 Federal Minis…    7.48    4.35 04/29/… Yes     Boreho… Well    Mechan…\n10  66419 Federal Minis…    7.63    4.50 05/08/… Yes     Boreho… Well    Hand P…\n# … with 5,547 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …\n\n\n\n\n4.2.2.2 Projection Transformation\nTransforming the projection of the Aspatial data from WGS84 to Nigeria’s Projected Coordinate System:\n\nwp_sf <- wp_sf %>% st_transform(crs=26392)\nwp_sf\n\nSimple feature collection with 5557 features and 70 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 177285.9 ymin: 340054.1 xmax: 291287.1 ymax: 450859.7\nProjected CRS: Minna / Nigeria Mid Belt\n# A tibble: 5,557 × 71\n   row_id `#source`      #lat_…¹ #lon_…² #repo…³ #stat…⁴ #wate…⁵ #wate…⁶ #wate…⁷\n *  <dbl> <chr>            <dbl>   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 429123 GRID3             8.02    5.06 08/29/… Unknown <NA>    <NA>    Tapsta…\n 2  70566 Federal Minis…    7.32    4.79 05/11/… No      Protec… Well    Mechan…\n 3  70578 Federal Minis…    7.76    4.56 05/11/… No      Boreho… Well    Mechan…\n 4  66401 Federal Minis…    8.03    4.64 04/30/… No      Boreho… Well    Mechan…\n 5 422190 GRID3             7.87    4.88 08/29/… Unknown <NA>    <NA>    Tapsta…\n 6 422064 GRID3             7.7     4.89 08/29/… Unknown <NA>    <NA>    Tapsta…\n 7  65607 Federal Minis…    7.89    4.71 05/12/… No      Boreho… Well    Mechan…\n 8  68989 Federal Minis…    7.51    4.27 05/07/… No      Boreho… Well    <NA>   \n 9  67708 Federal Minis…    7.48    4.35 04/29/… Yes     Boreho… Well    Mechan…\n10  66419 Federal Minis…    7.63    4.50 05/08/… Yes     Boreho… Well    Hand P…\n# … with 5,547 more rows, 62 more variables: `#water_tech_category` <chr>,\n#   `#facility_type` <chr>, `#clean_country_name` <chr>, `#clean_adm1` <chr>,\n#   `#clean_adm2` <chr>, `#clean_adm3` <chr>, `#clean_adm4` <chr>,\n#   `#install_year` <dbl>, `#installer` <chr>, `#rehab_year` <lgl>,\n#   `#rehabilitator` <lgl>, `#management_clean` <chr>, `#status_clean` <chr>,\n#   `#pay` <chr>, `#fecal_coliform_presence` <chr>,\n#   `#fecal_coliform_value` <dbl>, `#subjective_quality` <chr>, …"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis-eda",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-data-analysis-eda",
    "title": "Take-Home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "4.3 Exploratory Data Analysis (EDA)",
    "text": "4.3 Exploratory Data Analysis (EDA)\n\n4.3.1 Reveal distribution of water point status visually\nUsing freq() of funModeling to represent the visualisation and we can also find out the number of classes of #status_clean\n\nfreq(data = wp_sf,\n     input = '#status_clean')\n\n\n\n\n                     #status_clean frequency percentage cumulative_perc\n1                       Functional      2319      41.73           41.73\n2                   Non-Functional      2008      36.13           77.86\n3                             <NA>       748      13.46           91.32\n4      Functional but needs repair       248       4.46           95.78\n5 Non-Functional due to dry season       151       2.72           98.50\n6        Functional but not in use        63       1.13           99.63\n7                        Abandoned        15       0.27           99.90\n8         Abandoned/Decommissioned         5       0.09          100.00\n\n\nThere are 9 classes in the #status_clean field\nRename ‘#status_clean’ to ‘status_clean’ and replace NA values under ‘status_clean’ with ‘unknown’\n\nwp_sf_nga <- wp_sf %>% \n  rename(status_clean = '#status_clean') %>%\n  dplyr::select(status_clean, row_id) %>%\n  mutate(status_clean = replace_na(\n    status_clean, \"unknown\"))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-data-wrangling-for-all-water-points",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#geospatial-data-wrangling-for-all-water-points",
    "title": "Take-Home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "4.4 Geospatial Data Wrangling for all water points",
    "text": "4.4 Geospatial Data Wrangling for all water points\nThis section is for all water points, including functional and non-functional in Osun State, Nigeria\n\n4.4.1 Converting sf data frames to sp’s Spatial* class\nConvert from sf dataframe to sp’s Spatial class using as_Spatial() of sf package:\n\nNGA_spatial <- as_Spatial(NGA)\nwp_spatial <- as_Spatial(wp_sf)\n\nDisplay the Spatial* classes properties:\n\nNGA_spatial\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 30 \nextent      : 176503.2, 291043.8, 331434.7, 454520.1  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 4\nnames       :  ADM2_EN, ADM2_PCODE, ADM1_EN, ADM1_PCODE \nmin values  : Aiyedade,   NG030001,    Osun,      NG030 \nmax values  :   Osogbo,   NG030030,    Osun,      NG030 \n\n\n\nwp_spatial\n\nclass       : SpatialPointsDataFrame \nfeatures    : 5557 \nextent      : 177285.9, 291287.1, 340054.1, 450859.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 70\nnames       : row_id,                                     X.source, X.lat_deg, X.lon_deg,          X.report_date, X.status_id, X.water_source_clean, X.water_source_category, X.water_tech_clean, X.water_tech_category, X.facility_type, X.clean_country_name, X.clean_adm1, X.clean_adm2, X.clean_adm3, ... \nmin values  :  34829, Federal Ministry of Water Resources, Nigeria,  7.060309, 4.0320038, 01/01/2010 12:00:00 AM,          No,             Borehole,                  Spring,          Hand Pump,             Hand Pump,        Improved,              Nigeria,         Osun,     Aiyedade,           NA, ... \nmax values  : 472843,                                        GRID3, 8.0618983,      5.06, 09/16/2015 12:00:00 AM,         Yes,     Protected Spring,                    Well,           Tapstand,              Tapstand,        Improved,              Nigeria,         Osun,       Osogbo,           NA, ... \n\n\n\n\n4.4.2 Converting the Spatial* class into generic sp format\nSince spatstat requires the analytical data in ppp object format, we need to convert the Spatial* classes into Spatial objects first then convert them to spatstat’s ppp object format\nConvert from Spatial* classes into generic sp objects:\n\nNGA_sp <- as(NGA_spatial, \"SpatialPolygons\")\nwp_sp <- as(wp_spatial, \"SpatialPoints\")\n\nDisplay the sp object properties:\n\nNGA_sp\n\nclass       : SpatialPolygons \nfeatures    : 30 \nextent      : 176503.2, 291043.8, 331434.7, 454520.1  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \n\n\n\nwp_sp\n\nclass       : SpatialPoints \nfeatures    : 5557 \nextent      : 177285.9, 291287.1, 340054.1, 450859.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \n\n\n\n\n4.4.3 Converting the generic sp format into spatstat’s ppp format\nConvert from generic sp format to spatstat’s ppp object using as.ppp() of spatstat:\n\nwp_ppp <- as(wp_sp, \"ppp\")\nwp_ppp\n\nPlanar point pattern: 5557 points\nwindow: rectangle = [177285.9, 291287.05] x [340054.1, 450859.7] units\n\n\nPlot wp_ppp to examine the difference:\n\nplot(wp_ppp)\n\n\n\n\nSummary statistics of wp_ppp ppp object:\n\nsummary(wp_ppp)\n\nPlanar point pattern:  5557 points\nAverage intensity 4.399158e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: rectangle = [177285.9, 291287.05] x [340054.1, 450859.7] units\n                    (114000 x 110800 units)\nWindow area = 1.2632e+10 square units\n\n\n\n\n4.4.4 Checking for duplicate points in wp_ppp ppp object\n\nany(duplicated(wp_ppp))\n\n[1] FALSE\n\n\nThere are no duplicate point events\n\n\n4.4.5 Plot all water point point events\n\nsf_use_s2(FALSE)\ntmap_mode('view')\ntm_shape(wp_spatial) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\nChanging from interactive mode back to plot:\n\ntmap_mode('plot')\n\n\n\n4.4.6 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area. In spatstat, an object called owin is specially designed to represent this polygonal region.\nConvert NGASpatialPolygon object into owin object of spatstat:\n\nNGA_owin <- as(NGA_sp, \"owin\")\n\nDisplay the owin object:\n\nplot(NGA_owin)\n\n\n\n\nSummary of the owin object:\n\nsummary(NGA_owin)\n\nWindow: polygonal boundary\n30 separate polygons (no holes)\n            vertices      area relative.area\npolygon 1        204 766084000       0.08870\npolygon 2         81 304399000       0.03520\npolygon 3         97 465688000       0.05390\npolygon 4        124 373051000       0.04320\npolygon 5         60 149473000       0.01730\npolygon 6         84 144820000       0.01680\npolygon 7         50 102243000       0.01180\npolygon 8         72 216002000       0.02500\npolygon 9        112 269897000       0.03130\npolygon 10       125 365142000       0.04230\npolygon 11        83 111191000       0.01290\npolygon 12       126 192557000       0.02230\npolygon 13       219 904397000       0.10500\npolygon 14       174 741131000       0.08580\npolygon 15        81 138742000       0.01610\npolygon 16        65 119452000       0.01380\npolygon 17        90 280205000       0.03240\npolygon 18        69  69814600       0.00808\npolygon 19        69  42727500       0.00495\npolygon 20        49  30458800       0.00353\npolygon 21        62 263505000       0.03050\npolygon 22        93 438930000       0.05080\npolygon 23        87 274127000       0.03170\npolygon 24       105 509979000       0.05910\npolygon 25        98 292058000       0.03380\npolygon 26        64 327765000       0.03800\npolygon 27       133 108945000       0.01260\npolygon 28       122 462169000       0.05350\npolygon 29        94 109715000       0.01270\npolygon 30        95  61239800       0.00709\nenclosing rectangle: [176503.22, 291043.82] x [331434.7, 454520.1] units\n                     (114500 x 123100 units)\nWindow area = 8635910000 square units\nFraction of frame area: 0.613\n\n\n\n\n4.4.7 Combining point events object and owin object\nNow, we will extract water point events that are located within Osun State, Nigeria:\n\nWPNGA_ppp = wp_ppp[NGA_owin]\n\nSummary of the combined point and polygon feature in 1 ppp object class:\n\nsummary(WPNGA_ppp)\n\nPlanar point pattern:  5322 points\nAverage intensity 6.162642e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: polygonal boundary\n30 separate polygons (no holes)\n            vertices      area relative.area\npolygon 1        204 766084000       0.08870\npolygon 2         81 304399000       0.03520\npolygon 3         97 465688000       0.05390\npolygon 4        124 373051000       0.04320\npolygon 5         60 149473000       0.01730\npolygon 6         84 144820000       0.01680\npolygon 7         50 102243000       0.01180\npolygon 8         72 216002000       0.02500\npolygon 9        112 269897000       0.03130\npolygon 10       125 365142000       0.04230\npolygon 11        83 111191000       0.01290\npolygon 12       126 192557000       0.02230\npolygon 13       219 904397000       0.10500\npolygon 14       174 741131000       0.08580\npolygon 15        81 138742000       0.01610\npolygon 16        65 119452000       0.01380\npolygon 17        90 280205000       0.03240\npolygon 18        69  69814600       0.00808\npolygon 19        69  42727500       0.00495\npolygon 20        49  30458800       0.00353\npolygon 21        62 263505000       0.03050\npolygon 22        93 438930000       0.05080\npolygon 23        87 274127000       0.03170\npolygon 24       105 509979000       0.05910\npolygon 25        98 292058000       0.03380\npolygon 26        64 327765000       0.03800\npolygon 27       133 108945000       0.01260\npolygon 28       122 462169000       0.05350\npolygon 29        94 109715000       0.01270\npolygon 30        95  61239800       0.00709\nenclosing rectangle: [176503.22, 291043.82] x [331434.7, 454520.1] units\n                     (114500 x 123100 units)\nWindow area = 8635910000 square units\nFraction of frame area: 0.613\n\n\nPlot of the WPNGA_ppp ppp object:\n\nplot(WPNGA_ppp)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-spatial-data-analysis-esda",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#exploratory-spatial-data-analysis-esda",
    "title": "Take-Home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "4.5 Exploratory Spatial Data Analysis (ESDA)",
    "text": "4.5 Exploratory Spatial Data Analysis (ESDA)\n\n4.5.1 Geospatial Data Wrangling for functional and non-functional water points separately\nExtract functional water points using filter():\n\nwp_functional <- wp_sf_nga %>%\n  filter(`status_clean` %in%\n           c(\"Functional\",\n             \"Functional but not in use\",\n             \"Functional but needs repair\"))\n\n\nwp_functional\n\nSimple feature collection with 2630 features and 2 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 177285.9 ymin: 343128.1 xmax: 290751 ymax: 450859.7\nProjected CRS: Minna / Nigeria Mid Belt\n# A tibble: 2,630 × 3\n   status_clean                row_id            Geometry\n * <chr>                        <dbl>         <POINT [m]>\n 1 Functional but needs repair  67708   (212810 386707.6)\n 2 Functional                   66419 (228798.9 403822.5)\n 3 Functional                   68889 (270497.9 377476.9)\n 4 Functional                   65863   (212202 349210.1)\n 5 Functional                   70495 (259331.9 399591.4)\n 6 Functional                   67351   (195484 404733.2)\n 7 Functional                   67727 (221302.3 389473.6)\n 8 Functional but not in use    69886 (263254.1 382692.9)\n 9 Functional                   69369   (192484.1 405113)\n10 Functional                   70102     (252736 373593)\n# … with 2,620 more rows\n\n\nExtract non-functional water points using filter():\n\nwp_nonfunctional <- wp_sf_nga %>%\n  filter(status_clean %in%\n           c(\"Abandoned/Decommissioned\",\n             \"Abandoned\",\n             \"Non-Functional due to dry season\",\n             \"Non-Functional\",\n             \"Non functional due to dry season\"))\n\n\n4.5.1.1 Converting sf data frames to sp’s Spatial* class:\n\nwp_functional_spatial <- as_Spatial(wp_functional)\nwp_nonfunctional_spatial <- as_Spatial(wp_nonfunctional)\n\n\nwp_functional_spatial\n\nclass       : SpatialPointsDataFrame \nfeatures    : 2630 \nextent      : 177285.9, 290751, 343128.1, 450859.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :              status_clean, row_id \nmin values  :                Functional,  36914 \nmax values  : Functional but not in use, 471319 \n\n\n\nwp_nonfunctional_spatial\n\nclass       : SpatialPointsDataFrame \nfeatures    : 2179 \nextent      : 180539, 290616, 340054.1, 450780.1  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :                     status_clean, row_id \nmin values  :                        Abandoned,  34829 \nmax values  : Non-Functional due to dry season, 421239 \n\n\n\n\n4.5.1.2 Converting the Spatial* class into generic sp format:\n\nwp_functional_sp <- as(wp_functional_spatial, \"SpatialPoints\")\nwp_nonfunctional_sp <- as(wp_nonfunctional_spatial, \"SpatialPoints\")\n\n\nwp_functional_sp\n\nclass       : SpatialPoints \nfeatures    : 2630 \nextent      : 177285.9, 290751, 343128.1, 450859.7  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \n\n\n\nwp_nonfunctional_sp\n\nclass       : SpatialPoints \nfeatures    : 2179 \nextent      : 180539, 290616, 340054.1, 450780.1  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=4 +lon_0=8.5 +k=0.99975 +x_0=670553.98 +y_0=0 +a=6378249.145 +rf=293.465 +towgs84=-92,-93,122,0,0,0,0 +units=m +no_defs \n\n\n\n\n4.5.1.3 Converting the generic sp format into spatstat’s ppp format:\n\nwp_functional_ppp <- as(wp_functional_sp, \"ppp\")\nwp_nonfunctional_ppp <- as(wp_nonfunctional_sp, \"ppp\")\n\nPlot and Summary of PPP object for functional water points:\n\nplot(wp_functional_ppp)\n\n\n\n\n\nsummary(wp_functional_ppp)\n\nPlanar point pattern:  2630 points\nAverage intensity 2.151545e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: rectangle = [177285.9, 290750.96] x [343128.1, 450859.7] units\n                    (113500 x 107700 units)\nWindow area = 12223800000 square units\n\n\nPlot and Summary of PPP object for non-functional water points:\n\nplot(wp_nonfunctional_ppp)\n\n\n\n\n\nsummary(wp_nonfunctional_ppp)\n\nPlanar point pattern:  2179 points\nAverage intensity 1.787766e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: rectangle = [180538.96, 290616] x [340054.1, 450780.1] units\n                    (110100 x 110700 units)\nWindow area = 12188400000 square units\n\n\n\n\n4.5.1.4 Combining point events object and owin object:\nPreviously, the check for duplicate point events has been done as well as the creation of the NGA owin object hence we do not need to repeat in this section.\n\nwp_functional_NGA_ppp = wp_functional_ppp[NGA_owin]\n\n\nsummary(wp_functional_NGA_ppp)\n\nPlanar point pattern:  2529 points\nAverage intensity 2.928471e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: polygonal boundary\n30 separate polygons (no holes)\n            vertices      area relative.area\npolygon 1        204 766084000       0.08870\npolygon 2         81 304399000       0.03520\npolygon 3         97 465688000       0.05390\npolygon 4        124 373051000       0.04320\npolygon 5         60 149473000       0.01730\npolygon 6         84 144820000       0.01680\npolygon 7         50 102243000       0.01180\npolygon 8         72 216002000       0.02500\npolygon 9        112 269897000       0.03130\npolygon 10       125 365142000       0.04230\npolygon 11        83 111191000       0.01290\npolygon 12       126 192557000       0.02230\npolygon 13       219 904397000       0.10500\npolygon 14       174 741131000       0.08580\npolygon 15        81 138742000       0.01610\npolygon 16        65 119452000       0.01380\npolygon 17        90 280205000       0.03240\npolygon 18        69  69814600       0.00808\npolygon 19        69  42727500       0.00495\npolygon 20        49  30458800       0.00353\npolygon 21        62 263505000       0.03050\npolygon 22        93 438930000       0.05080\npolygon 23        87 274127000       0.03170\npolygon 24       105 509979000       0.05910\npolygon 25        98 292058000       0.03380\npolygon 26        64 327765000       0.03800\npolygon 27       133 108945000       0.01260\npolygon 28       122 462169000       0.05350\npolygon 29        94 109715000       0.01270\npolygon 30        95  61239800       0.00709\nenclosing rectangle: [176503.22, 291043.82] x [331434.7, 454520.1] units\n                     (114500 x 123100 units)\nWindow area = 8635910000 square units\nFraction of frame area: 0.613\n\n\nPlot PPP object (combined point and polygon features) for functional water points:\n\nplot(wp_functional_NGA_ppp)\n\n\n\n\n\nwp_nonfunctional_NGA_ppp = wp_nonfunctional_ppp[NGA_owin]\n\n\nsummary(wp_nonfunctional_NGA_ppp)\n\nPlanar point pattern:  2059 points\nAverage intensity 2.384232e-07 points per square unit\n\nCoordinates are given to 2 decimal places\ni.e. rounded to the nearest multiple of 0.01 units\n\nWindow: polygonal boundary\n30 separate polygons (no holes)\n            vertices      area relative.area\npolygon 1        204 766084000       0.08870\npolygon 2         81 304399000       0.03520\npolygon 3         97 465688000       0.05390\npolygon 4        124 373051000       0.04320\npolygon 5         60 149473000       0.01730\npolygon 6         84 144820000       0.01680\npolygon 7         50 102243000       0.01180\npolygon 8         72 216002000       0.02500\npolygon 9        112 269897000       0.03130\npolygon 10       125 365142000       0.04230\npolygon 11        83 111191000       0.01290\npolygon 12       126 192557000       0.02230\npolygon 13       219 904397000       0.10500\npolygon 14       174 741131000       0.08580\npolygon 15        81 138742000       0.01610\npolygon 16        65 119452000       0.01380\npolygon 17        90 280205000       0.03240\npolygon 18        69  69814600       0.00808\npolygon 19        69  42727500       0.00495\npolygon 20        49  30458800       0.00353\npolygon 21        62 263505000       0.03050\npolygon 22        93 438930000       0.05080\npolygon 23        87 274127000       0.03170\npolygon 24       105 509979000       0.05910\npolygon 25        98 292058000       0.03380\npolygon 26        64 327765000       0.03800\npolygon 27       133 108945000       0.01260\npolygon 28       122 462169000       0.05350\npolygon 29        94 109715000       0.01270\npolygon 30        95  61239800       0.00709\nenclosing rectangle: [176503.22, 291043.82] x [331434.7, 454520.1] units\n                     (114500 x 123100 units)\nWindow area = 8635910000 square units\nFraction of frame area: 0.613\n\n\nPlot PPP object (combined point and polygon features) for non-functional water points:\n\nplot(wp_nonfunctional_NGA_ppp)\n\n\n\n\n\n\n4.5.1.5 Displaying functional and non-functional water points together with different colours\nWith original data’s categories:\n\nsf_use_s2(FALSE)\ntmap_mode('view')\ntm_shape(wp_sf_nga) +\n  tm_dots(col = \"status_clean\",\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) + \n  tm_view(set.zoom.limits = c(8,14))\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\nMaking a more generic category:\n\nwp_sf_nga <- wp_sf_nga %>% mutate(Category = \n                       case_when(status_clean == \"Abandoned/Decommissioned\" ~ \"Non-Functional\",\n                                 status_clean == \"Abandoned\" ~ \"Non-Functional\",\n                                 status_clean == \"Non-Functional due to dry season\" ~ \"Non-Functional\",\n                                 status_clean == \"Non-Functional\" ~ \"Non-Functional\", \n                                 status_clean == \"Functional\" ~ \"Functional\",\n                                 status_clean == \"Functional but not in use\" ~ \"Functional\",\n                                 status_clean == \"Functional but needs repair\" ~ \"Functional\",\n                                 status_clean == \"unknown\" ~ \"Unknown\"))\n\nPlot of functional and non-functional water points with new category:\n\nsf_use_s2(FALSE)\ntmap_mode('view')\ntm_shape(wp_sf_nga) +\n  tm_dots(col = \"Category\",\n          size = 0.01) + \n  tm_view(set.zoom.limits = c(8,14))\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\n\n\n4.5.2 Derive kernel density maps of functional and non-functional water points\n\n4.5.2.1 For functional water points\nComputing kernel density estimation using automatic bandwidth selection method (bw.diggle()) and default kernel:\nI think that using bw.diggle() would be a good method as based on the above plots, the pattern does not really predominantly consist of tight clusters. Furthermore, can detect a single tight cluster in the midst of random noise.\n\nkde_wp_functional_NGA_bw <- density(wp_functional_NGA_ppp,\n                        sigma = bw.diggle,\n                        edge = TRUE,\n                        kernel = \"gaussian\")\n\nPlot kernel density map:\n\nplot(kde_wp_functional_NGA_bw)\n\n\n\n\nRescaling KDE values to kilometers as the scale was very small:\n\nwp_functional_NGA_ppp.km <- rescale(wp_functional_NGA_ppp, 1000, \"km\")\n\n\nkde_wp_functional_NGA.bw <- density(wp_functional_NGA_ppp.km,\n                                    sigma = bw.diggle,\n                                    edge = TRUE,\n                                    kernel = \"gaussian\")\nplot(kde_wp_functional_NGA.bw)\n\n\n\n\nConverting KDE output into grid object:\n\ngridded_kde_wp_functional_NGA_bw <- as.SpatialGridDataFrame.im(kde_wp_functional_NGA.bw)\nspplot(gridded_kde_wp_functional_NGA_bw)\n\n\n\n\nConverting gridded output into raster:\n\nkde_wp_functional_NGA_bw_raster <- raster(gridded_kde_wp_functional_NGA_bw)\n\n\nkde_wp_functional_NGA_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -5.092436e-15, 25.49435  (min, max)\n\n\nThe summary above shows that CRS is NA hence we would need to assign projection systems.\nAssigning projection systems:\n\nprojection(kde_wp_functional_NGA_bw_raster) <- CRS(\"+init=EPSG:26392\")\nkde_wp_functional_NGA_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : +init=EPSG:26392 \nsource     : memory\nnames      : v \nvalues     : -5.092436e-15, 25.49435  (min, max)\n\n\n\n\n4.5.2.2 For non-functional water points\nComputing kernel density estimation using automatic bandwidth selection method (bw.diggle()) and default kernel:\n\nkde_wp_nonfunctional_NGA_bw <- density(wp_nonfunctional_NGA_ppp,\n                        sigma = bw.diggle,\n                        edge = TRUE,\n                        kernel = \"gaussian\")\n\nPlot kernel density map:\n\nplot(kde_wp_nonfunctional_NGA_bw)\n\n\n\n\nRescaling KDE values to kilometers as the scale was very small:\n\nwp_nonfunctional_NGA_ppp.km <- rescale(wp_nonfunctional_NGA_ppp, 1000, \"km\")\n\n\nkde_wp_nonfunctional_NGA.bw <- density(wp_nonfunctional_NGA_ppp.km,\n                                    sigma = bw.diggle,\n                                    edge = TRUE,\n                                    kernel = \"gaussian\")\nplot(kde_wp_nonfunctional_NGA.bw)\n\n\n\n\nConverting KDE output into grid object:\n\ngridded_kde_wp_nonfunctional_NGA_bw <- as.SpatialGridDataFrame.im(kde_wp_nonfunctional_NGA.bw)\nspplot(gridded_kde_wp_nonfunctional_NGA_bw)\n\n\n\n\nConverting gridded output into raster:\n\nkde_wp_nonfunctional_NGA_bw_raster <- raster(gridded_kde_wp_nonfunctional_NGA_bw)\n\n\nkde_wp_nonfunctional_NGA_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : v \nvalues     : -3.925434e-15, 20.49412  (min, max)\n\n\nThe summary above shows that CRS is NA hence we would need to assign projection systems.\nAssigning projection systems:\n\nprojection(kde_wp_nonfunctional_NGA_bw_raster) <- CRS(\"+init=EPSG:26392\")\nkde_wp_nonfunctional_NGA_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.8948485, 0.9616045  (x, y)\nextent     : 176.5032, 291.0438, 331.4347, 454.5201  (xmin, xmax, ymin, ymax)\ncrs        : +init=EPSG:26392 \nsource     : memory\nnames      : v \nvalues     : -3.925434e-15, 20.49412  (min, max)\n\n\n\n\n\n4.5.3 Display the kernel density maps on openstreetmap of Osun State, Nigeria\nKernel density map on openstreetmap of Osun State, Nigeria for functional water points:\n\ntm_basemap(\"OpenStreetMap\") +\n  tm_shape(kde_wp_functional_NGA_bw_raster) +\n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            legend.height = 0.2,\n            legend.width = 0.2,\n            main.title = \"Density Map of Functional Water Points in Osun, Nigeria\",\n            main.title.position = 'center',\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\nKernel density map on openstreetmap of Osun State, Nigeria for non-functional water points:\n\ntm_basemap(\"OpenStreetMap\") +\n  tm_shape(kde_wp_nonfunctional_NGA_bw_raster) +\n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            legend.height = 0.2,\n            legend.width = 0.2,\n            main.title = \"Density Map of Non-Functional Water Points in Osun, Nigeria\",\n            main.title.position = 'center',\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\n\n\n4.5.4 Describe the spatial patterns revealed by the kernel density maps. Highlight the advantage of kernel density map over point map\nKernel density map makes it easier for the user to notice the concentration and clusters at one glance compared to a point map. For point maps, a longer time would be needed to compare the difference between the distributions in different areas.\nPoint Map of functional water points:\n\ntmap_mode(\"plot\")\ntm_shape(NGA) + \n  tm_borders(alpha = 0.5) +\ntm_shape(wp_functional) + \n  tm_dots(col = \"red\", size = 0.05) +\n  tm_layout(main.title = \"Point Map of Functional Water Points in Osun, Nigeria\",\n            main.title.position = 'center',\n            main.title.size = 0.8,\n            frame = TRUE)\n\n\n\n\nTo find out where the higher concentrations are, we would have to particularly look at the distance between the points which is hard to note.\nKernel Density Map of functional water points:\n\ntm_basemap(\"OpenStreetMap\") +\n  tm_shape(kde_wp_functional_NGA_bw_raster) +\n  tm_raster(\"v\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"),\n            legend.height = 0.2,\n            legend.width = 0.2,\n            main.title = \"Density Map of Functional Water Points in Osun, Nigeria\",\n            main.title.position = 'center',\n            main.title.size = 0.8,\n            frame = FALSE)\n\n\n\n\nTo find out where the higher concentrations are, we can easily notice by looking at the areas that are green in colour."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#second-order-spatial-point-patterns-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#second-order-spatial-point-patterns-analysis",
    "title": "Take-Home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "4.6 Second-order Spatial Point Patterns Analysis",
    "text": "4.6 Second-order Spatial Point Patterns Analysis\nWith reference to the spatial point patterns observed in ESDA:\n\n4.6.1 Formulate the null hypothesis and alternative hypothesis and select the confidence level.\n\nH0: The distribution of water points in Osun State, Nigeria is randomly distributed\nH1: The distribution of water points in Osun State, Nigeria is not randomly distributed\nConfidence Level: 95%\nSignificance Level: 0.05\nThe null hypothesis will be rejected if p-value is smaller than the alpha value of 0.05\n\n\n\n4.6.2 Perform the test by using appropriate Second order spatial point patterns analysis technique.\nThe L function, Lest(), is a descriptive statistics generally used to determine whether points have a random, dispersed or clustered distribution pattern at certain scale. To do monte carlo simulation test, envelope() will be used.\n\nL_WP = Lest(WPNGA_ppp, correction = \"Ripley\")\nplot(L_WP, . -r ~ r,\n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\nThis is an image of the output of the above code as it takes too long to run:\n\nTo confirm the observed spatial patterns above, the hypothesis test will be conducted.\nMonte Carlo test with L-function:\n\nL_WP.csr <- envelope(WPNGA_ppp, Lest, nsim = 39)\n\nThis is an image of the output of the above code as it takes too long to run:\n\n\n\n\n\n\n\nNote\n\n\n\nNote: I have noted that the number of simulations is supposed to be 39 simulations instead of 49 simulations (which is written in my output). My output says 49 simulations as I had already ran 49 simulations before I read the note on Piazza. As of now, 12 Feb 5pm, it will take too long for me to run 39 simulations as it took me 2 days to run 49 simulations. Kindly forgive me on this output :’(\n\n\n\nplot(L_WP.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\nThis is an image of the output of the above code as it takes too long to run:\n\n\n\n4.6.3 With reference to the analysis results, draw statistical conclusions.\nConclusion: Since the observed L(r) is far above L(theo) and the envelope, it shows that the water points in Osun, Nigeria are clustered. We have enough statistical evidence at 95% confidence level to reject the null hypothesis. Hence, we reject the null hypothesis that the distribution of water points in Osun, Nigeria is randomly distributed at 95% confidence level."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-correlation-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatial-correlation-analysis",
    "title": "Take-Home Exercise 1: Application of Spatial Point Patterns Analysis to discover the geographical distribution of functional and non-function water points in Osun State, Nigeria",
    "section": "4.7 Spatial Correlation Analysis",
    "text": "4.7 Spatial Correlation Analysis\nIn this section, you are required to confirm statistically if the spatial distribution of functional and non-functional water points are independent from each other.\n\n4.7.1 Formulate the null hypothesis and alternative hypothesis and select the confidence level.\n\nH0: The distribution of functional and non-functional water points in Osun State, Nigeria is independent from each other\nH1: The distribution of functional and non-functional water points in Osun State, Nigeria is not independent from each other\nConfidence Level: 95%\nSignificance Level: 0.05\nThe null hypothesis will be rejected if p-value is smaller than the alpha value of 0.05\n\n\n\n4.7.2 Perform the test by using appropriate Second order spatial point patterns analysis technique.\nGetting the sf dataframe for functional and non-functional water points only:\n\nnew_wp_sf <- subset(wp_sf_nga, select=c(\"row_id\", \"Category\"))\nnew_wp_sf <- filter(new_wp_sf, Category %in% c(\"Functional\", \"Non-Functional\"))\n\nPreparing nearest neighbours list with st_knn(), nearest 6 neighbours for a given point geometry:\n\nnb_wp <- include_self(\n  st_knn(st_geometry(new_wp_sf), 6)\n)\n\nComputing kernel weights with st_kernel_weights(), deriving a weights list using a kernel function:\n\nwt_wp <- st_kernel_weights(nb_wp,\n                        new_wp_sf,\n                        \"gaussian\",\n                        adaptive = TRUE)\n\nCharacter list for Functional water points:\n\nFunctional <- new_wp_sf %>% filter(Category == \"Functional\")\nA_wp <- Functional$Category\n\nCharacter list for Non-Functional water points:\n\nNonFunctional <- new_wp_sf %>% filter(Category == \"Non-Functional\")\nB_wp <- NonFunctional$Category\n\nComputing Local Colocation Quotient values for each Functional water point event using the character lists, neighbours list and kernel weights with a simulation of 49 for 95% confidence level:\n\nLCLQn <- local_colocation(A_wp, B_wp, nb_wp, wt_wp, 49)\n\nJoining the output of local_colocation() to the sf dataframe of functional and non-functional water points using cbind():\n\nLCLQ_WP <- cbind(new_wp_sf, LCLQn)\n\nPlotting LCLQ values:\n\ntmap_mode(\"view\")\ntm_shape(NGA) +\n  tm_polygons() +\n  tm_shape(LCLQ_WP) +\n  tm_dots(col = \"Non.Functional\",\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) + \n  tm_view(set.zoom.limits = c(8,14))\n\n\n\n\n\n\nPlotting LCLQ p-values:\n\ntmap_mode(\"view\")\ntm_shape(NGA) +\n  tm_polygons() +\n  tm_shape(LCLQ_WP) +\n  tm_dots(col = \"p_sim_Non.Functional\",\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) + \n  tm_view(set.zoom.limits = c(8,14))\n\n\n\n\n\n\nPlotting LCLQ p-values with custom legend:\n\ntmap_mode(\"view\")\ntm_shape(NGA) +\n  tm_polygons() +\n  tm_shape(LCLQ_WP) +\n  tm_dots(col = \"p_sim_Non.Functional\",\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5,\n          breaks = c(0, 0.05, 0.1)) + \n  tm_view(set.zoom.limits = c(8,14))\n\n\n\n\n\n\nChanging back to plot mode:\n\ntmap_mode(\"plot\")\n\n\n\n4.7.3 With reference to the analysis results, draw statistical conclusions.\nConclusion: Features of the Category of Interest (Functional water points) have a colocation quotient equal to one when rounded off to 3 significant figures. This means that the proportion of features of the Neighbouring Category (Non-Functional water points) within their neighbourhood is a good representation of the proportion of categories throughout the study area. The proportion of Functional and Non-Functional water points are more or less the same.\nThere are quite a few yellow points in the plot above which shows that the p-value is less than 0.05. For these points, the actual colocation quotient for the feature is statistically significant. However, for the brown points in the plot above, where the p-value is more than 0.05, the actual colocation quotient for the feature is not statistically significant.\nAt 95% confidence level, there is not enough statistical evidence to reject the null hypothesis as the p-value is not less than 0.05 for all features of interest. Hence, the distribution of functional and non-functional water points in Osun State, Nigeria are independent from each other."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5: Advanced Spatial Point Patterns Analysis: Local Co-Location Quotient",
    "section": "",
    "text": "In this in-class exercise, you will learn how to perform Local Colocation Quotient Analysis by using convenience store data of Taiwan as a use case."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#mapping-the-geospatial-data-sets",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#mapping-the-geospatial-data-sets",
    "title": "In-class Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "1.4.2 Mapping the geospatial data sets",
    "text": "1.4.2 Mapping the geospatial data sets\n\nsf_use_s2(FALSE)\ntmap_mode('view')\ntm_shape(childcare_sf)+\n  tm_dots(alpha = 0.5, size=0.01)+\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\ntmap_mode('plot')\n\n\nalpha controls the intensity of the colour, if the value is closer to 1, the colour will be darker. if the value is closer to 0, the colour will be brighter\ntm_dots(): usually used if we don’t assign any value to the dots\ntm_bubbles(): usually used if we want to create proportional bubbles\nset.zoom.limits in tm_view(): to prevent too far zooming in and out\nset.bounds in tm_view(): set boundaries of the map to prevent it from ‘running away’"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#handling-duplicated-points",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#handling-duplicated-points",
    "title": "In-class Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "1.5.4 Handling duplicated points",
    "text": "1.5.4 Handling duplicated points\nWe can check the duplication in a ppp object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of co-indicence point, we will use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nIf we want to know how many locations have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) > 1)\n\n[1] 128\n\n\nThe output shows that there are 128 duplicated point events.\nTo view the locations of these duplicate point events, we will plot childcare data by using the code chunk below.\n\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots(alpha=0.4,\n          size=0.05)\n\n\n\n\n\n\n\ntmap_mode('plot')\n\nThere are three ways to overcome this problem. The easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering, which will add a small perturbation to the duplicate points so that they do not occupy the exact same space.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\nThe code chunk below implements the jittering approach.\n\nchildcare_ppp_jit <- rjitter(childcare_ppp,\n                             retry=TRUE,\n                             nsim=1,\n                             drop=TRUE)\n\nCheck if any duplicated point is in this geospatial data\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#creating-owin-object",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#creating-owin-object",
    "title": "In-class Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "1.5.5 Creating owin object",
    "text": "1.5.5 Creating owin object\nWhen analysing spatial point patterns, it is a good practice to confine the analysis with a geographical area like Singapore boundary. In spatstat, an object called owin is specially designed to represent this polygonal region.\nThe code chunk below is used to covert sg SpatialPolygon object into owin object of spatstat.\n\nsg_owin <- as(sg_sp, \"owin\")\n\nThe ouput object can be displayed by using plot() function\n\nplot(sg_owin)\n\n\n\n\nand summary() function of Base R\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#combining-point-events-object-and-owin-object",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html#combining-point-events-object-and-owin-object",
    "title": "In-class Exercise 4: 1st Order Spatial Point Patterns Analysis Methods",
    "section": "1.5.6 Combining point events object and owin object",
    "text": "1.5.6 Combining point events object and owin object\nIn this last step of geospatial data wrangling, we will extract childcare events that are located within Singapore by using the code chunk below.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output object combined both the point and polygon feature in one ppp object class as shown below.\n\nsummary(childcareSG_ppp)\n\nPlanar point pattern:  1545 points\nAverage intensity 2.063463e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 3 decimal places\ni.e. rounded to the nearest multiple of 0.001 units\n\nWindow: polygonal boundary\n60 separate polygons (no holes)\n            vertices        area relative.area\npolygon 1         38 1.56140e+04      2.09e-05\npolygon 2        735 4.69093e+06      6.27e-03\npolygon 3         49 1.66986e+04      2.23e-05\npolygon 4         76 3.12332e+05      4.17e-04\npolygon 5       5141 6.36179e+08      8.50e-01\npolygon 6         42 5.58317e+04      7.46e-05\npolygon 7         67 1.31354e+06      1.75e-03\npolygon 8         15 4.46420e+03      5.96e-06\npolygon 9         14 5.46674e+03      7.30e-06\npolygon 10        37 5.26194e+03      7.03e-06\npolygon 11        53 3.44003e+04      4.59e-05\npolygon 12        74 5.82234e+04      7.78e-05\npolygon 13        69 5.63134e+04      7.52e-05\npolygon 14       143 1.45139e+05      1.94e-04\npolygon 15       165 3.38736e+05      4.52e-04\npolygon 16       130 9.40465e+04      1.26e-04\npolygon 17        19 1.80977e+03      2.42e-06\npolygon 18        16 2.01046e+03      2.69e-06\npolygon 19        93 4.30642e+05      5.75e-04\npolygon 20        90 4.15092e+05      5.54e-04\npolygon 21       721 1.92795e+06      2.57e-03\npolygon 22       330 1.11896e+06      1.49e-03\npolygon 23       115 9.28394e+05      1.24e-03\npolygon 24        37 1.01705e+04      1.36e-05\npolygon 25        25 1.66227e+04      2.22e-05\npolygon 26        10 2.14507e+03      2.86e-06\npolygon 27       190 2.02489e+05      2.70e-04\npolygon 28       175 9.25904e+05      1.24e-03\npolygon 29      1993 9.99217e+06      1.33e-02\npolygon 30        38 2.42492e+04      3.24e-05\npolygon 31        24 6.35239e+03      8.48e-06\npolygon 32        53 6.35791e+05      8.49e-04\npolygon 33        41 1.60161e+04      2.14e-05\npolygon 34        22 2.54368e+03      3.40e-06\npolygon 35        30 1.08382e+04      1.45e-05\npolygon 36       327 2.16921e+06      2.90e-03\npolygon 37       111 6.62927e+05      8.85e-04\npolygon 38        90 1.15991e+05      1.55e-04\npolygon 39        98 6.26829e+04      8.37e-05\npolygon 40       415 3.25384e+06      4.35e-03\npolygon 41       222 1.51142e+06      2.02e-03\npolygon 42       107 6.33039e+05      8.45e-04\npolygon 43         7 2.48299e+03      3.32e-06\npolygon 44        17 3.28303e+04      4.38e-05\npolygon 45        26 8.34758e+03      1.11e-05\npolygon 46       177 4.67446e+05      6.24e-04\npolygon 47        16 3.19460e+03      4.27e-06\npolygon 48        15 4.87296e+03      6.51e-06\npolygon 49        66 1.61841e+04      2.16e-05\npolygon 50       149 5.63430e+06      7.53e-03\npolygon 51       609 2.62570e+07      3.51e-02\npolygon 52         8 7.82256e+03      1.04e-05\npolygon 53       976 2.33447e+07      3.12e-02\npolygon 54        55 8.25379e+04      1.10e-04\npolygon 55       976 2.33447e+07      3.12e-02\npolygon 56        61 3.33449e+05      4.45e-04\npolygon 57         6 1.68410e+04      2.25e-05\npolygon 58         4 9.45963e+03      1.26e-05\npolygon 59        46 6.99702e+05      9.35e-04\npolygon 60        13 7.00873e+04      9.36e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 748741000 square units\nFraction of frame area: 0.414"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-spatial-data",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#importing-spatial-data",
    "title": "In-class Exercise 5: Advanced Spatial Point Patterns Analysis: Local Co-Location Quotient",
    "section": "1.4.1 Importing Spatial Data",
    "text": "1.4.1 Importing Spatial Data\nThis is a polygon features data showing selected towns of Taipei city. The original data set is in geographic coordinate system and st_transform is used to the data set into projected coordinates system\n\nstudyArea <- st_read(dsn = \"data\", layer=\"study_area\") %>% st_transform(crs = 3829)\n\nReading layer `study_area' from data source \n  `C:\\valtyl\\IS415-GAA\\In-class_Ex\\In-class_Ex05\\data' using driver `ESRI Shapefile'\nSimple feature collection with 7 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 121.4836 ymin: 25.00776 xmax: 121.592 ymax: 25.09288\nGeodetic CRS:  TWD97\n\n\n\n3829 is the projection system of taiwan\ntaiwan has 2 projections, 1 locally taiwan (3829), 1 taiwan + china\n\nThis is a point features data showing selected towns of Taipei city. The original data set is in geographic coordinate system and st_transform is used to the data set into projected coordinates system\n\nstores <- st_read(dsn = \"data\", layer=\"stores\") %>% st_transform(crs = 3829)\n\nReading layer `stores' from data source \n  `C:\\valtyl\\IS415-GAA\\In-class_Ex\\In-class_Ex05\\data' using driver `ESRI Shapefile'\nSimple feature collection with 1409 features and 4 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 121.4902 ymin: 25.01257 xmax: 121.5874 ymax: 25.08557\nGeodetic CRS:  TWD97"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-the-sf-layers",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#visualising-the-sf-layers",
    "title": "In-class Exercise 5: Advanced Spatial Point Patterns Analysis: Local Co-Location Quotient",
    "section": "1.4.2 Visualising the sf layers",
    "text": "1.4.2 Visualising the sf layers\n\ntmap_mode(\"view\")\ntm_shape(studyArea) +\n  tm_polygons() +\n  tm_shape(stores) +\n  tm_dots(col = \"Name\",\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(12,16))\n\n\n\n\n\n\n\nalways plot polygons FIRST then points"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, you will learn how to compute spatial weights using R. By the end to this hands-on exercise, you will be able to:\n\nimport geospatial data using appropriate function(s) of sf package,\nimport csv file using appropriate function of readr package,\nperform relational join using appropriate join function of dplyr package,\ncompute spatial weights using appropriate functions of spdep package, and\ncalculate spatially lagged variables using appropriate functions of spdep package."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class Exercise 6: Analysing Marked Point Patterns",
    "section": "",
    "text": "1.1 Overview"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-and-loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#installing-and-loading-the-r-packages",
    "title": "In-class Exercise 6: Spatial Weights and Applications",
    "section": "1.2.1 Installing and Loading the R Packages",
    "text": "1.2.1 Installing and Loading the R Packages\n\npacman::p_load(sf, sfdep, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-geospatial-data",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-geospatial-data",
    "title": "In-class Exercise 6: Spatial Weights and Applications",
    "section": "1.3.1 Importing geospatial data",
    "text": "1.3.1 Importing geospatial data\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\valtyl\\IS415-GAA\\In-class_Ex\\In-class_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-attribute-table",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#importing-attribute-table",
    "title": "In-class Exercise 6: Spatial Weights and Applications",
    "section": "1.3.2 Importing attribute table",
    "text": "1.3.2 Importing attribute table\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#combining-both-data-frame-by-using-left-join",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#combining-both-data-frame-by-using-left-join",
    "title": "In-class Exercise 6: Spatial Weights and Applications",
    "section": "1.3.3 Combining both data frame by using left join",
    "text": "1.3.3 Combining both data frame by using left join\n\nhunan_GDPPC <- left_join(hunan, hunan2012) %>% \n  select(1:4, 7, 15)\n\n\nnote: to retain the geospatial properties, the left dataframe must be the sf dataframe (i.e. hunan)\nleft_join() is from dplyr\nusually need to specific ‘join by what?’ but there is built in intelligence to identify which column exists in both\nto know which columns to select by, need to run hunan_GDPPC without the select statement first"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#plotting-a-choropleth-map",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#plotting-a-choropleth-map",
    "title": "In-class Exercise 6: Spatial Weights and Applications",
    "section": "1.3.4 Plotting a choropleth map",
    "text": "1.3.4 Plotting a choropleth map\n\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC)+\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by district, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.0,\n            legend.height = 0.40, \n            legend.width = 0.30,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)\n\n\n\n\n\ndefault number of classes for the legend is 5\nalpha at the borders to reduce the intensity of the border\nclassification method of quantile is acceptable, can explore other methods for other cases"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "6.2.1 Getting Started",
    "text": "6.2.1 Getting Started\nBefore we get started, we need to ensure that spdep, sf, tmap and tidyverse packages of R are currently installed in your R.\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#import-shapefile-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#import-shapefile-into-r-environment",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "6.3.1 Import Shapefile into R Environment",
    "text": "6.3.1 Import Shapefile into R Environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\valtyl\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex06\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#import-csv-file-into-r-environment",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#import-csv-file-into-r-environment",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "6.3.2 Import csv file into R environment",
    "text": "6.3.2 Import csv file into R environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#performing-relational-join",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#performing-relational-join",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "6.3.3 Performing relational join",
    "text": "6.3.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 dataframe. This is performed by using left_join() of dplyr package.\n\nhunan <- left_join(hunan,hunan2012)%>%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-queen-contiguity-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-queen-contiguity-based-neighbours",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "6.5.1 Computing (QUEEN) contiguity based neighbours",
    "text": "6.5.1 Computing (QUEEN) contiguity based neighbours\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q <- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID=1 is Anxiang county.\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nYou can display the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\nBe warned: The output might cut across several pages. Save the trees if you are going to print out the report."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-rook-contiguity-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#creating-rook-contiguity-based-neighbours",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "6.5.2 Creating (ROOK) contiguity based neighbours",
    "text": "6.5.2 Creating (ROOK) contiguity based neighbours\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r <- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two area units with only one neighbours."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-contiguity-weights",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#visualising-contiguity-weights",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "6.5.3 Visualising contiguity weights",
    "text": "6.5.3 Visualising contiguity weights\nA connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs. Getting Latitude and Longitude of Polygon Centroids\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude <- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords <- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n6.5.3.1 Plotting Queen contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n6.5.3.2 Plotting Rook contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")\n\n\n\n\n\n\n6.5.3.3 Plotting both Queen and Rook contiguity based neighbours map\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\", main=\"Queen Contiguity\")\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\", main=\"Rook Contiguity\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#determine-the-cut-off-distance",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#determine-the-cut-off-distance",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "6.6.1 Determine the cut-off distance",
    "text": "6.6.1 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords <- coordinates(hunan)\nk1 <- knn2nb(knearneigh(coords))\nk1dists <- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-fixed-distance-weight-matrix",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "6.6.2 Computing fixed distance weight matrix",
    "text": "6.6.2 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 <- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nQuiz: What is the meaning of “Average number of links: 3.681818” shown above?\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp <- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n6.6.2.1 Plotting fixed distance weight matrix\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08, main=\"1st nearest neighbours\")\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6, main=\"Distance link\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-adaptive-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#computing-adaptive-distance-weight-matrix",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "6.6.3 Computing adaptive distance weight matrix",
    "text": "6.6.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothes the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 <- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nNotice that each county has six neighbours, no less no more!\n\n6.6.3.1 Plotting distance based neighbours\nWe can plot the weight matrix using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "6.7.1 Row-standardised weights matrix",
    "text": "6.7.1 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(#ofneighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q <- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbors type:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.2 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\nrswm_ids <- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-lag-with-row-standardised-weights",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-lag-with-row-standardised-weights",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "6.8.1 Spatial lag with row-standardised weights",
    "text": "6.8.1 Spatial lag with row-standardised weights\nFinally, we’ll compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag <- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecalled in the previous section, we retrieved the GDPPC of these five countries by using the code chunk below.\n\nnb1 <- wm_q[[1]]\nnb1 <- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nQuestion: Can you see the meaning of Spatial lag with row-standardized weights now?\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.\n\nlag.list <- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res <- as.data.frame(lag.list)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag GDPPC\")\nhunan <- left_join(hunan,lag.res)\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_gdppc <- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-lag-as-a-sum-of-neighbouring-values",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-lag-as-a-sum-of-neighbouring-values",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "6.8.2 Spatial lag as a sum of neighbouring values",
    "text": "6.8.2 Spatial lag as a sum of neighbouring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\nb_weights <- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 <- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res <- as.data.frame(lag_sum)\ncolnames(lag.res) <- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nFirst, let us examine the result by using the code chunk below.\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\nQuestion: Can you understand the meaning of Spatial lag as a sum of neighboring values now?\n\nNext, we will append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\n\nhunan <- left_join(hunan, lag.res)\n\nNow, We can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc <- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc <- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-window-average",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-window-average",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "6.8.3 Spatial window average",
    "text": "6.8.3 Spatial window average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs <- include.self(wm_q)\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below.\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nNow we obtain weights with nb2listw()\n\nwm_qs <- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc <- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame()\n\nlag.list.wm_qs <- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res <- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) <- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nNote: The third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan <- left_join(hunan, lag_wm_qs.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %>%\n  select(\"County\", \"lag GDPPC\", \"lag_window_avg GDPPC\") %>%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc <- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\nNote: For more effective comparison, it is advicible to use the core tmap mapping functions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-window-sum",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#spatial-window-sum",
    "title": "Hands-on Exercise 6: Spatial Weights and Applications",
    "section": "6.8.4 Spatial window sum",
    "text": "6.8.4 Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs <- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights <- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNotice that now [1] has six neighbours instead of five.\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 <- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc <- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res <- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) <- c(\"NAME_3\", \"w_sum GDPPC\")\n\nNote: The second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan <- left_join(hunan, w_sum_gdppc.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %>%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %>%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc <- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)\n\n\n\n\nNote: For more effective comparison, it is advicible to use the core tmap mapping functions."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#contiguity-neighbours-method",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#contiguity-neighbours-method",
    "title": "In-class Exercise 6: Spatial Weights and Applications",
    "section": "1.4.1 Contiguity neighbours method",
    "text": "1.4.1 Contiguity neighbours method\n\nQueen’s method\n\ncn_queen <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         .before = 1)\n\n\nmore about st_contiguity()\nneeds the geometry field of POLYGON sf dataframe\nchap 08 8.5.1, poly2nb() is used from spdep, but here we are using sfdep\ndefault is queen so dont need to state which method to use\nhunan_GDPPC is sf polygon data and has the geometry column\ncn_queen retains the sf polygon and geometry attributes\n.before=1 puts the newly created field at the first column of the table\n\n\n\nRook’s method\n\ncn_rook <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry, queen = FALSE),\n         .before = 1)\n\n\nspdep can do bishop method, sfdep cannot do bishop method\n\n\n# geo <- sf_geometry()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#contiguity-weights-queens-method",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#contiguity-weights-queens-method",
    "title": "In-class Exercise 6: Spatial Weights and Applications",
    "section": "1.7.1 Contiguity weights: Queen’s method",
    "text": "1.7.1 Contiguity weights: Queen’s method\n\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb),\n         .before = 1)\n\n\n^ this code combines 1.4.1 inside, so 1.4.1 is not needed\nthe wt column of the wm_q output is now standardised"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#contiguity-weights-rooks-method",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#contiguity-weights-rooks-method",
    "title": "In-class Exercise 6: Spatial Weights and Applications",
    "section": "1.7.2 Contiguity weights: Rook’s method",
    "text": "1.7.2 Contiguity weights: Rook’s method\n\nwm_r <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry, queen = FALSE),\n         wt = st_weights(nb),\n         .before = 1)\n\n\nqueen has to be placed before wt"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "",
    "text": "Since late December 2019, an outbreak of a novel coronavirus disease (COVID-19; previously known as 2019-nCoV) was reported in Wuhan, China, which had subsequently affected 210 countries worldwide. In general, COVID-19 is an acute resolved disease but it can also be deadly, with a 2% case fatality rate.\nThe COVID-19 vaccination in Indonesia is an ongoing mass immunisation in response to the COVID-19 pandemic in Indonesia. On 13 January 2021, the program commenced when President Joko Widodo was vaccinated at the presidential palace. In terms of total doses given, Indonesia ranks third in Asia and fifth in the world.\nAccording to wikipedia, as of 5 February 2023 at 18:00 WIB (UTC+7), 204,266,655 people had received the first dose of the vaccine and 175,131,893 people had been fully vaccinated; 69,597,474 of them had been inoculated with the booster or the third dose, while 1,585,164 had received the fourth dose. Jakarta has the highest percentage of population fully vaccinated with 103.46%, followed by Bali and Special Region of Yogyakarta with 85.45% and 83.02% respectively.\nDespite its compactness, the cumulative vaccination rate are not evenly distributed within DKI Jakarta. The question is where are the sub-districts with relatively higher number of vaccination rate and how they changed over time."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#aspatial-data",
    "title": "Take-home Exercise 2: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "3.1 Aspatial Data",
    "text": "3.1 Aspatial Data\nFor the purpose of this assignment, data from Riwayat File Vaksinasi DKI Jakarta will be used. Daily vaccination data are provides. You are only required to download either the first day of the month or last day of the month of the study period."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#geospatial-data",
    "title": "Take-home Exercise 2: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "3.2 Geospatial Data",
    "text": "3.2 Geospatial Data\nFor the purpose of this study, DKI Jakarta administration boundary 2019 will be used. The data set can be downloaded at Indonesia Geospatial portal, specifically at this page.\n\n\n\n\n\n\nNote\n\n\n\n\nThe national Projected Coordinates Systems of Indonesia is DGN95 / Indonesia TM-3 zone 54.1.\nExclude all the outer islands from the DKI Jakarta sf data frame, and\nRetain the first nine fields in the DKI Jakarta sf data frame. The ninth field JUMLAH_PEN = Total Population."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#installing-and-loading-r-packages",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#installing-and-loading-r-packages",
    "title": "Take-home Exercise 2: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "4.1 Installing and Loading R packages",
    "text": "4.1 Installing and Loading R packages\n\nsf: to import, manage, and process geospatial data\ntidyverse: a collection of packages (readr for importing delimited text file, tidyr for tidying data, dplyr for wrangling data)\ntmap: provides functions for plotting cartographic quality static point patterns maps or interactive maps\nsfdep: for spatial dependence of simple features\nreadxl: for importing Excel worksheets(.xlsx)\nplyr: for splitting data, applying functions and combining results\nkableExtra: for table customisation\nKendall: for Mann-Kendall Test\nplotly for creating interactive web-based graphs\n\n\n\nShow the code!\npacman::p_load(sf, sfdep, readxl, plyr, kableExtra, tmap, Kendall, plotly, tidyverse)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling-geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling-geospatial-data",
    "title": "Take-home Exercise 2: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "4.2 Data Wrangling: Geospatial Data",
    "text": "4.2 Data Wrangling: Geospatial Data\n\n4.2.1 Importing the Geospatial Data\n\n\nShow the code!\n# bd stands for \"batas desa\", translated as \"village boundary\"\n# reads in geospatial data and stores into bd_jakarta dataframe\nbd_jakarta <- st_read(dsn = \"data/geospatial\",\n                       layer = \"BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA\")\n\n\nReading layer `BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA' from data source \n  `C:\\valtyl\\IS415-GAA\\Take-home_Ex\\Take-home_Ex02\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 269 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.3831 ymin: -6.370815 xmax: 106.9728 ymax: -5.184322\nGeodetic CRS:  WGS 84\n\n\nFrom the output message, we learn that:\n\nGeometry type: Multipolygon\n269 features, 161 fields\nAssigned CRS is WGS 84, ‘World Geodetic System 1984’ (This is not appropriate as this geospatial dataset is Indonesian-specific hence we will have to use the national CRS of Indonesia, DGN 95, ‘Datum Geodesi Nasional 1995’. We will change this later on.) (Refer to note in section 3.2)\n\n\n\n4.2.2 Data Pre-Processing\nBefore visualising our data, we need to check if there are:\n\ninvalid geometries\nor missing values\n\nThese can impact future calculations and representations\n\n4.2.2.1 Invalid Geometries\nChecking for invalid geometries:\n\n\nShow the code!\n# function breakdown:\n# the st_is_valid function checks whether a geometry is valid\n# which returns the indices of certain values based on logical conditions\n# length returns the length of data objects\n\n# checks for the number of geometries that are NOT valid\nlength(which(st_is_valid(bd_jakarta) == FALSE))\n\n\n[1] 0\n\n\nThe message output shows that there are no invalid geometries.\n\n\n4.2.2.2 Missing Values\n\n\nShow the code!\n# the rowSums(is.na(bd_jakarta))!=0 checks every row if there are NA values, returning TRUE or FALSE\n# the bd_jakarta 'wrapper' prints said rows that contain NA values\nbd_jakarta[rowSums(is.na(bd_jakarta))!=0,]\n\n\nSimple feature collection with 2 features and 161 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 106.8412 ymin: -6.154036 xmax: 106.8612 ymax: -6.144973\nGeodetic CRS:  WGS 84\n    OBJECT_ID KODE_DESA             DESA   KODE    PROVINSI KAB_KOTA KECAMATAN\n243     25645  31888888     DANAU SUNTER 318888 DKI JAKARTA     <NA>      <NA>\n244     25646  31888888 DANAU SUNTER DLL 318888 DKI JAKARTA     <NA>      <NA>\n    DESA_KELUR JUMLAH_PEN JUMLAH_KK LUAS_WILAY KEPADATAN PERPINDAHA JUMLAH_MEN\n243       <NA>          0         0          0         0          0          0\n244       <NA>          0         0          0         0          0          0\n    PERUBAHAN WAJIB_KTP SILAM KRISTEN KHATOLIK HINDU BUDHA KONGHUCU KEPERCAYAA\n243         0         0     0       0        0     0     0        0          0\n244         0         0     0       0        0     0     0        0          0\n    PRIA WANITA BELUM_KAWI KAWIN CERAI_HIDU CERAI_MATI U0 U5 U10 U15 U20 U25\n243    0      0          0     0          0          0  0  0   0   0   0   0\n244    0      0          0     0          0          0  0  0   0   0   0   0\n    U30 U35 U40 U45 U50 U55 U60 U65 U70 U75 TIDAK_BELU BELUM_TAMA TAMAT_SD SLTP\n243   0   0   0   0   0   0   0   0   0   0          0          0        0    0\n244   0   0   0   0   0   0   0   0   0   0          0          0        0    0\n    SLTA DIPLOMA_I DIPLOMA_II DIPLOMA_IV STRATA_II STRATA_III BELUM_TIDA\n243    0         0          0          0         0          0          0\n244    0         0          0          0         0          0          0\n    APARATUR_P TENAGA_PEN WIRASWASTA PERTANIAN NELAYAN AGAMA_DAN PELAJAR_MA\n243          0          0          0         0       0         0          0\n244          0          0          0         0       0         0          0\n    TENAGA_KES PENSIUNAN LAINNYA GENERATED KODE_DES_1 BELUM_ MENGUR_ PELAJAR_\n243          0         0       0      <NA>       <NA>      0       0        0\n244          0         0       0      <NA>       <NA>      0       0        0\n    PENSIUNA_1 PEGAWAI_ TENTARA KEPOLISIAN PERDAG_ PETANI PETERN_ NELAYAN_1\n243          0        0       0          0       0      0       0         0\n244          0        0       0          0       0      0       0         0\n    INDUSTR_ KONSTR_ TRANSP_ KARYAW_ KARYAW1 KARYAW1_1 KARYAW1_12 BURUH BURUH_\n243        0       0       0       0       0         0          0     0      0\n244        0       0       0       0       0         0          0     0      0\n    BURUH1 BURUH1_1 PEMBANT_ TUKANG TUKANG_1 TUKANG_12 TUKANG__13 TUKANG__14\n243      0        0        0      0        0         0          0          0\n244      0        0        0      0        0         0          0          0\n    TUKANG__15 TUKANG__16 TUKANG__17 PENATA PENATA_ PENATA1_1 MEKANIK SENIMAN_\n243          0          0          0      0       0         0       0        0\n244          0          0          0      0       0         0       0        0\n    TABIB PARAJI_ PERANCA_ PENTER_ IMAM_M PENDETA PASTOR WARTAWAN USTADZ JURU_M\n243     0       0        0       0      0       0      0        0      0      0\n244     0       0        0       0      0       0      0        0      0      0\n    PROMOT ANGGOTA_ ANGGOTA1 ANGGOTA1_1 PRESIDEN WAKIL_PRES ANGGOTA1_2\n243      0        0        0          0        0          0          0\n244      0        0        0          0        0          0          0\n    ANGGOTA1_3 DUTA_B GUBERNUR WAKIL_GUBE BUPATI WAKIL_BUPA WALIKOTA WAKIL_WALI\n243          0      0        0          0      0          0        0          0\n244          0      0        0          0      0          0        0          0\n    ANGGOTA1_4 ANGGOTA1_5 DOSEN GURU PILOT PENGACARA_ NOTARIS ARSITEK AKUNTA_\n243          0          0     0    0     0          0       0       0       0\n244          0          0     0    0     0          0       0       0       0\n    KONSUL_ DOKTER BIDAN PERAWAT APOTEK_ PSIKIATER PENYIA_ PENYIA1 PELAUT\n243       0      0     0       0       0         0       0       0      0\n244       0      0     0       0       0         0       0       0      0\n    PENELITI SOPIR PIALAN PARANORMAL PEDAGA_ PERANG_ KEPALA_ BIARAW_ WIRASWAST_\n243        0     0      0          0       0       0       0       0          0\n244        0     0      0          0       0       0       0       0          0\n    LAINNYA_12 LUAS_DESA KODE_DES_3 DESA_KEL_1 KODE_12\n243          0         0       <NA>       <NA>       0\n244          0         0       <NA>       <NA>       0\n                          geometry\n243 MULTIPOLYGON (((106.8612 -6...\n244 MULTIPOLYGON (((106.8504 -6...\n\n\nThe message output shows that there are 2 rows with missing values for the columns KAB_KOTA (City), KECAMATAN (District), DESA_KELUR (Village) and a few more others. We can also see that there are way too many columns, and we will remove the unnecessary columns later on.\nTo clean up, we will remove the rows that have NA values in DESA_KELUR since we are interested in the dataset on a sub-district level:\n\n\nShow the code!\n# removes rows that have an NA value in DESA_KELUR\n# in context of this data, we can use other columns, such as KAB_KOTA or KECAMATAN\n# but since we're looking at this on a sub-district level, DESA_KELUR seemed most appropriate\nbd_jakarta <- na.omit(bd_jakarta,c(\"DESA_KELUR\"))\n\n\n\n\n4.2.2.3 Verifying & Transforming the Coordinate System\nChecking the CRS of bd_jakarta:\n\n\nShow the code!\n# retrieves the coordinate system of bd_jakarta\nst_crs(bd_jakarta)\n\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nAs mentioned in section 4.2.1, WGS 84 is not appropriate and we should change it to DGN 95:\n\n\nShow the code!\n# transforms the CRS to DGN95, ESPG code 23845\nbd_jakarta <- st_transform(bd_jakarta, 23845)\n\n\nChecking if the CRS has been properly assigned:\n\n\nShow the code!\nst_crs(bd_jakarta)\n\n\nCoordinate Reference System:\n  User input: EPSG:23845 \n  wkt:\nPROJCRS[\"DGN95 / Indonesia TM-3 zone 54.1\",\n    BASEGEOGCRS[\"DGN95\",\n        DATUM[\"Datum Geodesi Nasional 1995\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4755]],\n    CONVERSION[\"Indonesia TM-3 zone 54.1\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",139.5,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9999,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",200000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",1500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"easting (X)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"northing (Y)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre.\"],\n        AREA[\"Indonesia - onshore east of 138°E.\"],\n        BBOX[-9.19,138,-1.49,141.01]],\n    ID[\"EPSG\",23845]]\n\n\nThe transformation is done.\n\n\n\n4.2.3 Data Visualisation\nFirst, we will visualise the geometry of Jakarta:\n\n\nShow the code!\nplot(st_geometry(bd_jakarta))\n\n\n\n\n\nFrom the output, it shows that bd_jakarta includes the main land but also many other outer islands that we are not relevant to our analysis in this assignment. (Refer to note in section 3.2)\nTo remove the outer islands, we should look at how unique values at the City level, KAB_KOTA:\n\n\nShow the code!\n# outputs unique values of the KAB_KOTA field\nunique(bd_jakarta$\"KAB_KOTA\")\n\n\n[1] \"JAKARTA BARAT\"    \"JAKARTA PUSAT\"    \"KEPULAUAN SERIBU\" \"JAKARTA UTARA\"   \n[5] \"JAKARTA TIMUR\"    \"JAKARTA SELATAN\" \n\n\nFrom the output, the cities within Jakarta have a JAKARTA prefix, while KEPULAUAN SERIBU (which means ‘Thousand Islands’) refers to the outer islands. Visualising KAB_KOTA will confirm this:\n\n\nShow the code!\n# with bd_jakarta as the input data (setting the 'base')\n# draw the KAB_KOTA (city) polygons\n# essentially shades the map according to the city divisions\ntm_shape(bd_jakarta) + \n  tm_polygons(\"KAB_KOTA\")\n\n\n\n\n\nThe above visualisation proves that KEPULAUAN SERIBU are the outer islands to remove:\n\n\nShow the code!\n# filters out the outer islands by accepting only if the value of KAB_KOTA is NOT KEPULAUAN SERIBU\nbd_jakarta <- filter(bd_jakarta, KAB_KOTA != \"KEPULAUAN SERIBU\")\n\n\n\n\n4.2.4 Retaining relavant columns only\nAs seen in section 4.2.2.2, there were many unnecessary and irrelevant columns that we could remove. (Refer to note in section 3.2)\nRetaining the relevant fields (first 9 fields) for our analysis:\n\n\nShow the code!\n# filters out other fields by accepting only the first 9 fields\nbd_jakarta <- bd_jakarta[, 0:9]\n\n\n\n\n4.2.5 Renaming the Columns in English\nFor ease of comprehension:\n\n\nShow the code!\n# with reference to: https://www.codegrepper.com/code-examples/r/rename+column+name+in+r\n# renames the columns in the style New_Name = OLD_NAME\nbd_jakarta <- bd_jakarta %>% \n  dplyr::rename(\n    Object_ID=OBJECT_ID,\n    Province=PROVINSI, \n    City=KAB_KOTA, \n    District=KECAMATAN, \n    Village_Code=KODE_DESA, \n    Village=DESA, \n    Sub_District=DESA_KELUR,\n    Code=KODE, \n    Total_Population=JUMLAH_PEN\n    )\n\n\n\n\n4.2.6 Brief EDA of Geospatial Data\nSummary of bd_jakarta:\n\n\nShow the code!\n# reveals the data type of all fields + some values\nglimpse(bd_jakarta)\n\n\nRows: 261\nColumns: 10\n$ Object_ID        <dbl> 25477, 25478, 25397, 25400, 25390, 25391, 25394, 2538…\n$ Village_Code     <chr> \"3173031006\", \"3173031007\", \"3171031003\", \"3171031006…\n$ Village          <chr> \"KEAGUNGAN\", \"GLODOK\", \"HARAPAN MULIA\", \"CEMPAKA BARU…\n$ Code             <dbl> 317303, 317303, 317103, 317103, 317102, 317102, 31710…\n$ Province         <chr> \"DKI JAKARTA\", \"DKI JAKARTA\", \"DKI JAKARTA\", \"DKI JAK…\n$ City             <chr> \"JAKARTA BARAT\", \"JAKARTA BARAT\", \"JAKARTA PUSAT\", \"J…\n$ District         <chr> \"TAMAN SARI\", \"TAMAN SARI\", \"KEMAYORAN\", \"KEMAYORAN\",…\n$ Sub_District     <chr> \"KEAGUNGAN\", \"GLODOK\", \"HARAPAN MULIA\", \"CEMPAKA BARU…\n$ Total_Population <dbl> 21609, 9069, 29085, 41913, 15793, 33383, 35906, 21828…\n$ geometry         <MULTIPOLYGON [m]> MULTIPOLYGON (((-3626874 69..., MULTIPOL…\n\n\nNumber of unique sub-districts:\n\n\nShow the code!\nlength(unique(bd_jakarta$\"Sub_District\"))\n\n\n[1] 261\n\n\nNumber of unique districts:\n\n\nShow the code!\nlength(unique(bd_jakarta$\"District\"))\n\n\n[1] 42\n\n\nNumber of unique cities:\n\n\nShow the code!\nlength(unique(bd_jakarta$\"City\"))\n\n\n[1] 5\n\n\nThere are 261 unique sub-districts, 42 unique districts and 5 unique cities. The maximum number of categories for mapping with tmap is 30. Even though max.categories can be adjusted in tmap_options, too many segmented sections on a single map will not provide much insights hence we should do the EDA at ‘City’ level:\n\n\nShow the code!\n# shades the map according to the city divisions\ntm_shape(bd_jakarta) + \n  tm_polygons(\"City\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling-aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#data-wrangling-aspatial-data",
    "title": "Take-home Exercise 2: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "4.3 Data Wrangling: Aspatial Data",
    "text": "4.3 Data Wrangling: Aspatial Data\n\n4.3.1 Pre-Importing EDA\nFor the aspatial data, I have decided to download the data for last day of every month from July 2021 to June 2022. However, the last day of Feb 2022 provided on the website in section 3.1 is 27 Feb instead of 28 Feb.\nThis section is to check for any discrepancies in each .xlsx file in the ‘data/aspatial’ folder by performing EDA:\n\n\nShow the code!\njul2021 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Juli 2021).xlsx\")\nglimpse(jul2021)\n\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 4441501, 12333, 13875, 18…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 4499710, 11614, 15506, 10…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 1663218, 4181, 4798, 3658…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 6162928, 15795, 20304, 14…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 502579, 1230, 2012, 865, …\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 440910, 1069, 1729, 701, …\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 943489, 2299, 3741, 1566,…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1052883, 3333, 2586, 2837…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 666009, 2158, 1374, 1761,…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 1718892, 5491, 3960, 4598…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 56660, 78, 122, 174, 71, …\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 38496, 51, 84, 106, 57, 7…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 95156, 129, 206, 280, 128…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 76397, 101, 90, 215, 73, …\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 67484, 91, 82, 192, 67, 3…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 143881, 192, 172, 407, 14…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 2279398, 5506, 9012, 5408…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 446028, 789, 1519, 897, 4…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 2725426, 6295, 10531, 630…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 531793, 1366, 1684, 1261,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 4291, 23, 10, 1, 1, 8, 6,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 536084, 1389, 1694, 1262,…\n\n\nThe above output shows that there are no duplicates for the columns.\nBelow, similar codes were used to check for the other excel files. There are no duplicates in the rest of the files. Doing a quick comparison, we can notice that the excel files for July 2021 to February 2022 have 27 columns while those for March 2022 to June 2022 have 34 columns.\n\n\nShow the code!\naug2021 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Agustus 2021).xlsx\")\nglimpse(aug2021)\n\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 3277484, 9191, 10400, 125…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 5663727, 14756, 18981, 16…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 3412906, 8935, 10470, 776…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 9076633, 23691, 29451, 24…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 535001, 1300, 2104, 1043,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 468678, 1140, 1849, 780, …\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1003679, 2440, 3953, 1823…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1393352, 4194, 3643, 4293…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1007921, 3135, 2519, 2548…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 2401273, 7329, 6162, 6841…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 65340, 89, 137, 188, 80, …\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 53995, 77, 119, 163, 71, …\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 119335, 166, 256, 351, 15…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 79502, 106, 92, 229, 78, …\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 72588, 96, 83, 203, 74, 3…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 152090, 202, 175, 432, 15…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 2941837, 7385, 11033, 872…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 1377349, 3277, 4541, 3010…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 4319186, 10662, 15574, 11…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 648695, 1682, 1972, 2090,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 432375, 1210, 1359, 1062,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1081070, 2892, 3331, 3152…\n\n\nShow the code!\nsep2021 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (30 September 2021).xlsx\")\nglimpse(sep2021)\n\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 2235772, 6688, 7581, 8708…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 6705439, 17259, 21800, 20…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 5171697, 13376, 16438, 14…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 11877136, 30635, 38238, 3…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 587215, 1417, 2270, 1263,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 518944, 1263, 2033, 988, …\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1106159, 2680, 4303, 2251…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1468382, 3938, 3883, 4540…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1305200, 3454, 3356, 3903…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 2773582, 7392, 7239, 8443…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 84049, 158, 173, 248, 100…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 75657, 148, 157, 229, 91,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 159706, 306, 330, 477, 19…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 112296, 140, 135, 329, 11…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 104381, 124, 125, 300, 11…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 216677, 264, 260, 629, 23…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 3677943, 9564, 12969, 114…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 2548057, 6788, 8944, 7023…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 6226000, 16352, 21913, 18…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 775554, 2042, 2370, 2510,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 619458, 1599, 1823, 1969,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1395012, 3641, 4193, 4479…\n\n\nShow the code!\noct2021 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Oktober 2021).xlsx\")\nglimpse(oct2021)\n\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1880524, 5991, 6557, 7586…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7060687, 17956, 22824, 21…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 5729001, 14504, 18185, 16…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 12789688, 32460, 41009, 3…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 608940, 1447, 2336, 1322,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 543483, 1296, 2104, 1104,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1152423, 2743, 4440, 2426…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1484292, 3972, 3917, 4595…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1349105, 3555, 3465, 4072…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 2833397, 7527, 7382, 8667…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 86323, 165, 175, 259, 101…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 81721, 160, 168, 245, 96,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 168044, 325, 343, 504, 19…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 113911, 140, 136, 338, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 107383, 128, 128, 310, 12…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 221294, 268, 264, 648, 24…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 3948804, 10101, 13744, 12…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 2949023, 7567, 10266, 849…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 6897827, 17668, 24010, 20…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 818417, 2131, 2516, 2672,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 698286, 1798, 2054, 2220,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1516703, 3929, 4570, 4892…\n\n\nShow the code!\nnov2021 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (30 November 2021).xlsx\")\nglimpse(nov2021)\n\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1723821, 5527, 5986, 6802…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7217390, 18420, 23395, 22…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6172636, 15466, 19404, 18…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 13390026, 33886, 42799, 4…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 624751, 1473, 2391, 1385,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 571830, 1351, 2192, 1224,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1196581, 2824, 4583, 2609…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1487961, 3980, 3926, 4614…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1369705, 3601, 3516, 4146…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 2857666, 7581, 7442, 8760…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 86710, 169, 176, 259, 101…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 83506, 163, 172, 252, 98,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 170216, 332, 348, 511, 19…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 114292, 140, 135, 341, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 109221, 128, 128, 323, 12…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 223513, 268, 263, 664, 24…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4069550, 10473, 14182, 12…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3304266, 8329, 11215, 978…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 7373816, 18802, 25397, 22…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 834126, 2185, 2585, 2733,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 734108, 1894, 2181, 2355,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1568234, 4079, 4766, 5088…\n\n\nShow the code!\ndec2021 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Desember 2021).xlsx\")\nglimpse(dec2021)\n\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1623736, 5062, 5626, 6335…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7317475, 18885, 23755, 22…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6370175, 15996, 20026, 18…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 13687650, 34881, 43781, 4…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 634516, 1520, 2427, 1418,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 586624, 1375, 2247, 1294,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1221140, 2895, 4674, 2712…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1485857, 3981, 3922, 4603…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1372180, 3607, 3521, 4153…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 2858037, 7588, 7443, 8756…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 86905, 169, 176, 260, 101…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 83995, 164, 174, 253, 99,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 170900, 333, 350, 513, 20…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 114612, 140, 136, 345, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 110119, 128, 129, 327, 12…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 224731, 268, 265, 672, 24…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4150113, 10841, 14450, 13…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3467714, 8782, 11715, 104…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 7617827, 19623, 26165, 23…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 845472, 2234, 2644, 2783,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 749543, 1940, 2240, 2401,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1595015, 4174, 4884, 5184…\n\n\nShow the code!\njan2022 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Januari 2022).xlsx\")\nglimpse(jan2022)\n\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1538221, 4647, 5388, 5967…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7402990, 19300, 23993, 23…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6516678, 16477, 20463, 19…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 13919668, 35777, 44456, 4…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 644280, 1564, 2459, 1446,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 598309, 1399, 2291, 1327,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1242589, 2963, 4750, 2773…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1478564, 3971, 3900, 4592…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1369268, 3604, 3506, 4158…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 2847832, 7575, 7406, 8750…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 88073, 177, 178, 262, 102…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 85942, 171, 179, 260, 99,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 174015, 348, 357, 522, 20…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 115123, 140, 135, 348, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 111364, 130, 130, 331, 12…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 226487, 270, 265, 679, 24…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4215232, 11158, 14620, 13…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3579348, 9173, 12024, 109…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 7794580, 20331, 26644, 24…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 861718, 2290, 2701, 2840,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 772447, 2000, 2333, 2488,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1634165, 4290, 5034, 5328…\n\n\nShow the code!\nfeb2022 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (27 Februari 2022).xlsx\")\nglimpse(feb2022)\n\n\nRows: 268\nColumns: 27\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1517196, 4592, 5319, 5903…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7424015, 19355, 24062, 23…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6590380, 16687, 20738, 19…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 14014395, 36042, 44800, 4…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 646481, 1567, 2465, 1451,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 604751, 1418, 2336, 1348,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1251232, 2985, 4801, 2799…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1478545, 3971, 3899, 4590…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1371190, 3614, 3512, 4161…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 2849735, 7585, 7411, 8751…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 88088, 178, 178, 262, 102…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 86046, 171, 179, 260, 99,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 174134, 349, 357, 522, 20…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 115186, 140, 135, 348, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 111623, 130, 130, 331, 12…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 226809, 270, 265, 679, 24…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4232389, 11200, 14670, 13…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3638187, 9327, 12227, 111…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 7870576, 20527, 26897, 24…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 863326, 2299, 2715, 2845,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 778583, 2027, 2354, 2512,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1641909, 4326, 5069, 5357…\n\n\nShow the code!\nmar2022 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Maret 2022).xlsx\")\nglimpse(mar2022)\n\n\nRows: 268\nColumns: 34\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1482471, 4522, 5186, 5780…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7458740, 19425, 24195, 23…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6682911, 16909, 21000, 20…\n$ `JUMLAH\\r\\nDOSIS 3`                          <dbl> 1836511, 3934, 6122, 4124…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 15978162, 40268, 51317, 4…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 649601, 1574, 2475, 1457,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 610754, 1433, 2350, 1366,…\n$ `LANSIA\\r\\nDOSIS 3`                          <dbl> 610754, 1433, 2350, 1366,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1533150, 3545, 6052, 3283…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1481237, 3980, 3910, 4604…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1375686, 3634, 3523, 4175…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 3`                  <dbl> 200536, 579, 660, 453, 24…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 3057459, 8193, 8093, 9232…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 88150, 178, 178, 262, 102…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 86122, 173, 179, 260, 99,…\n$ `GOTONG ROYONG\\r\\nDOSIS 3`                   <dbl> 19460, 22, 53, 57, 19, 41…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 193732, 373, 410, 579, 22…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 115527, 140, 135, 348, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 112027, 130, 130, 331, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 3`                <dbl> 84640, 103, 94, 239, 83, …\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 312194, 373, 359, 918, 32…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4258776, 11250, 14773, 13…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3715052, 9502, 12436, 114…\n$ `TAHAPAN 3\\r\\nDOSIS 3`                       <dbl> 1248211, 2671, 4048, 2891…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 9222039, 23423, 31257, 28…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 865449, 2303, 2724, 2851,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 783270, 2037, 2382, 2541,…\n$ `REMAJA\\r\\nDOSIS 3`                          <dbl> 10869, 21, 40, 24, 7, 28,…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1659588, 4361, 5146, 5416…\n\n\nShow the code!\napr2022 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (30 April 2022).xlsx\")\nglimpse(apr2022)\n\n\nRows: 268\nColumns: 34\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1453423, 4449, 5101, 5699…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7487788, 19498, 24280, 23…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6727002, 17027, 21134, 20…\n$ `JUMLAH\\r\\nDOSIS 3`                          <dbl> 2720796, 6568, 8915, 6491…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 16935586, 43093, 54329, 5…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 651696, 1579, 2481, 1458,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 613044, 1441, 2360, 1376,…\n$ `LANSIA\\r\\nDOSIS 3`                          <dbl> 613044, 1441, 2360, 1376,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1599248, 3750, 6301, 3425…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1483630, 3983, 3920, 4611…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1378338, 3640, 3529, 4187…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 3`                  <dbl> 366145, 1099, 1096, 941, …\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 3228113, 8722, 8545, 9739…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 88200, 178, 178, 262, 102…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 86184, 173, 179, 260, 99,…\n$ `GOTONG ROYONG\\r\\nDOSIS 3`                   <dbl> 38179, 71, 95, 120, 41, 7…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 212563, 422, 452, 642, 24…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 115623, 140, 135, 348, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 112253, 130, 130, 333, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 3`                <dbl> 89811, 109, 105, 259, 91,…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 317687, 379, 370, 940, 33…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4281576, 11308, 14842, 13…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3750893, 9596, 12545, 116…\n$ `TAHAPAN 3\\r\\nDOSIS 3`                       <dbl> 1866526, 4503, 6084, 4519…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 9898995, 25407, 33471, 29…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 867063, 2310, 2724, 2858,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 786290, 2047, 2391, 2557,…\n$ `REMAJA\\r\\nDOSIS 3`                          <dbl> 25627, 56, 75, 61, 19, 71…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1678980, 4413, 5190, 5476…\n\n\nShow the code!\nmay2022 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (31 Mei 2022).xlsx\")\nglimpse(may2022)\n\n\nRows: 268\nColumns: 34\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1445540, 4440, 5084, 5676…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7495671, 19507, 24297, 23…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6743764, 17077, 21182, 20…\n$ `JUMLAH\\r\\nDOSIS 3`                          <dbl> 2885301, 7022, 9484, 7030…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 17124736, 43606, 54963, 5…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 652411, 1580, 2482, 1461,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 614259, 1442, 2367, 1378,…\n$ `LANSIA\\r\\nDOSIS 3`                          <dbl> 614259, 1442, 2367, 1378,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1615382, 3804, 6385, 3468…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1483896, 3982, 3920, 4612…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1379577, 3645, 3534, 4192…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 3`                  <dbl> 395504, 1185, 1185, 1033,…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 3258977, 8812, 8639, 9837…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 88234, 179, 178, 262, 102…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 86232, 173, 179, 260, 99,…\n$ `GOTONG ROYONG\\r\\nDOSIS 3`                   <dbl> 43402, 100, 111, 132, 53,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 217868, 452, 468, 654, 25…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 115658, 140, 135, 348, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 112327, 130, 131, 333, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 3`                <dbl> 91061, 110, 108, 262, 93,…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 319046, 380, 374, 943, 33…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4287820, 11318, 14850, 13…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3763773, 9632, 12577, 116…\n$ `TAHAPAN 3\\r\\nDOSIS 3`                       <dbl> 1975879, 4777, 6455, 4893…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 10027472, 25727, 33882, 3…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 867652, 2308, 2732, 2858,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 787596, 2055, 2394, 2562,…\n$ `REMAJA\\r\\nDOSIS 3`                          <dbl> 30743, 68, 89, 81, 26, 80…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1685991, 4431, 5215, 5501…\n\n\nShow the code!\njun2022 <- read_xlsx(\"data/aspatial/Data Vaksinasi Berbasis Kelurahan (30 Juni 2022).xlsx\")\nglimpse(jun2022)\n\n\nRows: 268\nColumns: 34\n$ `KODE KELURAHAN`                             <chr> NA, \"3172051003\", \"317304…\n$ `WILAYAH KOTA`                               <chr> NA, \"JAKARTA UTARA\", \"JAK…\n$ KECAMATAN                                    <chr> NA, \"PADEMANGAN\", \"TAMBOR…\n$ KELURAHAN                                    <chr> \"TOTAL\", \"ANCOL\", \"ANGKE\"…\n$ SASARAN                                      <dbl> 8941211, 23947, 29381, 29…\n$ `BELUM VAKSIN`                               <dbl> 1431393, 4402, 5041, 5632…\n$ `JUMLAH\\r\\nDOSIS 1`                          <dbl> 7509818, 19545, 24340, 23…\n$ `JUMLAH\\r\\nDOSIS 2`                          <dbl> 6756584, 17106, 21213, 20…\n$ `JUMLAH\\r\\nDOSIS 3`                          <dbl> 3031594, 7369, 10086, 739…\n$ `TOTAL VAKSIN\\r\\nDIBERIKAN`                  <dbl> 17297996, 44020, 55639, 5…\n$ `LANSIA\\r\\nDOSIS 1`                          <dbl> 653401, 1582, 2483, 1466,…\n$ `LANSIA\\r\\nDOSIS 2`                          <dbl> 615341, 1447, 2368, 1382,…\n$ `LANSIA\\r\\nDOSIS 3`                          <dbl> 615341, 1447, 2368, 1382,…\n$ `LANSIA TOTAL \\r\\nVAKSIN DIBERIKAN`          <dbl> 1630553, 3848, 6464, 3495…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 1`                  <dbl> 1484892, 3982, 3924, 4613…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 2`                  <dbl> 1380501, 3646, 3536, 4195…\n$ `PELAYAN PUBLIK\\r\\nDOSIS 3`                  <dbl> 420795, 1244, 1265, 1104,…\n$ `PELAYAN PUBLIK TOTAL\\r\\nVAKSIN DIBERIKAN`   <dbl> 3286188, 8872, 8725, 9912…\n$ `GOTONG ROYONG\\r\\nDOSIS 1`                   <dbl> 88277, 180, 178, 262, 102…\n$ `GOTONG ROYONG\\r\\nDOSIS 2`                   <dbl> 86277, 174, 179, 260, 99,…\n$ `GOTONG ROYONG\\r\\nDOSIS 3`                   <dbl> 45143, 104, 115, 135, 56,…\n$ `GOTONG ROYONG TOTAL\\r\\nVAKSIN DIBERIKAN`    <dbl> 219697, 458, 472, 657, 25…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 1`                <dbl> 115697, 140, 135, 348, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 2`                <dbl> 112383, 130, 131, 333, 12…\n$ `TENAGA KESEHATAN\\r\\nDOSIS 3`                <dbl> 91999, 113, 108, 266, 95,…\n$ `TENAGA KESEHATAN TOTAL\\r\\nVAKSIN DIBERIKAN` <dbl> 320079, 383, 374, 947, 33…\n$ `TAHAPAN 3\\r\\nDOSIS 1`                       <dbl> 4298906, 11352, 14884, 13…\n$ `TAHAPAN 3\\r\\nDOSIS 2`                       <dbl> 3773713, 9652, 12601, 116…\n$ `TAHAPAN 3\\r\\nDOSIS 3`                       <dbl> 2075349, 5009, 6872, 5151…\n$ `TAHAPAN 3 TOTAL\\r\\nVAKSIN DIBERIKAN`        <dbl> 10147968, 26013, 34357, 3…\n$ `REMAJA\\r\\nDOSIS 1`                          <dbl> 868645, 2309, 2736, 2862,…\n$ `REMAJA\\r\\nDOSIS 2`                          <dbl> 788369, 2057, 2398, 2564,…\n$ `REMAJA\\r\\nDOSIS 3`                          <dbl> 36497, 80, 113, 95, 29, 1…\n$ `REMAJA TOTAL\\r\\nVAKSIN DIBERIKAN`           <dbl> 1693511, 4446, 5247, 5521…\n\n\n\n\n4.3.2 Creating an Aspatial Data Pre-processing Function\nFirstly, here are some requirements for our aspatial data:\nColumns of interest:\n\nKODE KELURAHAN: sub-district code\nKELURAHAN: sub-district\nSASARAN: target\nBELUM VAKSIN: not yet vaccinated\n\nWe need to create an extra Date column that has the month and year of the observation. Note that the files have a naming convention “Data Vaksinasi Berbasis Kelurahan (DD Month YYYY).xlsx”\n\n\nShow the code!\n# takes in an aspatial data filepath and returns a processed output\naspatial_preprocess <- function(filepath){\n  # we use [-1,] to remove the first row of the file as the first row is a subheader row\n  result_file <- read_xlsx(filepath)[-1,]\n  \n  # Create the Date Column\n  # the format of our files is: Data Vaksinasi Berbasis Kelurahan (DD Month YYYY)\n  # while the start is technically \"(\", \"(\" is part of a regular expression and leads to a warning message, so we'll use \"Kelurahan\" instead. The [[1]] refers to the first element in the list.\n  # we're loading it as DD-Month-YYYY format\n  # to get the end index, we use the length of the filepath - 6 \n  # as such, the most relevant functions are substr (returns a substring) and either str_locate (returns location of substring as an integer matrix) or gregexpr (returns a list of locations of substring)\n  # reference https://stackoverflow.com/questions/14249562/find-the-location-of-a-character-in-string\n  startpoint <- gregexpr(pattern=\"Kelurahan\", filepath)[[1]] + 11\n  \n  result_file$Date <- substr(filepath, startpoint, nchar(filepath)-6)\n  \n  # Retain the Relevant Columns\n  result_file <- result_file %>% \n    select(\"Date\", \n           \"KODE KELURAHAN\", \n           \"KELURAHAN\", \n           \"SASARAN\", \n           \"BELUM VAKSIN\")\n  return(result_file)\n}\n\n\n\n\n4.3.3 Importing the Aspatial Data\nFeeding Files into the aspatial_preprocess function using list.files() and lapply() to apply a function to all elements in the list:\n\n\nShow the code!\n# in the folder 'data/aspatial', find files with the extension '.xlsx' and add it to our fileslist \n# the full.names=TRUE prepends the directory path to the file names, giving a relative file path - otherwise, only the file names (not the paths) would be returned \n# reference: https://stat.ethz.ch/R-manual/R-devel/library/base/html/list.files.html\nfileslist <-list.files(path = \"data/aspatial\", pattern = \"*.xlsx\", full.names=TRUE)\n\n# afterwards, for every element in fileslist, apply aspatial_process function\ndflist <- lapply(seq_along(fileslist), function(x) aspatial_preprocess(fileslist[x]))\n\n\nConverting the dflist into an actual dataframe using ldply():\n\n\nShow the code!\nvacc_jakarta <- ldply(dflist, data.frame)\n\n\nChecking vacc_jakarta:\n\n\nShow the code!\nglimpse(vacc_jakarta)\n\n\nRows: 3,204\nColumns: 5\n$ Date           <chr> \"27 Februari 2022\", \"27 Februari 2022\", \"27 Februari 20…\n$ KODE.KELURAHAN <chr> \"3172051003\", \"3173041007\", \"3175041005\", \"3175031003\",…\n$ KELURAHAN      <chr> \"ANCOL\", \"ANGKE\", \"BALE KAMBANG\", \"BALI MESTER\", \"BAMBU…\n$ SASARAN        <dbl> 23947, 29381, 29074, 9752, 26285, 21566, 23886, 47898, …\n$ BELUM.VAKSIN   <dbl> 4592, 5319, 5903, 1649, 4030, 3950, 3344, 9382, 3772, 7…\n\n\n\n\n4.3.4 Formatting Date Column\nThe Dates are currently in string format as there were derived from the file names, hence we need to convert the Dates into datetime format.\n\n\nShow the code!\n# parses the 'Date' column into Month(Full Name)-YYYY datetime objects\n# reference: https://stackoverflow.com/questions/53380650/b-y-date-conversion-gives-na\n\n# locale=\"ind\" means that the locale has been set as Indonesia\nSys.setlocale(locale=\"ind\")\n\n\n[1] \"LC_COLLATE=Indonesian_Indonesia.1252;LC_CTYPE=Indonesian_Indonesia.1252;LC_MONETARY=Indonesian_Indonesia.1252;LC_NUMERIC=C;LC_TIME=Indonesian_Indonesia.1252\"\n\n\nConverting to datetime format:\n\n\nShow the code!\nvacc_jakarta$Date <- c(vacc_jakarta$Date) %>% \n  as.Date(vacc_jakarta$Date, format =\"%d %B %Y\")\n\nglimpse(vacc_jakarta)\n\n\nRows: 3,204\nColumns: 5\n$ Date           <date> 2022-02-27, 2022-02-27, 2022-02-27, 2022-02-27, 2022-0~\n$ KODE.KELURAHAN <chr> \"3172051003\", \"3173041007\", \"3175041005\", \"3175031003\",~\n$ KELURAHAN      <chr> \"ANCOL\", \"ANGKE\", \"BALE KAMBANG\", \"BALI MESTER\", \"BAMBU~\n$ SASARAN        <dbl> 23947, 29381, 29074, 9752, 26285, 21566, 23886, 47898, ~\n$ BELUM.VAKSIN   <dbl> 4592, 5319, 5903, 1649, 4030, 3950, 3344, 9382, 3772, 7~\n\n\n\n\n4.3.4 Renaming Columns to English\nRenaming columns to English for ease of comprehension:\n\n\nShow the code!\n# renames the columns in the style New_Name = OLD_NAME\nvacc_jakarta <- vacc_jakarta %>% \n  dplyr::rename(\n    Date=Date,\n    Sub_District_Code=KODE.KELURAHAN,\n    Sub_District=KELURAHAN, \n    Target=SASARAN, \n    Not_Yet_Vaccinated=BELUM.VAKSIN\n    )\n\n\n\n\n4.3.5 Further Data Processing\nAfter finalising the dataframe, we can proceed with other data processing requirements.\nChecking for missing values:\n\n\nShow the code!\n# returns rows that contain NA values\nvacc_jakarta[rowSums(is.na(vacc_jakarta))!=0,]\n\n\n[1] Date               Sub_District_Code  Sub_District       Target            \n[5] Not_Yet_Vaccinated\n<0 rows> (or 0-length row.names)\n\n\nFrom the output, there are no missing values."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#choropleth-mapping-and-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#choropleth-mapping-and-analysis",
    "title": "Take-home Exercise 2: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "4.5 Choropleth Mapping and Analysis",
    "text": "4.5 Choropleth Mapping and Analysis\nThere are different data classifications to choropleth maps like equal intervals, quantile, Jenks and standard deviation. I have decided to use Jenks as it minimises variation in each class. It will be able to find suitable class ranges and also group outliers in a class of its own.\n\n4.5.1 Jenks Choropleth Map\nAs we do not want too many classes, we will use 6 classes as it seems to be the optimum number to view different classes and we will be able to differentiate between the classes without straining our eyes.\nMap for July 2021:\n\n\nShow the code!\n# using the jenks method, with 6 classes\ntmap_mode(\"plot\")\ntm_shape(vacc_rate)+\n  tm_fill(\"2021-07-31\", \n          n= 6,\n          style = \"jenks\", \n          title = \"Vaccination Rate\") +\n  tm_layout(main.title = \"Distribution of Vaccination Rate in July 2021\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.5, \n            legend.width = 0.4,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nIntroducing a helper function to help us plot the maps for all 12 months:\n\n\nShow the code!\n# input: the dataframe and the variable name - in this case, the month \n# with style=\"jenks\" for the jenks classification method\njenks_plot <- function(df, varname) {\n  tm_shape(vacc_rate) +\n    tm_polygons() +\n  tm_shape(df) +\n    tm_fill(varname, \n          n= 6,\n          style = \"jenks\", \n          title = \"Vaccination Rate\") +\n    tm_layout(main.title = varname,\n          main.title.position = \"center\",\n          main.title.size = 1.2,\n          legend.height = 0.45, \n          legend.width = 0.35,\n          frame = TRUE) +\n    tm_borders(alpha = 0.5)\n}\n\n\nVisualising the Jenks Maps for all 12 months:\n\n\nShow the code!\ntmap_mode(\"plot\")\ntmap_arrange(jenks_plot(vacc_rate, \"2021-07-31\"),\n             jenks_plot(vacc_rate, \"2021-08-31\"),\n             jenks_plot(vacc_rate, \"2021-09-30\"),\n             jenks_plot(vacc_rate, \"2021-10-31\"))\n\n\n\n\n\n\n\nShow the code!\ntmap_mode(\"plot\")\ntmap_arrange(jenks_plot(vacc_rate, \"2021-11-30\"),\n             jenks_plot(vacc_rate, \"2021-12-31\"),\n             jenks_plot(vacc_rate, \"2022-01-31\"),\n             jenks_plot(vacc_rate, \"2022-02-27\"))\n\n\n\n\n\n\n\nShow the code!\ntmap_mode(\"plot\")\ntmap_arrange(jenks_plot(vacc_rate, \"2022-03-31\"),\n             jenks_plot(vacc_rate, \"2022-04-30\"),\n             jenks_plot(vacc_rate, \"2022-05-31\"),\n             jenks_plot(vacc_rate, \"2022-06-30\"))\n\n\n\n\n\n\n\n4.5.2 Observations from Jenks Choropleth Maps\nFor each map, they have their own relative vaccination rate as the range for each map differs. Hence, we cannot rely on the colour scale for each map to compare between the months as it would not be fair.\nHowever, we are able to compare each month individually and see that typically for each month, generically the higher vaccination rates are at the Central area and Southern area. Although there were higher vaccination rates initially at the Northern area.\nSome other analysis can be done like the sub-district with the highest vaccination rate and the sub-district with the lowest vaccination rate for each month:\n\n\nShow the code!\n#highest vaccination rate for each month\nvacc_rate$Sub_District[which.max(vacc_rate$`2021-07-31`)]\n\n\n[1] \"KAMAL MUARA\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.max(vacc_rate$`2021-08-31`)]\n\n\n[1] \"KAMAL MUARA\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.max(vacc_rate$`2021-09-30`)]\n\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.max(vacc_rate$`2021-10-31`)]\n\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.max(vacc_rate$`2021-11-30`)]\n\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.max(vacc_rate$`2021-12-31`)]\n\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.max(vacc_rate$`2022-01-31`)]\n\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.max(vacc_rate$`2022-02-27`)]\n\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.max(vacc_rate$`2022-03-31`)]\n\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.max(vacc_rate$`2022-04-30`)]\n\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.max(vacc_rate$`2022-05-31`)]\n\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.max(vacc_rate$`2022-06-30`)]\n\n\n[1] \"HALIM PERDANA KUSUMAH\"\n\n\nFrom this, we can tell that the sub-district “KAMAL MUARA” had the highest vaccination rate initially from July 2021 to August 2021 but thereafter, “HALIM PERDANA KUSMAH” consistently had the highest vaccination rate from September 2021 to June 2022.\n\n\nShow the code!\n#lowest vaccination rate for each month\nvacc_rate$Sub_District[which.min(vacc_rate$`2021-07-31`)]\n\n\n[1] \"BALE KAMBANG\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.min(vacc_rate$`2021-08-31`)]\n\n\n[1] \"PETAMBURAN\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.min(vacc_rate$`2021-09-30`)]\n\n\n[1] \"KALIBARU\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.min(vacc_rate$`2021-10-31`)]\n\n\n[1] \"KALIBARU\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.min(vacc_rate$`2021-11-30`)]\n\n\n[1] \"KALIBARU\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.min(vacc_rate$`2021-12-31`)]\n\n\n[1] \"KEBON MELATI\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.min(vacc_rate$`2022-01-31`)]\n\n\n[1] \"KALIBARU\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.min(vacc_rate$`2022-02-27`)]\n\n\n[1] \"KEBON MELATI\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.min(vacc_rate$`2022-03-31`)]\n\n\n[1] \"KEBON MELATI\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.min(vacc_rate$`2022-04-30`)]\n\n\n[1] \"KEBON MELATI\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.min(vacc_rate$`2022-05-31`)]\n\n\n[1] \"KEBON MELATI\"\n\n\nShow the code!\nvacc_rate$Sub_District[which.min(vacc_rate$`2022-06-30`)]\n\n\n[1] \"KEBON MELATI\"\n\n\nFrom this, we can tell that initially the sub-district “BALE KAMBANG” had the lowest vaccination rate in July 2021, and “PETAMBURAN” was the sub-district with the lowest vaccination rate in August 2021. But their vaccination rates improved over the months such that “KALIBARU” was identified as the sub-district with the lowest vaccination rate from September 2021 to January 2022 with the exception of December 2021. Then, “KEBON MELATI” became the sub-district with the lowest vaccination rate from December 2021 to June 2022 with the exception of January 2022.\n\n\n4.5.3 Spatio-Temporal Mapping with custom breakpoints\nIn the above section, each month had their own vaccination rate. To compare with the vaccination rate between months and see the spatio-temporal progression of the vaccination rates, we should set a fixed range.\nTo do so, we have to customise the breakpoints and following the above section, we will define 6 breakpoints.\nFirst, we require the maximum vaccination rate which would be from the latest month (June 2022):\n\n\nShow the code!\nmax(vacc_rate$`2022-06-30`)\n\n\n[1] 89.77894\n\n\nNow, we can define the 6 breakpoints based on the Jenks breaks ranges from the above section:\n\n\nShow the code!\nbreakpoints = c(37, 55, 72, 80, 84, 90)\n\n\nCreating a helper function for break plot:\n\nbreak_plot <- function(df, varname) {\n  tm_shape(vacc_rate) +\n    tm_polygons() +\n  tm_shape(df) +\n    tm_fill(varname, \n          breaks= breakpoints,\n          title = \"Vaccination Rate\") +\n    tm_layout(main.title = varname,\n          main.title.position = \"center\",\n          main.title.size = 1.2,\n          legend.height = 0.45, \n          legend.width = 0.35,\n          frame = TRUE) +\n    tm_borders(alpha = 0.5)\n}\n\nPlotting the custom break plots for each month:\n\n\nShow the code!\ntmap_mode(\"plot\")\ntmap_arrange(break_plot(vacc_rate, \"2021-07-31\"),\n             break_plot(vacc_rate, \"2021-08-31\"),\n             break_plot(vacc_rate, \"2021-09-30\"),\n             break_plot(vacc_rate, \"2021-10-31\"))\n\n\n\n\n\n\n\nShow the code!\ntmap_mode(\"plot\")\ntmap_arrange(break_plot(vacc_rate, \"2021-11-30\"),\n             break_plot(vacc_rate, \"2021-12-31\"),\n             break_plot(vacc_rate, \"2022-01-31\"),\n             break_plot(vacc_rate, \"2022-02-27\"))\n\n\n\n\n\n\n\nShow the code!\ntmap_mode(\"plot\")\ntmap_arrange(break_plot(vacc_rate, \"2022-03-31\"),\n             break_plot(vacc_rate, \"2022-04-30\"),\n             break_plot(vacc_rate, \"2022-05-31\"),\n             break_plot(vacc_rate, \"2022-06-30\"))\n\n\n\n\n\n\n\n4.5.4 Observations from Custom Breakplot Maps\n\n\n\n\n\nAt the start, in July 2021, there is a slightly higher vaccination rate at the Northern and Central area compared to the other areas given its slightly darker shade of yellow.\nHowever as time passes, from August 2021 to October 2021, the increase in the vaccination rate becomes greater at the Northern Central area and Southern area.\nSpecifically sub-district “HALIM PERDANA KUSUMAH” is obvious to the eye with its consistently high rate and darker shade at the Eastern border.\nFrom November 2021 to February 2022, the increase in vaccination rate is faster at the Southern area and the Northern Central Area.\n(Supplementing the previous observations in section 4.5.2, the general increasing trend happens at the Southern and Central area.)\nFrom March 2022 to June 2022, we can see the sub-districts at the Northern Central area as well as some sub-districts near the Eastern border increasing their vaccination rates."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#local-gi-analysis",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#local-gi-analysis",
    "title": "Take-home Exercise 2: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "4.6 Local Gi* Analysis",
    "text": "4.6 Local Gi* Analysis\n\n4.6.1 Computing local Gi* values of the monthly vaccination rate\nTo create a time series cube, we first have to make an attribute table with the data organised in the following format: Date, Location (Sub_District) and Value (Vaccination_Rate)\nMaking an attribute table:\n\n\nShow the code!\n# make new vaccination attribute table with Date, Sub_District, Target, Not_Yet_Vaccinated\nvacc_attribute_table <- combined_jakarta %>% select(10, 8, 12, 13) %>% st_drop_geometry()\n\n# add a new field for Vaccination_Rate\nvacc_attribute_table$Vaccination_Rate <- (vacc_attribute_table$Target - vacc_attribute_table$Not_Yet_Vaccinated) / vacc_attribute_table$Target*100\n\n# final vaccination attribute table with Date, Sub_District, Vaccination_Rate\nvacc_attribute_table <- tibble(vacc_attribute_table %>% select(1,2,5))\n\n\nDisplay attribute table details:\n\n\nShow the code!\nvacc_attribute_table\n\n\n# A tibble: 3,132 x 3\n   Date       Sub_District Vaccination_Rate\n   <date>     <chr>                   <dbl>\n 1 2022-02-27 KEAGUNGAN                84.2\n 2 2022-04-30 KEAGUNGAN                85.1\n 3 2022-06-30 KEAGUNGAN                85.3\n 4 2021-11-30 KEAGUNGAN                82.2\n 5 2021-09-30 KEAGUNGAN                75.8\n 6 2021-08-31 KEAGUNGAN                65.2\n 7 2021-12-31 KEAGUNGAN                83.2\n 8 2022-01-31 KEAGUNGAN                84.0\n 9 2021-07-31 KEAGUNGAN                53.3\n10 2022-03-31 KEAGUNGAN                84.6\n# ... with 3,122 more rows\n\n\nCreating a time series cube (spatio-temporal cube) using spacetime() of sfdep package:\n\n\nShow the code!\nvacc_rate_st <- spacetime(vacc_attribute_table, bd_jakarta,\n                          .loc_col = \"Sub_District\",\n                          .time_col = \"Date\")\n\n\nNext, we can check if vacc_rate_st is indeed a space-time cube object using is_spacetime_cube() of sfdep package:\n\n\nShow the code!\nis_spacetime_cube(vacc_rate_st)\n\n\n[1] TRUE\n\n\nThe output shows ‘TRUE’, confirming that vacc_rate_st is a space-time cube.\nTo compute the local Gi* statistics, we need to derive the spatial weights first:\n\n\nShow the code!\nvacc_rate_nb <- vacc_rate_st %>%\n  activate(\"geometry\") %>%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                  scale=1,\n                                  alpha=1),\n         .before=1) %>%\n  set_nbs(\"nb\") %>%\n  set_wts(\"wt\")\n\n\nThe above code does the following:\n\nidentify neighbours\nderive inverse distance weights\nactivate() of dplyr package is used to activate the geometry context\nmutate() of dplyr package is used to create two new columns nb and wt.\nThen we will activate the data context again and copy over the nb and wt columns to each time-slice using set_nbs() and set_wts()\nrow order is very important so do not rearrange the observations after using set_nbs() or set_wts().\n\nThe dataset now has neighbours and weights for each time-slice:\n\n\nShow the code!\nhead(vacc_rate_nb)\n\n\n# A tibble: 6 x 5\n  Date       Sub_District  Vaccination_Rate nb        wt       \n  <date>     <chr>                    <dbl> <list>    <list>   \n1 2021-07-31 KEAGUNGAN                 53.3 <int [6]> <dbl [6]>\n2 2021-07-31 GLODOK                    61.6 <int [7]> <dbl [7]>\n3 2021-07-31 HARAPAN MULIA             49.7 <int [6]> <dbl [6]>\n4 2021-07-31 CEMPAKA BARU              46.7 <int [7]> <dbl [7]>\n5 2021-07-31 PASAR BARU                59.3 <int [9]> <dbl [9]>\n6 2021-07-31 KARANG ANYAR              52.2 <int [7]> <dbl [7]>\n\n\nBefore computing Gi*, we will set the seed value so that the results of the simulations will be reproducible and constant:\n\n\nShow the code!\nset.seed(1234)\n\n\nComputing Gi* for each location, grouping by Date and using local_gstar_perm() of sfdep package:\n\n\nShow the code!\ngi_stars <- vacc_rate_nb |>\n  group_by(Date) |>\n  mutate(gi_star = local_gstar_perm(\n    Vaccination_Rate, nb, wt, nsim=99)) |>\n      tidyr::unnest(gi_star)\n\n\nNote: unnest() will unnest the gi_star column\nTaking a look at the newly created gi_stars dataframe:\n\n\nShow the code!\ngi_stars\n\n\n# A tibble: 3,132 x 13\n# Groups:   Date [12]\n   Date       Sub_Di~1 Vacci~2 nb    wt    gi_star    e_gi  var_gi p_value p_sim\n   <date>     <chr>      <dbl> <lis> <lis>   <dbl>   <dbl>   <dbl>   <dbl> <dbl>\n 1 2021-07-31 KEAGUNG~    53.3 <int> <dbl>   2.44  0.00383 2.13e-8 1.46e-2  0.02\n 2 2021-07-31 GLODOK      61.6 <int> <dbl>   3.85  0.00384 1.56e-8 1.18e-4  0.02\n 3 2021-07-31 HARAPAN~    49.7 <int> <dbl>   0.309 0.00382 2.20e-8 7.57e-1  0.84\n 4 2021-07-31 CEMPAKA~    46.7 <int> <dbl>  -1.05  0.00383 1.53e-8 2.96e-1  0.34\n 5 2021-07-31 PASAR B~    59.3 <int> <dbl>   2.71  0.00383 1.38e-8 6.82e-3  0.02\n 6 2021-07-31 KARANG ~    52.2 <int> <dbl>   1.67  0.00382 2.17e-8 9.49e-2  0.1 \n 7 2021-07-31 MANGGA ~    51.6 <int> <dbl>   1.35  0.00384 1.80e-8 1.77e-1  0.22\n 8 2021-07-31 PETOJO ~    47.2 <int> <dbl>  -0.179 0.00382 1.92e-8 8.58e-1  0.96\n 9 2021-07-31 SENEN       54.4 <int> <dbl>   1.51  0.00382 1.20e-8 1.32e-1  0.1 \n10 2021-07-31 BUNGUR      52.8 <int> <dbl>   0.797 0.00385 1.54e-8 4.25e-1  0.48\n# ... with 3,122 more rows, 3 more variables: p_folded_sim <dbl>,\n#   skewness <dbl>, kurtosis <dbl>, and abbreviated variable names\n#   1: Sub_District, 2: Vaccination_Rate\n\n\n\n\n4.6.2 Displaying the Gi* maps of the monthly vaccination rate\nBefore we can visualise the Gi* values using maps, we need to join both combined_jakarta and gi_stars together:\n\n\nShow the code!\ncombined_jakarta_gi_stars <- combined_jakarta %>%\n  left_join(gi_stars)\n\n\nTaking a look at combined_jakarta_gi_stars:\n\n\nShow the code!\ncombined_jakarta_gi_stars\n\n\nSimple feature collection with 3132 features and 24 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -3644275 ymin: 663887.8 xmax: -3606237 ymax: 701380.1\nProjected CRS: DGN95 / Indonesia TM-3 zone 54.1\nFirst 10 features:\n   Object_ID Village_Code   Village   Code    Province          City   District\n1      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n2      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n3      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n4      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n5      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n6      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n7      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n8      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n9      25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n10     25477   3173031006 KEAGUNGAN 317303 DKI JAKARTA JAKARTA BARAT TAMAN SARI\n   Sub_District Total_Population       Date Sub_District_Code Target\n1     KEAGUNGAN            21609 2022-02-27        3173031006  17387\n2     KEAGUNGAN            21609 2022-04-30        3173031006  17387\n3     KEAGUNGAN            21609 2022-06-30        3173031006  17387\n4     KEAGUNGAN            21609 2021-11-30        3173031006  17387\n5     KEAGUNGAN            21609 2021-09-30        3173031006  17387\n6     KEAGUNGAN            21609 2021-08-31        3173031006  17387\n7     KEAGUNGAN            21609 2021-12-31        3173031006  17387\n8     KEAGUNGAN            21609 2022-01-31        3173031006  17387\n9     KEAGUNGAN            21609 2021-07-31        3173031006  17387\n10    KEAGUNGAN            21609 2022-03-31        3173031006  17387\n   Not_Yet_Vaccinated Vaccination_Rate                      nb\n1                2755         84.15483 1, 2, 39, 152, 158, 166\n2                2593         85.08656 1, 2, 39, 152, 158, 166\n3                2553         85.31662 1, 2, 39, 152, 158, 166\n4                3099         82.17634 1, 2, 39, 152, 158, 166\n5                4203         75.82677 1, 2, 39, 152, 158, 166\n6                6054         65.18088 1, 2, 39, 152, 158, 166\n7                2924         83.18284 1, 2, 39, 152, 158, 166\n8                2783         83.99379 1, 2, 39, 152, 158, 166\n9                8126         53.26393 1, 2, 39, 152, 158, 166\n10               2675         84.61494 1, 2, 39, 152, 158, 166\n                                                                             wt\n1  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n2  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n3  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n4  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n5  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n6  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n7  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n8  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n9  0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n10 0.000000000, 0.001071983, 0.001039284, 0.001417870, 0.001110612, 0.001297268\n    gi_star        e_gi       var_gi     p_value p_sim p_folded_sim    skewness\n1  2.478859 0.003831172 8.419778e-10 0.013180341  0.02         0.01 -0.03194341\n2  2.825027 0.003827108 7.494269e-10 0.004727670  0.04         0.02 -0.06356613\n3  2.856078 0.003828377 6.980492e-10 0.004289104  0.02         0.01  0.09797571\n4  2.400280 0.003831389 1.665572e-09 0.016382514  0.02         0.01 -0.75383323\n5  2.340497 0.003839767 1.969413e-09 0.019258078  0.02         0.01 -0.45706127\n6  2.697283 0.003843766 4.229906e-09 0.006990777  0.02         0.01  0.19649652\n7  2.737341 0.003831004 9.440138e-10 0.006193804  0.02         0.01 -0.13372915\n8  2.601179 0.003833862 7.779184e-10 0.009290410  0.02         0.01 -0.51408533\n9  2.442508 0.003830045 2.133669e-08 0.014585591  0.02         0.01 -0.40723702\n10 2.631489 0.003829259 7.973859e-10 0.008501151  0.04         0.02  0.23980167\n      kurtosis                       geometry\n1  -0.81316154 MULTIPOLYGON (((-3626874 69...\n2   0.55021722 MULTIPOLYGON (((-3626874 69...\n3  -0.50749002 MULTIPOLYGON (((-3626874 69...\n4   0.54499553 MULTIPOLYGON (((-3626874 69...\n5   0.28836755 MULTIPOLYGON (((-3626874 69...\n6   0.03187466 MULTIPOLYGON (((-3626874 69...\n7  -0.02562365 MULTIPOLYGON (((-3626874 69...\n8   0.07882560 MULTIPOLYGON (((-3626874 69...\n9   0.28865884 MULTIPOLYGON (((-3626874 69...\n10 -0.20275849 MULTIPOLYGON (((-3626874 69...\n\n\nVisualising Gi* and p-value of Gi* (only significant locations where p-value < 0.05) for vaccination rates in July 2021:\n\n\nShow the code!\ntmap_mode(\"plot\")\ngi_star_map = tm_shape(filter(combined_jakarta_gi_stars, Date == '2021-07-31')) +\n  tm_fill(\"gi_star\") +\n  tm_borders(alpha=0.5) +\n  tm_layout(main.title = \"Gi* values for vaccination rates in July 2021\", main.title.size=0.8)\n  # tm_view(set.zoom.limits = c(10,16))\n\np_sim_map = tm_shape(filter(combined_jakarta_gi_stars, Date == '2021-07-31')) +\n  tm_fill(\"p_sim\", breaks = c(0, 0.05, 1)) +\n  tm_borders(alpha=0.5) + \n  tm_layout(main.title = \"p-values of Gi* for vaccination rates in July 2021\", main.title.size=0.8)\n  # tm_view(set.zoom.limits = c(10,16))\n\ntmap_arrange(gi_star_map, p_sim_map)\n\n\n\n\n\nIntroducing a helper function to help us plot the Gi* and p-value of Gi* maps for all 12 months:\n\n\nShow the code!\ngi_star_plot <- function(date, month) {\n  gi_star_map = tm_shape(filter(combined_jakarta_gi_stars, Date == date)) +\n    tm_fill(\"gi_star\") +\n    tm_borders(alpha=0.5) +\n    tm_layout(main.title = paste(\"Gi* values for vaccination rates in\", month), main.title.size=0.8)\n\n  p_sim_map = tm_shape(filter(combined_jakarta_gi_stars, Date == date)) +\n    tm_fill(\"p_sim\", breaks = c(0, 0.05, 1)) +\n    tm_borders(alpha=0.5) + \n    tm_layout(main.title = paste(\"p-values of Gi* for vaccination rates in\", month), main.title.size=0.8)\n\n  tmap_arrange(gi_star_map, p_sim_map)\n}\n\n\n\n\nShow the code!\ntmap_mode(\"plot\")\ngi_star_plot(\"2021-07-31\", \"July 2021\")\n\n\n\n\n\nShow the code!\ngi_star_plot(\"2021-08-31\", \"August 2021\")\n\n\n\n\n\nShow the code!\ngi_star_plot(\"2021-09-30\", \"September 2021\")\n\n\n\n\n\nShow the code!\ngi_star_plot(\"2021-10-31\", \"October 2021\")\n\n\n\n\n\nShow the code!\ngi_star_plot(\"2021-11-30\", \"November 2021\")\n\n\n\n\n\nShow the code!\ngi_star_plot(\"2021-12-31\", \"December 2021\")\n\n\n\n\n\nShow the code!\ngi_star_plot(\"2022-01-31\", \"January 2022\")\n\n\n\n\n\nShow the code!\ngi_star_plot(\"2022-02-27\", \"February 2022\")\n\n\n\n\n\nShow the code!\ngi_star_plot(\"2022-03-31\", \"March 2022\")\n\n\n\n\n\nShow the code!\ngi_star_plot(\"2022-04-30\", \"April 2022\")\n\n\n\n\n\nShow the code!\ngi_star_plot(\"2022-05-31\", \"May 2022\")\n\n\n\n\n\nShow the code!\ngi_star_plot(\"2022-06-30\", \"June 2022\")\n\n\n\n\n\nLocations with p-value of Gi* < 0.05 in July 2021:\n\n\nShow the code!\njuly_details = filter(combined_jakarta_gi_stars, Date == '2021-07-31' & p_sim<0.05)\njuly_details$Sub_District\n\n\n [1] \"KEAGUNGAN\"              \"GLODOK\"                 \"PASAR BARU\"            \n [4] \"PETAMBURAN\"             \"KEBON MELATI\"           \"KAMPUNG RAWA\"          \n [7] \"ANCOL\"                  \"KELAPA GADING TIMUR\"    \"MANGGA BESAR\"          \n[10] \"SUKABUMI UTARA\"         \"SUKABUMI SELATAN\"       \"KELAPA DUA\"            \n[13] \"RAWA BUNGA\"             \"SRENGSENG\"              \"PEJATEN TIMUR\"         \n[16] \"CIPULIR\"                \"PISANGAN BARU\"          \"JATINEGARA KAUM\"       \n[19] \"CIPINANG MUARA\"         \"CIPINANG BESAR SELATAN\" \"CIPINANG BESAR UTARA\"  \n[22] \"KAMPUNG TENGAH\"         \"BALE KAMBANG\"           \"CILILITAN\"             \n[25] \"KLENDER\"                \"PONDOK KOPI\"            \"PISANGAN TIMUR\"        \n[28] \"GUNUNG SAHARI SELATAN\"  \"GUNUNG SAHARI UTARA\"    \"KEBON KACANG\"          \n[31] \"KAMPUNG BALI\"           \"GALUR\"                  \"TANAH TINGGI\"          \n[34] \"KAPUK MUARA\"            \"SUNTER JAYA\"            \"PEGANGSAAN DUA\"        \n[37] \"KELAPA GADING BARAT\"    \"MAPHAR\"                 \"TANGKI\"                \n[40] \"TOMANG\"                 \"PINANGSIA\"              \"CIPINANG CEMPEDAK\"     \n[43] \"MELAWAI\"                \"SELONG\"                 \"RAWA BARAT\"            \n[46] \"PETOGOGAN\"              \"KAMPUNG MELAYU\"         \"BIDARA CINA\"           \n[49] \"BALI MESTER\"            \"KRAMAT JATI\"            \"BATU AMPAR\"            \n[52] \"GEDONG\"                 \"JATINEGARA\"             \"PONDOK BAMBU\"          \n[55] \"RAMBUTAN\"              \n\n\nIntroducing a helper function to help us discover the Sub-Districts with p-value of Gi* < 0.05 for all 12 months:\n\n\nShow the code!\nget_significant_locations <- function(date, month) {\n  print(paste(\"Sub-Districts with p-value of Gi* < 0.05 in\", month))\n  filter(combined_jakarta_gi_stars, Date == date & p_sim<0.05)$Sub_District\n}\n\n\n\n\nShow the code!\nget_significant_locations(\"2021-07-31\", \"July 2021\")\n\n\n[1] \"Sub-Districts with p-value of Gi* < 0.05 in July 2021\"\n\n\n [1] \"KEAGUNGAN\"              \"GLODOK\"                 \"PASAR BARU\"            \n [4] \"PETAMBURAN\"             \"KEBON MELATI\"           \"KAMPUNG RAWA\"          \n [7] \"ANCOL\"                  \"KELAPA GADING TIMUR\"    \"MANGGA BESAR\"          \n[10] \"SUKABUMI UTARA\"         \"SUKABUMI SELATAN\"       \"KELAPA DUA\"            \n[13] \"RAWA BUNGA\"             \"SRENGSENG\"              \"PEJATEN TIMUR\"         \n[16] \"CIPULIR\"                \"PISANGAN BARU\"          \"JATINEGARA KAUM\"       \n[19] \"CIPINANG MUARA\"         \"CIPINANG BESAR SELATAN\" \"CIPINANG BESAR UTARA\"  \n[22] \"KAMPUNG TENGAH\"         \"BALE KAMBANG\"           \"CILILITAN\"             \n[25] \"KLENDER\"                \"PONDOK KOPI\"            \"PISANGAN TIMUR\"        \n[28] \"GUNUNG SAHARI SELATAN\"  \"GUNUNG SAHARI UTARA\"    \"KEBON KACANG\"          \n[31] \"KAMPUNG BALI\"           \"GALUR\"                  \"TANAH TINGGI\"          \n[34] \"KAPUK MUARA\"            \"SUNTER JAYA\"            \"PEGANGSAAN DUA\"        \n[37] \"KELAPA GADING BARAT\"    \"MAPHAR\"                 \"TANGKI\"                \n[40] \"TOMANG\"                 \"PINANGSIA\"              \"CIPINANG CEMPEDAK\"     \n[43] \"MELAWAI\"                \"SELONG\"                 \"RAWA BARAT\"            \n[46] \"PETOGOGAN\"              \"KAMPUNG MELAYU\"         \"BIDARA CINA\"           \n[49] \"BALI MESTER\"            \"KRAMAT JATI\"            \"BATU AMPAR\"            \n[52] \"GEDONG\"                 \"JATINEGARA\"             \"PONDOK BAMBU\"          \n[55] \"RAMBUTAN\"              \n\n\nShow the code!\nget_significant_locations(\"2021-08-31\", \"August 2021\")\n\n\n[1] \"Sub-Districts with p-value of Gi* < 0.05 in August 2021\"\n\n\n [1] \"KEAGUNGAN\"              \"GLODOK\"                 \"PASAR BARU\"            \n [4] \"PETAMBURAN\"             \"KEBON MELATI\"           \"KAMPUNG RAWA\"          \n [7] \"KAMAL MUARA\"            \"PAPANGGO\"               \"KELAPA GADING TIMUR\"   \n[10] \"MANGGA BESAR\"           \"SUKABUMI UTARA\"         \"SUKABUMI SELATAN\"      \n[13] \"KELAPA DUA\"             \"RAWA BUNGA\"             \"PEJATEN TIMUR\"         \n[16] \"CIPULIR\"                \"GROGOL SELATAN\"         \"PISANGAN BARU\"         \n[19] \"CIPINANG MUARA\"         \"CIPINANG BESAR SELATAN\" \"CIPINANG BESAR UTARA\"  \n[22] \"KAMPUNG TENGAH\"         \"BALE KAMBANG\"           \"CILILITAN\"             \n[25] \"DUREN SAWIT\"            \"KLENDER\"                \"PONDOK KOPI\"           \n[28] \"CEMPAKA PUTIH BARAT\"    \"BENDUNGAN HILIR\"        \"KEBON KACANG\"          \n[31] \"KAMPUNG BALI\"           \"JOHAR BARU\"             \"GALUR\"                 \n[34] \"TANAH TINGGI\"           \"KAPUK MUARA\"            \"SUNTER JAYA\"           \n[37] \"SUNTER AGUNG\"           \"PEGANGSAAN DUA\"         \"MAPHAR\"                \n[40] \"PINANGSIA\"              \"TANAH SEREAL\"           \"ROA MALAKA\"            \n[43] \"DURI SELATAN\"           \"CIPINANG CEMPEDAK\"      \"GROGOL UTARA\"          \n[46] \"PETUKANGAN UTARA\"       \"PULO GADUNG\"            \"ULUJAMI\"               \n[49] \"KAYU MANIS\"             \"PAL MERIAM\"             \"KAMPUNG MELAYU\"        \n[52] \"BIDARA CINA\"            \"BALI MESTER\"            \"BATU AMPAR\"            \n[55] \"CIJANTUNG\"              \"PENGGILINGAN\"           \"PONDOK BAMBU\"          \n[58] \"MALAKA SARI\"            \"HALIM PERDANA KUSUMAH\"  \"CIBUBUR\"               \n[61] \"KELAPA DUA WETAN\"      \n\n\nShow the code!\nget_significant_locations(\"2021-09-30\", \"September 2021\")\n\n\n[1] \"Sub-Districts with p-value of Gi* < 0.05 in September 2021\"\n\n\n [1] \"KEAGUNGAN\"             \"GLODOK\"                \"PETAMBURAN\"           \n [4] \"KEBON MELATI\"          \"KAMPUNG RAWA\"          \"TUGU UTARA\"           \n [7] \"LAGOA\"                 \"KOJA\"                  \"CILINCING\"            \n[10] \"KALIBARU\"              \"KELAPA GADING TIMUR\"   \"MANGGA BESAR\"         \n[13] \"SUKABUMI UTARA\"        \"SUKABUMI SELATAN\"      \"KELAPA DUA\"           \n[16] \"RAWA BUNGA\"            \"PEJATEN TIMUR\"         \"CIPEDAK\"              \n[19] \"CIPINANG BESAR UTARA\"  \"KAMPUNG TENGAH\"        \"BALE KAMBANG\"         \n[22] \"CILILITAN\"             \"RAWA BADAK UTARA\"      \"KEBON KACANG\"         \n[25] \"KAMPUNG BALI\"          \"SEMPER TIMUR\"          \"PEGANGSAAN DUA\"       \n[28] \"KELAPA GADING BARAT\"   \"TANGKI\"                \"PINANGSIA\"            \n[31] \"TEBET BARAT\"           \"TEBET TIMUR\"           \"CIPINANG CEMPEDAK\"    \n[34] \"MELAWAI\"               \"SELONG\"                \"PETOGOGAN\"            \n[37] \"CIGANJUR\"              \"PULO GADUNG\"           \"KAMPUNG MELAYU\"       \n[40] \"BIDARA CINA\"           \"BALI MESTER\"           \"KRAMAT JATI\"          \n[43] \"BATU AMPAR\"            \"GEDONG\"                \"CIJANTUNG\"            \n[46] \"PONDOK BAMBU\"          \"HALIM PERDANA KUSUMAH\" \"KELAPA DUA WETAN\"     \n[49] \"MUNJUL\"               \n\n\nShow the code!\nget_significant_locations(\"2021-10-31\", \"October 2021\")\n\n\n[1] \"Sub-Districts with p-value of Gi* < 0.05 in October 2021\"\n\n\n [1] \"KEAGUNGAN\"             \"GLODOK\"                \"PETAMBURAN\"           \n [4] \"KEBON MELATI\"          \"TUGU UTARA\"            \"LAGOA\"                \n [7] \"KOJA\"                  \"CILINCING\"             \"KALIBARU\"             \n[10] \"SEMPER BARAT\"          \"KELAPA GADING TIMUR\"   \"MANGGA BESAR\"         \n[13] \"SUKABUMI SELATAN\"      \"RAWA BUNGA\"            \"MANGGARAI SELATAN\"    \n[16] \"PONDOK LABU\"           \"LENTENG AGUNG\"         \"JAGAKARSA\"            \n[19] \"CIPEDAK\"               \"CIPINANG BESAR UTARA\"  \"KAMPUNG TENGAH\"       \n[22] \"BALE KAMBANG\"          \"KALISARI\"              \"CIPAYUNG\"             \n[25] \"RAWA BADAK UTARA\"      \"BENDUNGAN HILIR\"       \"KEBON KACANG\"         \n[28] \"KAMPUNG BALI\"          \"MAPHAR\"                \"TANGKI\"               \n[31] \"JEMBATAN LIMA\"         \"TEBET BARAT\"           \"TEBET TIMUR\"          \n[34] \"CIPINANG CEMPEDAK\"     \"CILANDAK BARAT\"        \"SRENGSENG SAWAH\"      \n[37] \"CIGANJUR\"              \"BIDARA CINA\"           \"BATU AMPAR\"           \n[40] \"GEDONG\"                \"BARU\"                  \"CIJANTUNG\"            \n[43] \"PEKAYON\"               \"HALIM PERDANA KUSUMAH\" \"CIBUBUR\"              \n[46] \"KELAPA DUA WETAN\"      \"MUNJUL\"                \"LUBANG BUAYA\"         \n\n\nShow the code!\nget_significant_locations(\"2021-11-30\", \"November 2021\")\n\n\n[1] \"Sub-Districts with p-value of Gi* < 0.05 in November 2021\"\n\n\n [1] \"KEAGUNGAN\"              \"GLODOK\"                 \"PETAMBURAN\"            \n [4] \"KEBON MELATI\"           \"TUGU UTARA\"             \"LAGOA\"                 \n [7] \"RAWA BADAK SELATAN\"     \"CILINCING\"              \"KALIBARU\"              \n[10] \"SEMPER BARAT\"           \"KELAPA GADING TIMUR\"    \"MANGGA BESAR\"          \n[13] \"RAWA BUNGA\"             \"MANGGARAI SELATAN\"      \"RAGUNAN\"               \n[16] \"PONDOK LABU\"            \"LENTENG AGUNG\"          \"JAGAKARSA\"             \n[19] \"CIPEDAK\"                \"CIPINANG BESAR SELATAN\" \"CIPINANG BESAR UTARA\"  \n[22] \"KAMPUNG TENGAH\"         \"BALE KAMBANG\"           \"KALISARI\"              \n[25] \"RAWA BADAK UTARA\"       \"PETOJO SELATAN\"         \"BENDUNGAN HILIR\"       \n[28] \"KEBON KACANG\"           \"KAMPUNG BALI\"           \"SUNTER JAYA\"           \n[31] \"SEMPER TIMUR\"           \"TANGKI\"                 \"TEBET BARAT\"           \n[34] \"TEBET TIMUR\"            \"CIPINANG CEMPEDAK\"      \"CILANDAK TIMUR\"        \n[37] \"CIKOKO\"                 \"SRENGSENG SAWAH\"        \"CIGANJUR\"              \n[40] \"BIDARA CINA\"            \"BALI MESTER\"            \"KRAMAT JATI\"           \n[43] \"BATU AMPAR\"             \"BARU\"                   \"CIJANTUNG\"             \n[46] \"HALIM PERDANA KUSUMAH\"  \"CIBUBUR\"                \"KELAPA DUA WETAN\"      \n[49] \"MUNJUL\"                \n\n\nShow the code!\nget_significant_locations(\"2021-12-31\", \"December 2021\")\n\n\n[1] \"Sub-Districts with p-value of Gi* < 0.05 in December 2021\"\n\n\n [1] \"KEAGUNGAN\"             \"GLODOK\"                \"MENTENG\"              \n [4] \"PETAMBURAN\"            \"KEBON MELATI\"          \"TUGU UTARA\"           \n [7] \"LAGOA\"                 \"CILINCING\"             \"KALIBARU\"             \n[10] \"SEMPER BARAT\"          \"KELAPA GADING TIMUR\"   \"MANGGA BESAR\"         \n[13] \"RAWA BUNGA\"            \"MANGGARAI SELATAN\"     \"PASAR MANGGIS\"        \n[16] \"RAGUNAN\"               \"KEBAGUSAN\"             \"PONDOK LABU\"          \n[19] \"LENTENG AGUNG\"         \"JAGAKARSA\"             \"CIPEDAK\"              \n[22] \"KAMPUNG TENGAH\"        \"BALE KAMBANG\"          \"KALISARI\"             \n[25] \"CIPAYUNG\"              \"RAWA BADAK UTARA\"      \"PETOJO SELATAN\"       \n[28] \"GONDANGDIA\"            \"KEBON SIRIH\"           \"GELORA\"               \n[31] \"BENDUNGAN HILIR\"       \"KEBON KACANG\"          \"KAMPUNG BALI\"         \n[34] \"PENJARINGAN\"           \"SUNTER JAYA\"           \"MARUNDA\"              \n[37] \"TANGKI\"                \"TANAH SEREAL\"          \"TEBET BARAT\"          \n[40] \"TEBET TIMUR\"           \"CIPINANG CEMPEDAK\"     \"CILANDAK TIMUR\"       \n[43] \"CIKOKO\"                \"SRENGSENG SAWAH\"       \"CIGANJUR\"             \n[46] \"TANJUNG BARAT\"         \"BIDARA CINA\"           \"BATU AMPAR\"           \n[49] \"BARU\"                  \"PEKAYON\"               \"HALIM PERDANA KUSUMAH\"\n[52] \"CIBUBUR\"               \"KELAPA DUA WETAN\"     \n\n\nShow the code!\nget_significant_locations(\"2022-01-31\", \"January 2022\")\n\n\n[1] \"Sub-Districts with p-value of Gi* < 0.05 in January 2022\"\n\n\n [1] \"KEAGUNGAN\"             \"GLODOK\"                \"MENTENG\"              \n [4] \"PETAMBURAN\"            \"KEBON MELATI\"          \"LAGOA\"                \n [7] \"CILINCING\"             \"KALIBARU\"              \"SEMPER BARAT\"         \n[10] \"KELAPA GADING TIMUR\"   \"MANGGA BESAR\"          \"RAWA BUNGA\"           \n[13] \"MANGGARAI SELATAN\"     \"RAGUNAN\"               \"KEBAGUSAN\"            \n[16] \"PONDOK LABU\"           \"LENTENG AGUNG\"         \"JAGAKARSA\"            \n[19] \"CIPEDAK\"               \"CIPINANG BESAR UTARA\"  \"KAMPUNG TENGAH\"       \n[22] \"KALISARI\"              \"CIPAYUNG\"              \"GAMBIR\"               \n[25] \"PETOJO SELATAN\"        \"KRAMAT\"                \"GONDANGDIA\"           \n[28] \"KEBON SIRIH\"           \"GELORA\"                \"BENDUNGAN HILIR\"      \n[31] \"KEBON KACANG\"          \"KAMPUNG BALI\"          \"PENJARINGAN\"          \n[34] \"SEMPER TIMUR\"          \"TANGKI\"                \"TEBET BARAT\"          \n[37] \"TEBET TIMUR\"           \"CIPINANG CEMPEDAK\"     \"CILANDAK TIMUR\"       \n[40] \"CILANDAK BARAT\"        \"CIKOKO\"                \"SRENGSENG SAWAH\"      \n[43] \"CIGANJUR\"              \"BATU AMPAR\"            \"BARU\"                 \n[46] \"CIJANTUNG\"             \"PEKAYON\"               \"MALAKA JAYA\"          \n[49] \"HALIM PERDANA KUSUMAH\" \"CIBUBUR\"               \"KELAPA DUA WETAN\"     \n[52] \"MUNJUL\"                \"LUBANG BUAYA\"         \n\n\nShow the code!\nget_significant_locations(\"2022-02-27\", \"February 2022\")\n\n\n[1] \"Sub-Districts with p-value of Gi* < 0.05 in February 2022\"\n\n\n [1] \"KEAGUNGAN\"             \"GLODOK\"                \"MENTENG\"              \n [4] \"PETAMBURAN\"            \"KEBON MELATI\"          \"TUGU UTARA\"           \n [7] \"LAGOA\"                 \"CILINCING\"             \"KALIBARU\"             \n[10] \"MANGGA BESAR\"          \"MANGGARAI SELATAN\"     \"RAGUNAN\"              \n[13] \"SENAYAN\"               \"PONDOK LABU\"           \"LENTENG AGUNG\"        \n[16] \"JAGAKARSA\"             \"CIPEDAK\"               \"KAMPUNG TENGAH\"       \n[19] \"BALE KAMBANG\"          \"KALISARI\"              \"GAMBIR\"               \n[22] \"PETOJO SELATAN\"        \"KRAMAT\"                \"GONDANGDIA\"           \n[25] \"KEBON SIRIH\"           \"GELORA\"                \"BENDUNGAN HILIR\"      \n[28] \"KARET TENGSIN\"         \"KEBON KACANG\"          \"KAMPUNG BALI\"         \n[31] \"SEMPER TIMUR\"          \"TANGKI\"                \"TEBET BARAT\"          \n[34] \"TEBET TIMUR\"           \"CIPINANG CEMPEDAK\"     \"CILANDAK TIMUR\"       \n[37] \"CIKOKO\"                \"SRENGSENG SAWAH\"       \"CIGANJUR\"             \n[40] \"TANJUNG BARAT\"         \"BIDARA CINA\"           \"BATU AMPAR\"           \n[43] \"BARU\"                  \"CIJANTUNG\"             \"PEKAYON\"              \n[46] \"MALAKA JAYA\"           \"HALIM PERDANA KUSUMAH\" \"CIBUBUR\"              \n[49] \"KELAPA DUA WETAN\"      \"MUNJUL\"                \"LUBANG BUAYA\"         \n\n\nShow the code!\nget_significant_locations(\"2022-03-31\", \"March 2022\")\n\n\n[1] \"Sub-Districts with p-value of Gi* < 0.05 in March 2022\"\n\n\n [1] \"KEAGUNGAN\"             \"GLODOK\"                \"SENEN\"                \n [4] \"MENTENG\"               \"CIKINI\"                \"PETAMBURAN\"           \n [7] \"KEBON MELATI\"          \"LAGOA\"                 \"CILINCING\"            \n[10] \"KALIBARU\"              \"MANGGA BESAR\"          \"RAWA BUNGA\"           \n[13] \"RAGUNAN\"               \"KEBAGUSAN\"             \"PONDOK LABU\"          \n[16] \"LENTENG AGUNG\"         \"JAGAKARSA\"             \"CIPEDAK\"              \n[19] \"CIPINANG BESAR UTARA\"  \"KAMPUNG TENGAH\"        \"BALE KAMBANG\"         \n[22] \"KALISARI\"              \"GAMBIR\"                \"PETOJO SELATAN\"       \n[25] \"GONDANGDIA\"            \"KEBON SIRIH\"           \"GELORA\"               \n[28] \"BENDUNGAN HILIR\"       \"KARET TENGSIN\"         \"KEBON KACANG\"         \n[31] \"KAMPUNG BALI\"          \"TANAH SEREAL\"          \"TEBET BARAT\"          \n[34] \"TEBET TIMUR\"           \"CIPINANG CEMPEDAK\"     \"CILANDAK TIMUR\"       \n[37] \"CILANDAK BARAT\"        \"CIKOKO\"                \"SRENGSENG SAWAH\"      \n[40] \"CIGANJUR\"              \"TANJUNG BARAT\"         \"BIDARA CINA\"          \n[43] \"BATU AMPAR\"            \"BARU\"                  \"CIJANTUNG\"            \n[46] \"PEKAYON\"               \"MALAKA JAYA\"           \"HALIM PERDANA KUSUMAH\"\n[49] \"CIBUBUR\"               \"KELAPA DUA WETAN\"      \"MUNJUL\"               \n[52] \"LUBANG BUAYA\"         \n\n\nShow the code!\nget_significant_locations(\"2022-04-30\", \"April 2022\")\n\n\n[1] \"Sub-Districts with p-value of Gi* < 0.05 in April 2022\"\n\n\n [1] \"KEAGUNGAN\"             \"GLODOK\"                \"PETOJO UTARA\"         \n [4] \"MENTENG\"               \"PETAMBURAN\"            \"KEBON MELATI\"         \n [7] \"CILINCING\"             \"KALIBARU\"              \"SEMPER BARAT\"         \n[10] \"MANGGA BESAR\"          \"MANGGARAI SELATAN\"     \"PASAR MANGGIS\"        \n[13] \"KEBAGUSAN\"             \"PONDOK LABU\"           \"LENTENG AGUNG\"        \n[16] \"JAGAKARSA\"             \"CIPEDAK\"               \"KAMPUNG TENGAH\"       \n[19] \"BALE KAMBANG\"          \"CILILITAN\"             \"KALISARI\"             \n[22] \"CIRACAS\"               \"CIPAYUNG\"              \"GAMBIR\"               \n[25] \"PETOJO SELATAN\"        \"GONDANGDIA\"            \"KEBON SIRIH\"          \n[28] \"GELORA\"                \"BENDUNGAN HILIR\"       \"KARET TENGSIN\"        \n[31] \"KEBON KACANG\"          \"KAMPUNG BALI\"          \"TANGKI\"               \n[34] \"TANAH SEREAL\"          \"TEBET BARAT\"           \"TEBET TIMUR\"          \n[37] \"CIPINANG CEMPEDAK\"     \"CILANDAK TIMUR\"        \"CIKOKO\"               \n[40] \"SRENGSENG SAWAH\"       \"CIGANJUR\"              \"TANJUNG BARAT\"        \n[43] \"BIDARA CINA\"           \"BATU AMPAR\"            \"BARU\"                 \n[46] \"CIJANTUNG\"             \"PEKAYON\"               \"PONDOK BAMBU\"         \n[49] \"HALIM PERDANA KUSUMAH\" \"CIBUBUR\"               \"KELAPA DUA WETAN\"     \n[52] \"MUNJUL\"                \"LUBANG BUAYA\"         \n\n\nShow the code!\nget_significant_locations(\"2022-05-31\", \"May 2022\")\n\n\n[1] \"Sub-Districts with p-value of Gi* < 0.05 in May 2022\"\n\n\n [1] \"KEAGUNGAN\"             \"GLODOK\"                \"MENTENG\"              \n [4] \"PETAMBURAN\"            \"KEBON MELATI\"          \"LAGOA\"                \n [7] \"CILINCING\"             \"KALIBARU\"              \"MANGGA BESAR\"         \n[10] \"RAWA BUNGA\"            \"MANGGARAI SELATAN\"     \"RAGUNAN\"              \n[13] \"KEBAGUSAN\"             \"SENAYAN\"               \"PONDOK LABU\"          \n[16] \"LENTENG AGUNG\"         \"JAGAKARSA\"             \"CIPEDAK\"              \n[19] \"KAMPUNG TENGAH\"        \"BALE KAMBANG\"          \"KALISARI\"             \n[22] \"PINANG RANTI\"          \"CIPAYUNG\"              \"GONDANGDIA\"           \n[25] \"KEBON SIRIH\"           \"GELORA\"                \"BENDUNGAN HILIR\"      \n[28] \"KEBON KACANG\"          \"KAMPUNG BALI\"          \"TANGKI\"               \n[31] \"KAMAL\"                 \"TEBET BARAT\"           \"TEBET TIMUR\"          \n[34] \"CIPINANG CEMPEDAK\"     \"CIKOKO\"                \"SRENGSENG SAWAH\"      \n[37] \"CIGANJUR\"              \"TANJUNG BARAT\"         \"BATU AMPAR\"           \n[40] \"BARU\"                  \"CIJANTUNG\"             \"PEKAYON\"              \n[43] \"HALIM PERDANA KUSUMAH\" \"CIBUBUR\"               \"KELAPA DUA WETAN\"     \n[46] \"MUNJUL\"               \n\n\nShow the code!\nget_significant_locations(\"2022-06-30\", \"June 2022\")\n\n\n[1] \"Sub-Districts with p-value of Gi* < 0.05 in June 2022\"\n\n\n [1] \"KEAGUNGAN\"             \"GLODOK\"                \"PETOJO UTARA\"         \n [4] \"SENEN\"                 \"MENTENG\"               \"PETAMBURAN\"           \n [7] \"KEBON MELATI\"          \"LAGOA\"                 \"CILINCING\"            \n[10] \"KALIBARU\"              \"MANGGA BESAR\"          \"MANGGARAI SELATAN\"    \n[13] \"RAGUNAN\"               \"PONDOK LABU\"           \"LENTENG AGUNG\"        \n[16] \"JAGAKARSA\"             \"CIPEDAK\"               \"CIPINANG BESAR UTARA\" \n[19] \"KAMPUNG TENGAH\"        \"BALE KAMBANG\"          \"KALISARI\"             \n[22] \"CIPAYUNG\"              \"GAMBIR\"                \"PETOJO SELATAN\"       \n[25] \"GONDANGDIA\"            \"KEBON SIRIH\"           \"GELORA\"               \n[28] \"BENDUNGAN HILIR\"       \"KARET TENGSIN\"         \"KEBON KACANG\"         \n[31] \"KAMPUNG BALI\"          \"TANGKI\"                \"TANAH SEREAL\"         \n[34] \"TEBET BARAT\"           \"TEBET TIMUR\"           \"CIPINANG CEMPEDAK\"    \n[37] \"CILANDAK TIMUR\"        \"CIKOKO\"                \"SRENGSENG SAWAH\"      \n[40] \"CIGANJUR\"              \"TANJUNG BARAT\"         \"BATU AMPAR\"           \n[43] \"BARU\"                  \"CIJANTUNG\"             \"PEKAYON\"              \n[46] \"MALAKA JAYA\"           \"HALIM PERDANA KUSUMAH\" \"CIBUBUR\"              \n[49] \"KELAPA DUA WETAN\"      \"MUNJUL\"               \n\n\nBelow is a table that summarises the number of times the p-value of Gi* was less than 0.05 for the respective Sub-Districts in the 12 months period (this table only shows the Sub-Districts with a significant p-value for at least 1 month):\n\n\nShow the code!\nnum_of_times = filter(combined_jakarta_gi_stars, p_sim<0.05)\nas.data.frame(table(num_of_times$Sub_District))\n\n\n                      Var1 Freq\n1                    ANCOL    1\n2             BALE KAMBANG   11\n3              BALI MESTER    4\n4                     BARU    9\n5               BATU AMPAR   12\n6          BENDUNGAN HILIR   10\n7              BIDARA CINA    9\n8      CEMPAKA PUTIH BARAT    1\n9                  CIBUBUR   10\n10                CIGANJUR   10\n11               CIJANTUNG   10\n12                  CIKINI    1\n13                  CIKOKO    8\n14          CILANDAK BARAT    3\n15          CILANDAK TIMUR    7\n16               CILILITAN    4\n17               CILINCING   10\n18                CIPAYUNG    6\n19                 CIPEDAK   10\n20  CIPINANG BESAR SELATAN    3\n21    CIPINANG BESAR UTARA    8\n22       CIPINANG CEMPEDAK   12\n23          CIPINANG MUARA    2\n24                 CIPULIR    2\n25                 CIRACAS    1\n26             DUREN SAWIT    1\n27            DURI SELATAN    1\n28                   GALUR    2\n29                  GAMBIR    5\n30                  GEDONG    3\n31                  GELORA    7\n32                  GLODOK   12\n33              GONDANGDIA    7\n34          GROGOL SELATAN    1\n35            GROGOL UTARA    1\n36   GUNUNG SAHARI SELATAN    1\n37     GUNUNG SAHARI UTARA    1\n38   HALIM PERDANA KUSUMAH   11\n39               JAGAKARSA    9\n40              JATINEGARA    1\n41         JATINEGARA KAUM    1\n42           JEMBATAN LIMA    1\n43              JOHAR BARU    1\n44                KALIBARU   10\n45                KALISARI    9\n46                   KAMAL    1\n47             KAMAL MUARA    1\n48            KAMPUNG BALI   12\n49          KAMPUNG MELAYU    3\n50            KAMPUNG RAWA    3\n51          KAMPUNG TENGAH   12\n52             KAPUK MUARA    2\n53           KARET TENGSIN    4\n54              KAYU MANIS    1\n55               KEAGUNGAN   12\n56               KEBAGUSAN    5\n57            KEBON KACANG   12\n58            KEBON MELATI   12\n59             KEBON SIRIH    7\n60              KELAPA DUA    3\n61        KELAPA DUA WETAN   11\n62     KELAPA GADING BARAT    2\n63     KELAPA GADING TIMUR    7\n64                 KLENDER    2\n65                    KOJA    2\n66                  KRAMAT    2\n67             KRAMAT JATI    3\n68                   LAGOA    9\n69           LENTENG AGUNG    9\n70            LUBANG BUAYA    5\n71             MALAKA JAYA    4\n72             MALAKA SARI    1\n73            MANGGA BESAR   12\n74       MANGGARAI SELATAN    8\n75                  MAPHAR    3\n76                 MARUNDA    1\n77                 MELAWAI    2\n78                 MENTENG    7\n79                  MUNJUL    9\n80              PAL MERIAM    1\n81                PAPANGGO    1\n82              PASAR BARU    2\n83           PASAR MANGGIS    2\n84          PEGANGSAAN DUA    3\n85           PEJATEN TIMUR    3\n86                 PEKAYON    8\n87            PENGGILINGAN    1\n88             PENJARINGAN    2\n89              PETAMBURAN   12\n90               PETOGOGAN    2\n91          PETOJO SELATAN    7\n92            PETOJO UTARA    2\n93        PETUKANGAN UTARA    1\n94            PINANG RANTI    1\n95               PINANGSIA    3\n96           PISANGAN BARU    2\n97          PISANGAN TIMUR    1\n98            PONDOK BAMBU    4\n99             PONDOK KOPI    2\n100            PONDOK LABU    9\n101            PULO GADUNG    2\n102                RAGUNAN    7\n103               RAMBUTAN    1\n104     RAWA BADAK SELATAN    1\n105       RAWA BADAK UTARA    4\n106             RAWA BARAT    1\n107             RAWA BUNGA    9\n108             ROA MALAKA    1\n109                 SELONG    2\n110           SEMPER BARAT    5\n111           SEMPER TIMUR    4\n112                SENAYAN    2\n113                  SENEN    2\n114              SRENGSENG    1\n115        SRENGSENG SAWAH    9\n116       SUKABUMI SELATAN    4\n117         SUKABUMI UTARA    3\n118           SUNTER AGUNG    1\n119            SUNTER JAYA    4\n120           TANAH SEREAL    5\n121           TANAH TINGGI    2\n122                 TANGKI   10\n123          TANJUNG BARAT    6\n124            TEBET BARAT   10\n125            TEBET TIMUR   10\n126                 TOMANG    1\n127             TUGU UTARA    5\n128                ULUJAMI    1\n\n\nHere is a gif to show how the Gi* values and their p-values change over time\n\n\n\n\n\nWe can tell that from July 2021 to September 2021, the areas of significant p-values seem to be around the Northern and Central areas.\nFrom October 2021 to June 2022, the North-East, Central and Southern areas seem to be the locations with significant p-values instead.\n\n\n4.6.3 Statistical conclusions\nFor the Sub-Districts with p-value of Gi* < 0.05, the Gi* values of the monthly vaccination rates of these locations are significant. The Gi* values of these locations are either significantly high (around 2 to 6) or significantly low (around -2 to -6).\nThroughout the 12 months, there were 128 Sub-Districts with at least 1 month of having a significant Gi* value.\nThe Gi* value of the vaccination rates for all 12 months were significant for Sub-Districts “BATU AMPAR”, “CIPINANG CEMPEDAK”, “GLODOK”, “KAMPUNG BALI”, “KAMPUNG TENGAH”, “KEAGUNGAN”, “KEBON KACANG”, “KEBON MELATI”, “MANGGA BESAR”, “PETAMBURAN”. This means that the vaccination rates for 12 months for these Sub-Districts were either significantly high or low."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hot-spot-analysis-ehsa",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#emerging-hot-spot-analysis-ehsa",
    "title": "Take-home Exercise 2: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "4.7 Emerging Hot Spot Analysis (EHSA)",
    "text": "4.7 Emerging Hot Spot Analysis (EHSA)\n\n4.7.1 Mann-Kendall Test\nIn this section, we will perform the Mann-Kendall Test using the spatio-temporal local Gi* values on 3 Sub-Districts.\n\n4.7.1.1 Sub-District 1 - “HALIM PERDANA KUSUMAH”\nFirstly, on Sub-District “HALIM PERDANA KUSUMAH”:\n\n\nShow the code!\ncbg <- gi_stars |>\n  ungroup() |>\n  filter(Sub_District == \"HALIM PERDANA KUSUMAH\") |>\n  select(Sub_District, Date, gi_star)\n\n\nPlotting the result using ggplot2 functions\n\n\nShow the code!\nggplot(data = cbg,\n       aes(x = Date,\n           y = gi_star)) + \n  geom_line() + \n  theme_light()\n\n\n\n\n\nInteractive plot using ggplotly() of plotly package:\n\n\nShow the code!\np <- ggplot(data = cbg,\n       aes(x = Date,\n           y = gi_star)) + \n  geom_line() + \n  theme_light()\n\nggplotly(p)\n\n\n\n\n\n\np-value of Mann Kendall Test:\n\n\nShow the code!\ncbg %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n\n# A tibble: 1 x 5\n    tau     sl     S     D  varS\n  <dbl>  <dbl> <dbl> <dbl> <dbl>\n1 0.394 0.0865    26  66.0  213.\n\n\nThe p-value is 0.08 which is > 0.05 hence p-value is not significant. This result tells us that here is an overall upward but insignificant trend.\n\n\n4.7.1.2 Sub-District 2 - “CIPAYUNG”\nSecondly, on Sub-District “CIPAYUNG”:\n\n\nShow the code!\ncbg <- gi_stars |>\n  ungroup() |>\n  filter(Sub_District == \"CIPAYUNG\") |>\n  select(Sub_District, Date, gi_star)\n\n\nPlotting the result using ggplot2 functions\n\n\nShow the code!\nggplot(data = cbg,\n       aes(x = Date,\n           y = gi_star)) + \n  geom_line() + \n  theme_light()\n\n\n\n\n\nInteractive plot using ggplotly() of plotly package:\n\n\nShow the code!\np <- ggplot(data = cbg,\n       aes(x = Date,\n           y = gi_star)) + \n  geom_line() + \n  theme_light()\n\nggplotly(p)\n\n\n\n\n\n\np-value of Mann Kendall Test:\n\n\nShow the code!\ncbg %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n\n# A tibble: 1 x 5\n    tau    sl     S     D  varS\n  <dbl> <dbl> <dbl> <dbl> <dbl>\n1 0.364 0.115    24  66.0  213.\n\n\nThe p-value is 0.11 which is > 0.05 hence p-value is not significant. This result tells us that here is an overall steep upward but insignificant trend.\n\n\n4.7.1.3 Sub-District 3 - “ANCOL”\nThirdly, on Sub-District “ANCOL”:\n\n\nShow the code!\ncbg <- gi_stars |>\n  ungroup() |>\n  filter(Sub_District == \"ANCOL\") |>\n  select(Sub_District, Date, gi_star)\n\n\nPlotting the result using ggplot2 functions\n\n\nShow the code!\nggplot(data = cbg,\n       aes(x = Date,\n           y = gi_star)) + \n  geom_line() + \n  theme_light()\n\n\n\n\n\nInteractive plot using ggplotly() of plotly package:\n\n\nShow the code!\np <- ggplot(data = cbg,\n       aes(x = Date,\n           y = gi_star)) + \n  geom_line() + \n  theme_light()\n\nggplotly(p)\n\n\n\n\n\n\np-value of Mann Kendall Test:\n\n\nShow the code!\ncbg %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>% \n  tidyr::unnest_wider(mk)\n\n\n# A tibble: 1 x 5\n     tau    sl     S     D  varS\n   <dbl> <dbl> <dbl> <dbl> <dbl>\n1 -0.273 0.244   -18  66.0  213.\n\n\nThe p-value is 0.24 which is > 0.05 hence p-value is not significant. This result tells us that here is an overall steep downward but insignificant trend.\n\n\n\n4.7.2 EHSA map of the Gi* values of the vaccination rate\nTo find out the significant emerging hot/cold spots, we would need to perform the Mann Kendall Test for each location. We can use group_by() of dplyr package:\n\n\nShow the code!\nehsa <- gi_stars %>%\n  group_by(Sub_District) %>%\n  summarise(mk = list(\n    unclass(\n      Kendall::MannKendall(gi_star)))) %>%\n  tidyr::unnest_wider(mk)\n\n\nArrange to show significant emerging hot/cold spots:\n\n\nShow the code!\nemerging <- ehsa %>% \n  arrange(sl, abs(tau)) %>% \n  slice(1:5)\nemerging\n\n\n# A tibble: 5 x 6\n  Sub_District       tau        sl     S     D  varS\n  <chr>            <dbl>     <dbl> <dbl> <dbl> <dbl>\n1 PETOJO UTARA    -0.970 0.0000156   -64  66.0  213.\n2 KAYU MANIS       0.970 0.0000156    64  66.0  213.\n3 JATINEGARA KAUM  0.939 0.0000287    62  66.0  213.\n4 PISANGAN BARU    0.939 0.0000287    62  66.0  213.\n5 PASAR BARU      -0.939 0.0000288   -62  66.0  213.\n\n\nPerforming Emerging Hotspot Analysis using emerging_hotspot_analysis() of sfdep package:\n\n\nShow the code!\nehsa <- emerging_hotspot_analysis(\n  x = vacc_rate_st,\n  .var = \"Vaccination_Rate\",\n  k = 1,\n  nsim = 99\n)\n\n\nNotes:\n\nIt takes a spacetime object x (i.e. varr_rate_st)\nand the quoted name of the variable of interest (i.e. Vaccination_Rate) for .var argument\nk argument is used to specify the number of time lags which is set to 1 by default\nnsim map numbers of simulation to be performed\n\nVisualisation of the distribution of EHSA classes using ggplot2 functions:\n\n\nShow the code!\nggplot(data = ehsa,\n       aes(x=classification, fill=classification)) + \n  geom_bar()\n\n\n\n\n\nThe figure shows that the oscillating hot spot class has the highest number of Sub-Districts.\nBefore we can visualise the geographic distribution of the EHSA classes, we need to join combined_jakarta and ehsa together:\n\n\nShow the code!\ncombined_jakarta_ehsa <- combined_jakarta %>%\n  left_join(ehsa, by = c(\"Sub_District\" = \"location\"))\n\n\nNext, we can plot a categorical choropleth map for the significant locations using tmap functions:\n\n\nShow the code!\n# this adds a new column \"NewClassification\" so that we can include a class called \"insignificant\" in our plot\ncombined_jakarta_ehsa <- combined_jakarta_ehsa %>% mutate(NewClassification = \n                                                            case_when(p_value < 0.05 ~ classification,\n                                                                      p_value >= 0.05 ~ \"insignificant\"))\n\n\n\n\nShow the code!\ntmap_mode(\"plot\")\ntm_shape(combined_jakarta_ehsa) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(combined_jakarta_ehsa) +\n  tm_fill(\"NewClassification\",\n          palette = c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")) + \n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n4.7.2.1 Observations of the spatial patterns\nAmong the significant places, the number of locations being classified as oscillating hotspot is the greatest, followed by sporadic coldspot, oscillating coldspot, and no pattern detected.\nThe oscillating hotspots are spread out almost evenly in the whole of Jakarta since there are so many of them.\nThe sporadic coldspots are spread out slightly less evenly than the oscillating hotspots since the borders are not covered as much and they seem to be mainly at the Central area.\nThe oscillating coldspots seem to be spread quite evenly, around the Southern, Western and Central area. They seem to be less obvious at the Northern borders.\nLastly, the locations where no patterns are detected seem to be mainly in the Central area with the rest of the locations at different parts of Jakarta.\nThe areas where the patterns are insignificant appears to be mostly at the Central area and a little at the Western and Southern area."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#geospatial-data-integration",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#geospatial-data-integration",
    "title": "Take-home Exercise 2: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "4.3 Geospatial Data Integration",
    "text": "4.3 Geospatial Data Integration\n\n4.3.1 Preliminary joining + EDA\nWe need to join the geospatial and aspatial data frames but we first need to see what they both commonly have.\nCheck column names of bd_jakarta:\n\n\nShow the code!\ncolnames(bd_jakarta)\n\n\n [1] \"Object_ID\"        \"Village_Code\"     \"Village\"          \"Code\"            \n [5] \"Province\"         \"City\"             \"District\"         \"Sub_District\"    \n [9] \"Total_Population\" \"geometry\"        \n\n\nCheck column names of vacc_jakarta:\n\n\nShow the code!\ncolnames(vacc_jakarta)\n\n\n[1] \"Date\"               \"Sub_District_Code\"  \"Sub_District\"      \n[4] \"Target\"             \"Not_Yet_Vaccinated\"\n\n\nWe are able to see that we can join the dataframes with Sub_District and Sub_District_Code:\n\n\nShow the code!\ncombined_jakarta <- left_join(bd_jakarta, vacc_jakarta,\n                              by=c(\n                                \"Sub_District\"=\"Sub_District\", \n                             \"Village_Code\"=\"Sub_District_Code\")\n                              )\n\n\nVisualising combined_jakarta in terms of:\n\npopulation not yet vaccinated\ntarget population to be vaccinated\ntotal population\n\n\n\nShow the code!\nnot_yet_vaccinated = tm_shape(combined_jakarta)+\n  tm_fill(\"Not_Yet_Vaccinated\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Not Yet Vaccinated Count\")\n\ntarget = tm_shape(combined_jakarta)+\n  tm_fill(\"Target\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Target Count\")\n\ntotal_population = tm_shape(combined_jakarta)+\n  tm_fill(\"Total_Population\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Total Count\")\n\ntmap_arrange(not_yet_vaccinated, target, total_population)\n\n\n\n\n\nChecking for empty rows in vacc_jakarta:\n\n\nShow the code!\nvacc_jakarta[rowSums(is.na(vacc_jakarta))!=0,]\n\n\n[1] Date               Sub_District_Code  Sub_District       Target            \n[5] Not_Yet_Vaccinated\n<0 rows> (or 0-length row.names)\n\n\nChecking for empty rows in bd_jakarta:\n\n\nShow the code!\nbd_jakarta[rowSums(is.na(bd_jakarta))!=0,]\n\n\nSimple feature collection with 0 features and 9 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: DGN95 / Indonesia TM-3 zone 54.1\n [1] Object_ID        Village_Code     Village          Code            \n [5] Province         City             District         Sub_District    \n [9] Total_Population geometry        \n<0 rows> (or 0-length row.names)\n\n\nThere are some missing values in the visualisations even though there are no rows with missing values in vacc_jakarta and bd_jakarta individually. This could be due to the mismatch in the values due to slightly different namings for the same sub-district when the left join was done.\n\n\n4.3.2 Identifying Mismatched Sub-District Records\nChecking for unique values of Sub-District in vacc_jakarta but not in bd_jakarta and vice versa:\n\n\nShow the code!\nvacc_subdistrict <- c(vacc_jakarta$Sub_District)\nbd_subdistrict <- c(bd_jakarta$Sub_District)\n\nunique(vacc_subdistrict[!(vacc_subdistrict %in% bd_subdistrict)])\n\n\n [1] \"BALE KAMBANG\"          \"HALIM PERDANA KUSUMAH\" \"JATI PULO\"            \n [4] \"KAMPUNG TENGAH\"        \"KERENDANG\"             \"KRAMAT JATI\"          \n [7] \"PAL MERIAM\"            \"PINANG RANTI\"          \"PULAU HARAPAN\"        \n[10] \"PULAU KELAPA\"          \"PULAU PANGGANG\"        \"PULAU PARI\"           \n[13] \"PULAU TIDUNG\"          \"PULAU UNTUNG JAWA\"     \"RAWA JATI\"            \n\n\n\n\nShow the code!\nunique(bd_subdistrict[!(bd_subdistrict %in% vacc_subdistrict)])\n\n\n[1] \"KRENDANG\"             \"RAWAJATI\"             \"TENGAH\"              \n[4] \"BALEKAMBANG\"          \"PINANGRANTI\"          \"JATIPULO\"            \n[7] \"PALMERIAM\"            \"KRAMATJATI\"           \"HALIM PERDANA KUSUMA\"\n\n\nTable to view difference in naming:\n\n\nShow the code!\n# initialise a dataframe of our cases vs bd subdistrict spelling\nspelling <- data.frame(\n  Aspatial_Cases=c(\"BALE KAMBANG\", \"HALIM PERDANA KUSUMAH\", \"JATI PULO\", \"KAMPUNG TENGAH\", \"KERENDANG\", \"KRAMAT JATI\", \"PAL MERIAM\", \"PINANG RANTI\", \"RAWA JATI\"),\n  Geospatial_BD=c(\"BALEKAMBAG\", \"HALIM PERDANA KUSUMA\", \"JATIPULO\", \"TENGAH\", \"KRENDANG\", \"KRAMATJATI\", \"PALMERIAM\", \"PINANGRANTI\", \"RAWAJATI\")\n  )\n\n# with dataframe a input, outputs a kable\nlibrary(knitr)\nlibrary(kableExtra)\nkable(spelling, caption=\"Mismatched Records\") %>%\n  kable_material(\"hover\", latex_options=\"scale_down\")\n\n\n\n\nMismatched Records\n \n  \n    Aspatial_Cases \n    Geospatial_BD \n  \n \n\n  \n    BALE KAMBANG \n    BALEKAMBAG \n  \n  \n    HALIM PERDANA KUSUMAH \n    HALIM PERDANA KUSUMA \n  \n  \n    JATI PULO \n    JATIPULO \n  \n  \n    KAMPUNG TENGAH \n    TENGAH \n  \n  \n    KERENDANG \n    KRENDANG \n  \n  \n    KRAMAT JATI \n    KRAMATJATI \n  \n  \n    PAL MERIAM \n    PALMERIAM \n  \n  \n    PINANG RANTI \n    PINANGRANTI \n  \n  \n    RAWA JATI \n    RAWAJATI \n  \n\n\n\n\n\nCorrecting the mismatched sub-district records in bd_jakarta:\n\n\nShow the code!\n# where bd_jakarta is a mismatched value, replace with the correct value\nbd_jakarta$Sub_District[bd_jakarta$Sub_District == 'BALEKAMBANG'] <- 'BALE KAMBANG'\nbd_jakarta$Sub_District[bd_jakarta$Sub_District == 'HALIM PERDANA KUSUMA'] <- 'HALIM PERDANA KUSUMAH'\nbd_jakarta$Sub_District[bd_jakarta$Sub_District == 'JATIPULO'] <- 'JATI PULO'\nbd_jakarta$Sub_District[bd_jakarta$Sub_District == 'KALI BARU'] <- 'KALIBARU'\nbd_jakarta$Sub_District[bd_jakarta$Sub_District == 'TENGAH'] <- 'KAMPUNG TENGAH'\nbd_jakarta$Sub_District[bd_jakarta$Sub_District == 'KRAMATJATI'] <- 'KRAMAT JATI'\nbd_jakarta$Sub_District[bd_jakarta$Sub_District == 'KRENDANG'] <- 'KERENDANG'\nbd_jakarta$Sub_District[bd_jakarta$Sub_District == 'PALMERIAM'] <- 'PAL MERIAM'\nbd_jakarta$Sub_District[bd_jakarta$Sub_District == 'PINANGRANTI'] <- 'PINANG RANTI'\nbd_jakarta$Sub_District[bd_jakarta$Sub_District == 'RAWAJATI'] <- 'RAWA JATI'\n\n\nThere are 6 more unique values in vacc_jakarta as those values are data referring to the outer islands looking at the fact that the rows under the column “WILAYAH KOTA” do not have the word “JAKARTA”, meaning that these places are not in Jakarta:\n\nThus, we need to remove the rows with these outer islands data:\n\n\nShow the code!\nvacc_jakarta <- vacc_jakarta[!(vacc_jakarta$Sub_District==\"PULAU HARAPAN\" | vacc_jakarta$Sub_District==\"PULAU KELAPA\" | vacc_jakarta$Sub_District==\"PULAU PANGGANG\" | vacc_jakarta$Sub_District==\"PULAU PARI\" | vacc_jakarta$Sub_District==\"PULAU TIDUNG\" | vacc_jakarta$Sub_District==\"PULAU UNTUNG JAWA\"), ]\n\n\nRe-checking for rows with NA values in vacc_jakarta:\n\n\nShow the code!\nvacc_jakarta[rowSums(is.na(vacc_jakarta))!=0,]\n\n\n[1] Date               Sub_District_Code  Sub_District       Target            \n[5] Not_Yet_Vaccinated\n<0 rows> (or 0-length row.names)\n\n\nRe-checking for rows with NA values in bd_jakarta:\n\n\nShow the code!\nbd_jakarta[rowSums(is.na(bd_jakarta))!=0,]\n\n\nSimple feature collection with 0 features and 9 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: DGN95 / Indonesia TM-3 zone 54.1\n [1] Object_ID        Village_Code     Village          Code            \n [5] Province         City             District         Sub_District    \n [9] Total_Population geometry        \n<0 rows> (or 0-length row.names)\n\n\n\n\n4.3.3 Re-joining the geospatial and aspatial data frames + EDA\n\n\nShow the code!\n# joins vacc_jakarta to bd_jakarta based on Sub_District\ncombined_jakarta <- left_join(bd_jakarta, vacc_jakarta,\n                              by=c(\"Sub_District\"=\"Sub_District\")\n                              )\n\n\nChecking for rows with NA values in combined_jakarta:\n\n\nShow the code!\ncombined_jakarta[rowSums(is.na(combined_jakarta))!=0,]\n\n\nSimple feature collection with 0 features and 13 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: DGN95 / Indonesia TM-3 zone 54.1\n [1] Object_ID          Village_Code       Village            Code              \n [5] Province           City               District           Sub_District      \n [9] Total_Population   Date               Sub_District_Code  Target            \n[13] Not_Yet_Vaccinated geometry          \n<0 rows> (or 0-length row.names)\n\n\nVisualising combined_jakarta again in terms of :\n\npopulation not yet vaccinated\ntarget population to be vaccinated\ntotal population\n\n\n\nShow the code!\nnot_yet_vaccinated = tm_shape(combined_jakarta)+\n  tm_fill(\"Not_Yet_Vaccinated\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Not Yet Vaccinated Count\")\n\ntarget = tm_shape(combined_jakarta)+\n  tm_fill(\"Target\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Target Count\")\n\ntotal_population = tm_shape(combined_jakarta)+\n  tm_fill(\"Total_Population\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title=\"Total Count\")\n\ntmap_arrange(not_yet_vaccinated, target, total_population)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#calculation-for-vaccination-rate",
    "href": "Take-home_Ex/Take-home_Ex02/Take-home_Ex02.html#calculation-for-vaccination-rate",
    "title": "Take-home Exercise 2: Spatio-temporal Analysis of COVID-19 Vaccination Trends at the Sub-district Level, DKI Jakarta",
    "section": "4.4 Calculation for Vaccination Rate",
    "text": "4.4 Calculation for Vaccination Rate\nWe need to compute the monthly vaccination rate:\n\nvaccination rate (in %) = (target - number of people not vaccinated yet) / target * 100\n\nNote: We will use “target number of people to vaccinate” instead of “total population” to calculate the vaccination rate as Indonesia excludes people age 14 and below for vaccination.\n\n\nShow the code!\n# grouping based on the sub-district and date\n# the cumulative_case_rate is based on the sum of cases over the total population\nvacc_rate <- vacc_jakarta %>%\n  inner_join(bd_jakarta, by=c(\"Sub_District\" = \"Sub_District\")) %>%\n  group_by(Sub_District, Date) %>%\n  dplyr::summarise(`vacc_rate` = ((Target-Not_Yet_Vaccinated)/Target)*100) %>%\n  \n  #afterwards, pivots the table based on the Dates, using the cumulative case rate as the values\n  ungroup() %>% pivot_wider(names_from = Date,\n              values_from = vacc_rate)\n\n\nShow Vaccination Rate:\n\n\nShow the code!\nvacc_rate\n\n\n# A tibble: 261 x 13\n   Sub_District  2021-~1 2021-~2 2021-~3 2021-~4 2021-~5 2021-~6 2022-~7 2022-~8\n   <chr>           <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 ANCOL            48.5    61.6    72.1    75.0    76.9    78.9    80.6    80.8\n 2 ANGKE            52.8    64.6    74.2    77.7    79.6    80.9    81.7    81.9\n 3 BALE KAMBANG     37.0    57.0    70.0    73.9    76.6    78.2    79.5    79.7\n 4 BALI MESTER      47.0    62.0    74.2    78.2    80.3    81.7    82.8    83.1\n 5 BAMBU APUS       47.6    64.2    76.2    80.9    82.5    83.4    84.5    84.7\n 6 BANGKA           51.6    61.3    73.2    78.0    79.8    80.7    81.5    81.7\n 7 BARU             57.9    67.6    79.5    82.9    84.2    85.0    85.8    86.0\n 8 BATU AMPAR       39.8    58.4    70.6    74.5    77.1    78.8    80.1    80.4\n 9 BENDUNGAN HI~    53.6    62.6    75.6    79.1    80.5    81.4    82.3    82.5\n10 BIDARA CINA      40.6    57.6    71.0    75.2    77.0    78.2    79.2    79.5\n# ... with 251 more rows, 4 more variables: `2022-03-31` <dbl>,\n#   `2022-04-30` <dbl>, `2022-05-31` <dbl>, `2022-06-30` <dbl>, and abbreviated\n#   variable names 1: `2021-07-31`, 2: `2021-08-31`, 3: `2021-09-30`,\n#   4: `2021-10-31`, 5: `2021-11-30`, 6: `2021-12-31`, 7: `2022-01-31`,\n#   8: `2022-02-27`\n\n\n\n4.4.1 Converting dataframes to sf objects\nBefore moving on to mapping, we should convert dataframes into sf objects\nConverting combined_jakarta and vacc_rate:\n\n\nShow the code!\ncombined_jakarta <- st_as_sf(combined_jakarta)\n\n# need to join our previous dataframes with the geospatial data to ensure that geometry column is present\nvacc_rate <- vacc_rate%>% left_join(bd_jakarta, by=c(\"Sub_District\"=\"Sub_District\"))\nvacc_rate <- st_as_sf(vacc_rate)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#installing-and-loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#installing-and-loading-the-r-packages",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "2.1 Installing and Loading the R packages",
    "text": "2.1 Installing and Loading the R packages\n\npacman::p_load(sf, sfdep, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#importing-geospatial-data",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#importing-geospatial-data",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "3.1 Importing geospatial data",
    "text": "3.1 Importing geospatial data\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\valtyl\\IS415-GAA\\In-class_Ex\\In-class_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#importing-attribute-table",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#importing-attribute-table",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "3.2 Importing attribute table",
    "text": "3.2 Importing attribute table\n\nhunan2012 <- read_csv(\"data/aspatial/Hunan_2012.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#combining-both-data-frame-by-using-a-left-join",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#combining-both-data-frame-by-using-a-left-join",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "3.3 Combining both data frame by using a left join",
    "text": "3.3 Combining both data frame by using a left join\n\nhunan_GDPPC <- left_join(hunan, hunan2012, by=\"County\") |>\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#plotting-a-choropleth-map",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#plotting-a-choropleth-map",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "3.4 Plotting a choropleth map",
    "text": "3.4 Plotting a choropleth map\n\ntmap_mode(\"plot\")\ntm_shape(hunan_GDPPC)+\n  tm_fill(\"GDPPC\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"GDPPC\") +\n  tm_layout(main.title = \"Distribution of GDP per capita by district, Hunan Province\",\n            main.title.position = \"center\",\n            main.title.size = 1.0,\n            legend.height = 0.40, \n            legend.width = 0.30,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#deriving-contiguity-weights-queens-method",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#deriving-contiguity-weights-queens-method",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "4.1 Deriving contiguity weights: Queen’s method",
    "text": "4.1 Deriving contiguity weights: Queen’s method\n\nwm_q <- hunan_GDPPC |>\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb, style='W'),\n         .before = 1)\n\n\nnb: A neighbor list object as created by st_neighbors().\nstyle: Default “W” for row standardized weights. This value can also be “B”, “C”, “U”, “minmax”, and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nallow_zero: If TRUE, assigns zero as lagged value to zone without neighbors."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#computing-global-morans-i",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#computing-global-morans-i",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "4.2 Computing Global Moran’s I",
    "text": "4.2 Computing Global Moran’s I\n\nmoranI <- global_moran(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#performing-global-morans-i-test",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#performing-global-morans-i-test",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "4.3 Performing Global Moran’s I Test",
    "text": "4.3 Performing Global Moran’s I Test\n\nglobal_moran_test(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nwe can reject null hypothesis that the observed pattern is spatial independent, meaning that it is actually dependent\nMoran I stats > 0 meaning clustered, observations tend to be similar\nthis uses raw data"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#performing-global-morans-i-permutation-test",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#performing-global-morans-i-permutation-test",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "4.4 Performing Global Moran’s I Permutation Test",
    "text": "4.4 Performing Global Moran’s I Permutation Test\n\nset.seed(1234)\n\n\nset the seed value (just at the v beginning of permutations/simulations) so that the results will always be reproducible and constant\n\n\nglobal_moran_perm(wm_q$GDPPC,\n                       wm_q$nb,\n                       wm_q$wt,\n                  nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided\n\n\n\nthis is simulations not raw data\nMoran’s I test statistic is quite similar to section 4.3 but p-value here is more significant\nsimulations always give 2 sided test"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-local-morans-i",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-local-morans-i",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "5.1 Visualising local Moran’s I",
    "text": "5.1 Visualising local Moran’s I\n\ntmap_mode(\"plot\")\ntm_shape(lisa) + \n  tm_fill(\"ii\") + \n  tm_borders(alpha=0.5) +\n  tm_view(set.zoom.limits = c(6,8))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-p-value-of-local-morans-i",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-p-value-of-local-morans-i",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "5.2 Visualising p-value of local Moran’s I",
    "text": "5.2 Visualising p-value of local Moran’s I\n\ntmap_mode(\"plot\")\ntm_shape(lisa) + \n  tm_fill(\"p_ii\") + \n  tm_borders(alpha=0.5) +\n  tm_view(set.zoom.limits = c(6,8))\n\n\n\n\n\ntmap_mode(\"plot\")\ntm_shape(lisa) + \n  tm_fill(\"p_ii_sim\") + \n  tm_borders(alpha=0.5)\n\n\n\n\n\nshould actually use p_ii_sim instead of p_ii\np_ii is only based on the raw data u use\np_ii_sim / p_folded_sim is based on simulations (just use p_ii_sim)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-local-morans-i-1",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-local-morans-i-1",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "5.3 Visualising local Moran’s I",
    "text": "5.3 Visualising local Moran’s I"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#deriving-contiguity-weights-rooks-method",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#deriving-contiguity-weights-rooks-method",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "6.1 Deriving contiguity weights: Rooks method",
    "text": "6.1 Deriving contiguity weights: Rooks method\n\nwm_r <- hunan %>%\n  mutate(nb = st_contiguity(geometry,\n                            queen = FALSE),\n         wt = st_weights(nb),\n         .before = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#hot-and-cold-spot-analysis",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#hot-and-cold-spot-analysis",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "Hot and Cold Spot Analysis",
    "text": "Hot and Cold Spot Analysis\n\nHCSA <- wm_q %>%\n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wt, nsim=99),\n      .before=1) %>%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 16 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 17\n    gi_star   e_gi     var_gi  p_value p_sim p_fol…¹ skewn…² kurto…³ nb    wt   \n      <dbl>  <dbl>      <dbl>    <dbl> <dbl>   <dbl>   <dbl>   <dbl> <nb>  <lis>\n 1 -0.00567 0.0115 0.00000812  9.95e-1  0.82    0.41   1.03    1.23  <int> <dbl>\n 2 -0.235   0.0110 0.00000581  8.14e-1  1       0.5    0.912   1.05  <int> <dbl>\n 3  0.298   0.0114 0.00000776  7.65e-1  0.7     0.35   0.455  -0.732 <int> <dbl>\n 4  0.145   0.0121 0.0000111   8.84e-1  0.64    0.32   0.900   0.726 <int> <dbl>\n 5  0.356   0.0113 0.0000119   7.21e-1  0.64    0.32   1.08    1.31  <int> <dbl>\n 6 -0.480   0.0116 0.00000706  6.31e-1  0.82    0.41   0.364  -0.676 <int> <dbl>\n 7  3.66    0.0116 0.00000825  2.47e-4  0.02    0.01   0.909   0.664 <int> <dbl>\n 8  2.14    0.0116 0.00000714  3.26e-2  0.16    0.08   1.13    1.48  <int> <dbl>\n 9  4.55    0.0113 0.00000656  5.28e-6  0.02    0.01   1.36    4.14  <int> <dbl>\n10  1.61    0.0109 0.00000341  1.08e-1  0.18    0.09   0.269  -0.396 <int> <dbl>\n# … with 78 more rows, 7 more variables: NAME_2 <chr>, ID_3 <int>,\n#   NAME_3 <chr>, ENGTYPE_3 <chr>, County <chr>, GDPPC <dbl>,\n#   geometry <POLYGON [°]>, and abbreviated variable names ¹​p_folded_sim,\n#   ²​skewness, ³​kurtosis\n\n\n\nin general, we will use g star not g\ng star perm means run simulations, g star just runs once"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-gi",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-gi",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "Visualising Gi*",
    "text": "Visualising Gi*\n\ntmap_mode(\"view\")\ntm_shape(HCSA) +\n  tm_fill(\"gi_star\") +\n  tm_borders(alpha=0.5) + \n  tm_view(set.zoom.limits = c(6,8))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-p-value-of-hcsa",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-p-value-of-hcsa",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "Visualising p-value of HCSA",
    "text": "Visualising p-value of HCSA\n\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_fill(\"p_sim\") +\n  tm_borders(alpha=0.5)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#installing-and-loading-the-r-packages-1",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#installing-and-loading-the-r-packages-1",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "Installing and Loading the R packages",
    "text": "Installing and Loading the R packages\n\npacman::p_load(sf, sfdep, tmap, plotly, tidyverse)\n\n\nplotly to make the graph interactive “ggplotly(plot)”"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#import-the-geospatial-data",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#import-the-geospatial-data",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "Import the geospatial data",
    "text": "Import the geospatial data\n\nhunan <- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\valtyl\\IS415-GAA\\In-class_Ex\\In-class_Ex07\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#import-attribute-table",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#import-attribute-table",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "Import attribute table",
    "text": "Import attribute table\n\nGDPPC <- read_csv(\"data/aspatial/Hunan_GDPPC.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#creating-a-time-series-cube",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#creating-a-time-series-cube",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "Creating a time series cube",
    "text": "Creating a time series cube\n\nGDPPC_st <- spacetime(GDPPC, hunan,\n                      .loc_col = \"County\",\n                      .time_col = \"Year\")\n\n\nspacetime takes in spatial data on the left, attribute info on the right gets combined & need to tell explicitly which field is location, which field is time\n\n\nGDPPC_st\n\n# A tibble: 1,496 × 3\n    Year County    GDPPC\n * <dbl> <chr>     <dbl>\n 1  2005 Longshan   3469\n 2  2005 Changsha  24612\n 3  2005 Wangcheng 14659\n 4  2005 Ningxiang 11687\n 5  2005 Liuyang   13406\n 6  2005 Zhuzhou    8546\n 7  2005 You       10944\n 8  2005 Chaling    8040\n 9  2005 Yanling    7383\n10  2005 Liling    11688\n# … with 1,486 more rows\n\n\n\nhas the aspatial df & geometry field\n\n\nGDPPC_nb <- GDPPC_st |>\n  activate(\"geometry\") |>\n  mutate(\n    nb = include_self(st_contiguity(geometry)),\n    wt = st_weights(nb)\n  ) |>\n  set_nbs(\"nb\") |>\n  set_wts(\"wt\")\n\n\n\n\n\nComputing Gi*\n\ngi_stars <- GDPPC_nb |>\n  group_by(Year) |>\n  mutate(gi_star = local_gstar_perm(\n    GDPPC, nb, wt, nsim=99)) |>\n      tidyr::unnest(gi_star)\ngi_stars\n\n# A tibble: 1,496 × 13\n# Groups:   Year [17]\n    Year County   GDPPC nb    wt    gi_star   e_gi  var_gi p_value p_sim p_fol…¹\n   <dbl> <chr>    <dbl> <lis> <lis>   <dbl>  <dbl>   <dbl>   <dbl> <dbl>   <dbl>\n 1  2005 Anxiang   8184 <int> <dbl>   0.540 0.0111 3.80e-6 5.89e-1  0.5     0.25\n 2  2005 Hanshou   6560 <int> <dbl>  -0.322 0.0116 4.83e-6 7.48e-1  0.9     0.45\n 3  2005 Jinshi    9956 <int> <dbl>   0.929 0.0115 4.92e-6 3.53e-1  0.36    0.18\n 4  2005 Li        8394 <int> <dbl>   1.11  0.0110 4.54e-6 2.67e-1  0.24    0.12\n 5  2005 Linli     8850 <int> <dbl>   1.43  0.0109 3.37e-6 1.52e-1  0.18    0.09\n 6  2005 Shimen    9244 <int> <dbl>   0.586 0.0109 2.28e-6 5.58e-1  0.56    0.28\n 7  2005 Liuyang  13406 <int> <dbl>   4.19  0.0110 4.19e-6 2.84e-5  0.02    0.01\n 8  2005 Ningxia… 11687 <int> <dbl>   2.25  0.0108 2.14e-6 2.46e-2  0.06    0.03\n 9  2005 Wangche… 14659 <int> <dbl>   4.00  0.0114 3.00e-6 6.40e-5  0.02    0.01\n10  2005 Anren     7423 <int> <dbl>   1.61  0.0114 2.63e-6 1.08e-1  0.16    0.08\n# … with 1,486 more rows, 2 more variables: skewness <dbl>, kurtosis <dbl>, and\n#   abbreviated variable name ¹​p_folded_sim"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#mann-kendall-test",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#mann-kendall-test",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "Mann Kendall Test",
    "text": "Mann Kendall Test\n\ncbg <- gi_stars |>\n  ungroup() |>\n  filter(County == \"Changsha\") |>\n  select(County, Year, gi_star)\n\n\ncan choose any County\n\n\nggplot(data = cbg,\n       aes(x = Year,\n           y = gi_star)) +\n  geom_line() +\n  theme_light()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#performing-emerging-hotspot-analysis",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#performing-emerging-hotspot-analysis",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "Performing Emerging Hotspot Analysis",
    "text": "Performing Emerging Hotspot Analysis\n\npacman::p_load(Kendall)\nehsa <- emerging_hotspot_analysis(\n  x = GDPPC_st,\n  .var = \"GDPPC\",\n  k = 1,\n  nsim = 99\n)\n\n\nggplot(data = ehsa,\n       aes(x=classification)) + \n  geom_bar()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "",
    "text": "This in-class introduces an alternative R package to spdep package you used in Chapter 9: Global Measures of Spatial Autocorrelation and Chapter 10: Local Measures of Spatial Autocorrelation. The package is called sfdep. According to Josiah Parry, the developer of the package, \"sfdep builds on the great shoulders of spdep package for spatial dependence. sfdep creates an sf and tidyverse friendly interface to the package as well as introduces new functionality that is not present in spdep. sfdep utilizes list columns extensively to make this interface possible.\""
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-local-morans-i-and-p-value",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-local-morans-i-and-p-value",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "5.3 Visualising local Moran’s I and p-value",
    "text": "5.3 Visualising local Moran’s I and p-value\n\ntmap_mode(\"plot\")\nmap1 <- tm_shape(lisa) +\n  tm_fill(\"ii\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"local Moran's I of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 <- tm_shape(lisa) +\n  tm_fill(\"p_ii\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of local Moran's I\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#deriving-fixed-distance-weights",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#deriving-fixed-distance-weights",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "7.1 Deriving Fixed Distance Weights",
    "text": "7.1 Deriving Fixed Distance Weights\nBefore we can derive the fixed distance weights, we need to determine the upper limit for distance band by using the steps below:\n\ngeo <- sf::st_geometry(hunan_GDPPC)\nnb <- st_knn(geo, longlat = TRUE)\ndists <- unlist(st_nb_dists(geo, nb))\n\n\nst_nb_dists() of sfdep is used to calculate the nearest neighbour distance. The output is a list of distances for each observation’s neighbors list.\nunlist() of Base R is then used to return the output as a vector so that the summary statistics of the nearest neighbour distances can be derived.\n\nNow, we will go ahead to derive summary statistics of the nearest neighbour distances vector (i.e. dists) by usign the coced chunk below.\n\nsummary(dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  21.56   29.11   36.89   37.34   43.21   65.80 \n\n\nThe summary statistics report above shows that the maximum nearest neighbour distance is 65.80km. By using a threshold value of 66km will ensure that each area will have at least one neighbour.\nNow we will go ahead to compute the fixed distance weights by using the code chunk below.\n\nwm_fd <- hunan_GDPPC %>%\n  dplyr::mutate(nb = st_dist_band(geometry,\n                                  upper = 66),\n               wt = st_weights(nb),\n               .before = 1)\n\n\nst_dists_band() of sfdep is used to identify neighbors based on a distance band (i.e. 66km). The output is a list of neighbours (i.e. nb).\nst_weights() is then used to calculate polygon spatial weights of the nb list. Note that:\nthe default style argument is set to “W” for row standardized weights, and\nthe default allow_zero is set to TRUE, assigns zero as lagged value to zone without neighbors."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#deriving-adaptive-distance-weights",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#deriving-adaptive-distance-weights",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "7.2 Deriving Adaptive Distance Weights",
    "text": "7.2 Deriving Adaptive Distance Weights\n\nwm_ad <- hunan_GDPPC %>% \n  mutate(nb = st_knn(geometry,\n                     k=8),\n         wt = st_weights(nb),\n               .before = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#calculate-inverse-distance-weights",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#calculate-inverse-distance-weights",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "7.3 Calculate Inverse Distance Weights",
    "text": "7.3 Calculate Inverse Distance Weights\n\nwm_idw <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#computing-local-morans-i-1",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#computing-local-morans-i-1",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "Computing local Moran’s I",
    "text": "Computing local Moran’s I\n\nHCSA <- wm_q |>\n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wt, nsim=99),\n      .before=1) |>\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 16 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 17\n    gi_star   e_gi     var_gi  p_value p_sim p_fol…¹ skewn…² kurto…³ nb    wt   \n      <dbl>  <dbl>      <dbl>    <dbl> <dbl>   <dbl>   <dbl>   <dbl> <nb>  <lis>\n 1 -0.00567 0.0115 0.00000812  9.95e-1  0.82    0.41   1.03    1.23  <int> <dbl>\n 2 -0.235   0.0110 0.00000581  8.14e-1  1       0.5    0.912   1.05  <int> <dbl>\n 3  0.298   0.0114 0.00000776  7.65e-1  0.7     0.35   0.455  -0.732 <int> <dbl>\n 4  0.145   0.0121 0.0000111   8.84e-1  0.64    0.32   0.900   0.726 <int> <dbl>\n 5  0.356   0.0113 0.0000119   7.21e-1  0.64    0.32   1.08    1.31  <int> <dbl>\n 6 -0.480   0.0116 0.00000706  6.31e-1  0.82    0.41   0.364  -0.676 <int> <dbl>\n 7  3.66    0.0116 0.00000825  2.47e-4  0.02    0.01   0.909   0.664 <int> <dbl>\n 8  2.14    0.0116 0.00000714  3.26e-2  0.16    0.08   1.13    1.48  <int> <dbl>\n 9  4.55    0.0113 0.00000656  5.28e-6  0.02    0.01   1.36    4.14  <int> <dbl>\n10  1.61    0.0109 0.00000341  1.08e-1  0.18    0.09   0.269  -0.396 <int> <dbl>\n# … with 78 more rows, 7 more variables: NAME_2 <chr>, ID_3 <int>,\n#   NAME_3 <chr>, ENGTYPE_3 <chr>, County <chr>, GDPPC <dbl>,\n#   geometry <POLYGON [°]>, and abbreviated variable names ¹​p_folded_sim,\n#   ²​skewness, ³​kurtosis\n\n\n\nin general, we will use g star not g\ng star perm means run simulations, g star just runs once"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-local-hcsa",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#visualising-local-hcsa",
    "title": "In-class Exercise 7: Global and Local Spatial Autocorrelation",
    "section": "Visualising local HCSA",
    "text": "Visualising local HCSA\n\ntmap_mode(\"plot\")\nmap1 <- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 <- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-geospatial-data",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.5.1 Importing geospatial data",
    "text": "8.5.1 Importing geospatial data\nThe geospatial data used in this hands-on exercise is called MP14_SUBZONE_WEB_PL. It is in ESRI shapefile format. The shapefile consists of URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in svy21 projected coordinates systems.\nThe code chunk below is used to import MP_SUBZONE_WEB_PL shapefile by using st_read() of sf packages.\n\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\valtyl\\IS415-GAA\\Hands-on_Ex\\Hands-on_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe report above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is multipolygon. it is also important to note that mpsz simple feature object does not have EPSG information."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#updating-crs-information",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#updating-crs-information",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.5.2 Updating CRS information",
    "text": "8.5.2 Updating CRS information\nThe code chunk below updates the newly imported mpsz with the correct ESPG code (i.e. 3414)\n\nmpsz_svy21 <- st_transform(mpsz, 3414)\n\nAfter transforming the projection metadata, you can varify the projection of the newly transformed mpsz_svy21 by using st_crs() of sf package.\nThe code chunk below will be used to varify the newly transformed mpsz_svy21.\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG: is indicated as 3414 now.\nNext, you will reveal the extent of mpsz_svy21 by using st_bbox() of sf package.\n\nst_bbox(mpsz_svy21) #view extent\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-the-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#importing-the-aspatial-data",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.6.1 Importing the aspatial data",
    "text": "8.6.1 Importing the aspatial data\nThe condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() function of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe codes chunks below uses glimpse() to display the data structure of will do the job.\n\ndplyr::glimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             <dbl> 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            <dbl> 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             <dbl> 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nhead(condo_resale$LONGITUDE) #see the data in XCOORD column\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\n\n\nhead(condo_resale$LATITUDE) #see the data in YCOORD column\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nNext, summary() of base R is used to display the summary statistics of cond_resale tibble data frame.\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#converting-aspatial-data-frame-into-a-sf-object",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#converting-aspatial-data-frame-into-a-sf-object",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.6.2 Converting aspatial data frame into a sf object",
    "text": "8.6.2 Converting aspatial data frame into a sf object\nCurrently, the condo_resale tibble data frame is aspatial. We will convert it to a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %>%\n  st_transform(crs=3414)\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\nNext, head() is used to list the content of condo_resale.sf object.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLI…¹ AREA_…²   AGE PROX_…³ PROX_…⁴ PROX_…⁵ PROX_…⁶ PROX_…⁷ PROX_…⁸\n     <dbl>   <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1   118635 3000000     309    30    7.94   0.166   2.52     6.62   1.77   0.0584\n2   288420 3880000     290    32    6.61   0.280   1.93     7.51   0.545  0.616 \n3   267833 3325000     248    33    6.90   0.429   0.502    6.46   0.378  0.141 \n4   258380 4250000     127     7    4.04   0.395   1.99     4.91   1.68   0.382 \n5   467169 1400000     145    28   11.8    0.119   1.12     6.41   0.565  0.461 \n6   466472 1320000     139    22   10.3    0.125   0.789    5.09   0.781  0.0994\n# … with 12 more variables: PROX_MRT <dbl>, PROX_PARK <dbl>,\n#   PROX_PRIMARY_SCH <dbl>, PROX_TOP_PRIMARY_SCH <dbl>,\n#   PROX_SHOPPING_MALL <dbl>, PROX_SUPERMARKET <dbl>, PROX_BUS_STOP <dbl>,\n#   NO_Of_UNITS <dbl>, FAMILY_FRIENDLY <dbl>, FREEHOLD <dbl>,\n#   LEASEHOLD_99YR <dbl>, geometry <POINT [m]>, and abbreviated variable names\n#   ¹​SELLING_PRICE, ²​AREA_SQM, ³​PROX_CBD, ⁴​PROX_CHILDCARE, ⁵​PROX_ELDERLYCARE,\n#   ⁶​PROX_URA_GROWTH_AREA, ⁷​PROX_HAWKER_MARKET, ⁸​PROX_KINDERGARTEN\n\n\nNotice that the output is in point feature data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#eda-using-statistical-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#eda-using-statistical-graphics",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.7.1 EDA using statistical graphics",
    "text": "8.7.1 EDA using statistical graphics\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\ncondo_resale.sf <- condo_resale.sf %>%\n  dplyr::mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, you can plot the LOG_SELLING_PRICE using the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-histogram-plots-distribution-of-variables",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.7.2 Multiple Histogram Plots distribution of variables",
    "text": "8.7.2 Multiple Histogram Plots distribution of variables\nIn this section, you will learn how to draw a small multiple histograms (also known as trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histogram into a 3 columns by 4 rows small multiple plot.\n\nAREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggpubr::ggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-statistical-point-map",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#drawing-statistical-point-map",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.7.3 Drawing Statistical Point Map",
    "text": "8.7.3 Drawing Statistical Point Map\nLastly, we want to reveal the geospatial distribution condominium resale prices in Singapore. The map will be prepared by using tmap package.\nFirst, we will turn on the interactive mode of tmap by using the code chunk below.\n\ntmap_mode(\"view\")\n\nNext, the code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) + \n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\nNotice that tm_dots() is used instead of tm_bubbles().\nset.zoom.limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.\nBefore moving on to the next section, the code below will be used to turn R display into plot mode.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#simple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#simple-linear-regression-method",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.8.1 Simple Linear Regression Method",
    "text": "8.8.1 Simple Linear Regression Method\nFirst, we will build a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nlm() returns an object of class “lm” or for multiple responses of class c(“mlm”, “lm”).\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: < 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n      *y = -258121.1 + 14719x1*\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#multiple-linear-regression-method",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.8.2 Multiple Linear Regression Method",
    "text": "8.8.2 Multiple Linear Regression Method\n\n8.8.2.1 Visualising the relationships of the independent variables\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\n# 0.8 and above, positive or negative, we should avoid\ncorrplot::corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-a-hedonic-pricing-model-using-multiple-linear-regression-method",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.8.3 Building a hedonic pricing model using multiple linear regression method",
    "text": "8.8.3 Building a hedonic pricing model using multiple linear regression method\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\n# formula = DEPENDENT VARIABLE then list out the independent variables\ncondo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  < 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  < 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  < 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  < 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#preparing-publication-quality-table-olsrr-method",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#preparing-publication-quality-table-olsrr-method",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.8.4 Preparing Publication Quality Table: olsrr method",
    "text": "8.8.4 Preparing Publication Quality Table: olsrr method\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\ncondo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                             Model Summary                               \n------------------------------------------------------------------------\nR                       0.807       RMSE                     755957.289 \nR-Squared               0.651       Coef. Var                    43.168 \nAdj. R-Squared          0.647       MSE                571471422208.591 \nPred R-Squared          0.638       MAE                      414819.628 \n------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n13.8.5 Preparing Publication Quality Table: gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %>% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n<0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n<0.001\n    AGE\n-24,688\n-30,092, -19,284\n<0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n<0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n<0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n<0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n<0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n<0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n<0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n<0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n<0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = <0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nFor more customisation options, refer to Tutorial: tbl_regression\n\n\n8.8.5.1 Checking for multicolinearity\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\n8.8.5.2 Test for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\n8.8.5.3 Test for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chunk below.\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n13.8.5.4 Testing for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr.output <- as.data.frame(condo.mlr1$residuals)\n\nNext, we will join the newly created data frame with condo_resale.sf object.\n\ncondo_resale.res.sf <- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %>%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\nNext, we will convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nThe code chunk below will be used to perform the data conversion process.\n\ncondo_resale.sp <- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nThe code chunk below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\nThe code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\nRemember to switch back to “plot” mode before continue.\n\ntmap_mode(\"plot\")\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, the Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\nnb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.\n\nnb_lw <- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value < 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-fixed-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-fixed-bandwidth-gwr-model",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.9.1 Building Fixed Bandwidth GWR Model",
    "text": "8.9.1 Building Fixed Bandwidth GWR Model\n\n8.9.1.1 Computing fixed bandwith\nIn the code chunk below bw.gwr() of GWModel package is used to determine the optimal fixed bandwidth to use in the model. Notice that the argument adaptive is set to FALSE indicates that we are interested to compute the fixed bandwidth.\nThere are two possible approaches can be uused to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using approach argeement.\n\nbw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                     PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                     PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                     PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                     FAMILY_FRIENDLY + FREEHOLD, \n                   data=condo_resale.sp, \n                   approach=\"CV\", \n                   kernel=\"gaussian\", \n                   adaptive=FALSE, \n                   longlat=FALSE)\n\nFixed bandwidth: 17660.96 CV score: 8.259118e+14 \nFixed bandwidth: 10917.26 CV score: 7.970454e+14 \nFixed bandwidth: 6749.419 CV score: 7.273273e+14 \nFixed bandwidth: 4173.553 CV score: 6.300006e+14 \nFixed bandwidth: 2581.58 CV score: 5.404958e+14 \nFixed bandwidth: 1597.687 CV score: 4.857515e+14 \nFixed bandwidth: 989.6077 CV score: 4.722431e+14 \nFixed bandwidth: 613.7939 CV score: 1.378294e+16 \nFixed bandwidth: 1221.873 CV score: 4.778717e+14 \nFixed bandwidth: 846.0596 CV score: 4.791629e+14 \nFixed bandwidth: 1078.325 CV score: 4.751406e+14 \nFixed bandwidth: 934.7772 CV score: 4.72518e+14 \nFixed bandwidth: 1023.495 CV score: 4.730305e+14 \nFixed bandwidth: 968.6643 CV score: 4.721317e+14 \nFixed bandwidth: 955.7206 CV score: 4.722072e+14 \nFixed bandwidth: 976.6639 CV score: 4.721387e+14 \nFixed bandwidth: 963.7202 CV score: 4.721484e+14 \nFixed bandwidth: 971.7199 CV score: 4.721293e+14 \nFixed bandwidth: 973.6083 CV score: 4.721309e+14 \nFixed bandwidth: 970.5527 CV score: 4.721295e+14 \nFixed bandwidth: 972.4412 CV score: 4.721296e+14 \nFixed bandwidth: 971.2741 CV score: 4.721292e+14 \nFixed bandwidth: 970.9985 CV score: 4.721293e+14 \nFixed bandwidth: 971.4443 CV score: 4.721292e+14 \nFixed bandwidth: 971.5496 CV score: 4.721293e+14 \nFixed bandwidth: 971.3793 CV score: 4.721292e+14 \nFixed bandwidth: 971.3391 CV score: 4.721292e+14 \nFixed bandwidth: 971.3143 CV score: 4.721292e+14 \nFixed bandwidth: 971.3545 CV score: 4.721292e+14 \nFixed bandwidth: 971.3296 CV score: 4.721292e+14 \nFixed bandwidth: 971.345 CV score: 4.721292e+14 \nFixed bandwidth: 971.3355 CV score: 4.721292e+14 \nFixed bandwidth: 971.3413 CV score: 4.721292e+14 \nFixed bandwidth: 971.3377 CV score: 4.721292e+14 \nFixed bandwidth: 971.34 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3408 CV score: 4.721292e+14 \nFixed bandwidth: 971.3403 CV score: 4.721292e+14 \nFixed bandwidth: 971.3406 CV score: 4.721292e+14 \nFixed bandwidth: 971.3404 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \nFixed bandwidth: 971.3405 CV score: 4.721292e+14 \n\n\nThe result shows that the recommended bandwidth is 971.3405 metres. (Quiz: Do you know why it is in metre?)\n\n\n8.9.1.2 GWModel method - fixed bandwith\nNow we can use the code chunk below to calibrate the gwr model using fixed bandwidth and gaussian kernel.\n\ngwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n                         PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + \n                         PROX_MRT   + PROX_PARK + PROX_PRIMARY_SCH + \n                         PROX_SHOPPING_MALL + PROX_BUS_STOP + NO_Of_UNITS + \n                         FAMILY_FRIENDLY + FREEHOLD, \n                       data=condo_resale.sp, \n                       bw=bw.fixed, \n                       kernel = 'gaussian', \n                       longlat = FALSE)\n\nThe output is saved in a list of class “gwrm”. The code below can be used to display the model output.\n\ngwr.fixed\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-03-06 11:11:16 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.fixed, kernel = \"gaussian\", \n    longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Fixed bandwidth: 971.3405 \n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -3.5988e+07 -5.1998e+05  7.6780e+05  1.7412e+06\n   AREA_SQM              1.0003e+03  5.2758e+03  7.4740e+03  1.2301e+04\n   AGE                  -1.3475e+05 -2.0813e+04 -8.6260e+03 -3.7784e+03\n   PROX_CBD             -7.7047e+07 -2.3608e+05 -8.3600e+04  3.4646e+04\n   PROX_CHILDCARE       -6.0097e+06 -3.3667e+05 -9.7425e+04  2.9007e+05\n   PROX_ELDERLYCARE     -3.5000e+06 -1.5970e+05  3.1971e+04  1.9577e+05\n   PROX_URA_GROWTH_AREA -3.0170e+06 -8.2013e+04  7.0749e+04  2.2612e+05\n   PROX_MRT             -3.5282e+06 -6.5836e+05 -1.8833e+05  3.6922e+04\n   PROX_PARK            -1.2062e+06 -2.1732e+05  3.5383e+04  4.1335e+05\n   PROX_PRIMARY_SCH     -2.2695e+07 -1.7066e+05  4.8472e+04  5.1555e+05\n   PROX_SHOPPING_MALL   -7.2585e+06 -1.6684e+05 -1.0517e+04  1.5923e+05\n   PROX_BUS_STOP        -1.4676e+06 -4.5207e+04  3.7601e+05  1.1664e+06\n   NO_Of_UNITS          -1.3170e+03 -2.4822e+02 -3.0846e+01  2.5496e+02\n   FAMILY_FRIENDLY      -2.2749e+06 -1.1140e+05  7.6214e+03  1.6107e+05\n   FREEHOLD             -9.2067e+06  3.8073e+04  1.5169e+05  3.7528e+05\n                             Max.\n   Intercept            112793548\n   AREA_SQM                 21575\n   AGE                     434201\n   PROX_CBD               2704596\n   PROX_CHILDCARE         1654087\n   PROX_ELDERLYCARE      38867814\n   PROX_URA_GROWTH_AREA  78515730\n   PROX_MRT               3124316\n   PROX_PARK             18122425\n   PROX_PRIMARY_SCH       4637503\n   PROX_SHOPPING_MALL     1529952\n   PROX_BUS_STOP         11342182\n   NO_Of_UNITS              12907\n   FAMILY_FRIENDLY        1720744\n   FREEHOLD               6073636\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 438.3804 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 997.6196 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 42263.61 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41632.36 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 42515.71 \n   Residual sum of squares: 2.53407e+14 \n   R-square value:  0.8909912 \n   Adjusted R-square value:  0.8430417 \n\n   ***********************************************************************\n   Program stops at: 2023-03-06 11:11:17 \n\n\nThe report shows that the AICc of the gwr is 42263.61 which is significantly smaller than the globel multiple linear regression model of 42967.1."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-adaptive-bandwidth-gwr-model",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#building-adaptive-bandwidth-gwr-model",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.9.2 Building Adaptive Bandwidth GWR Model",
    "text": "8.9.2 Building Adaptive Bandwidth GWR Model\nIn this section, we will calibrate the gwr-based hedonic pricing model by using adaptive bandwidth approach.\n\n8.9.2.1 Computing the adaptive bandwidth\nSimilar to the earlier section, we will first use bw.gwr() to determine the recommended data point to use.\nThe code chunk used look very similar to the one used to compute the fixed bandwidth except the adaptive argument has changed to TRUE.\n\nbw.adaptive <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + \n                        PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE    + \n                        PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                        PROX_PRIMARY_SCH + PROX_SHOPPING_MALL   + PROX_BUS_STOP + \n                        NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                      data=condo_resale.sp, \n                      approach=\"CV\", \n                      kernel=\"gaussian\", \n                      adaptive=TRUE, \n                      longlat=FALSE)\n\nAdaptive bandwidth: 895 CV score: 7.952401e+14 \nAdaptive bandwidth: 561 CV score: 7.667364e+14 \nAdaptive bandwidth: 354 CV score: 6.953454e+14 \nAdaptive bandwidth: 226 CV score: 6.15223e+14 \nAdaptive bandwidth: 147 CV score: 5.674373e+14 \nAdaptive bandwidth: 98 CV score: 5.426745e+14 \nAdaptive bandwidth: 68 CV score: 5.168117e+14 \nAdaptive bandwidth: 49 CV score: 4.859631e+14 \nAdaptive bandwidth: 37 CV score: 4.646518e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \nAdaptive bandwidth: 25 CV score: 4.430816e+14 \nAdaptive bandwidth: 32 CV score: 4.505602e+14 \nAdaptive bandwidth: 27 CV score: 4.462172e+14 \nAdaptive bandwidth: 30 CV score: 4.422088e+14 \n\n\nThe result shows that the 30 is the recommended data points to be used.\n\n\n8.9.2.2 Constructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and gaussian kernel as shown in the code chunk below.\n\ngwr.adaptive <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                            PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE + \n                            PROX_URA_GROWTH_AREA + PROX_MRT + PROX_PARK + \n                            PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP + \n                            NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                          data=condo_resale.sp, bw=bw.adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE, \n                          longlat = FALSE)\n\nThe code below can be used to display the model output.\n\ngwr.adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2023-03-06 11:11:27 \n   Call:\n   gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + \n    PROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + \n    PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sp, bw = bw.adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  SELLING_PRICE\n   Independent variables:  AREA_SQM AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE PROX_URA_GROWTH_AREA PROX_MRT PROX_PARK PROX_PRIMARY_SCH PROX_SHOPPING_MALL PROX_BUS_STOP NO_Of_UNITS FAMILY_FRIENDLY FREEHOLD\n   Number of data points: 1436\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3470778  -298119   -23481   248917 12234210 \n\n   Coefficients:\n                          Estimate Std. Error t value Pr(>|t|)    \n   (Intercept)           527633.22  108183.22   4.877 1.20e-06 ***\n   AREA_SQM               12777.52     367.48  34.771  < 2e-16 ***\n   AGE                   -24687.74    2754.84  -8.962  < 2e-16 ***\n   PROX_CBD              -77131.32    5763.12 -13.384  < 2e-16 ***\n   PROX_CHILDCARE       -318472.75  107959.51  -2.950 0.003231 ** \n   PROX_ELDERLYCARE      185575.62   39901.86   4.651 3.61e-06 ***\n   PROX_URA_GROWTH_AREA   39163.25   11754.83   3.332 0.000885 ***\n   PROX_MRT             -294745.11   56916.37  -5.179 2.56e-07 ***\n   PROX_PARK             570504.81   65507.03   8.709  < 2e-16 ***\n   PROX_PRIMARY_SCH      159856.14   60234.60   2.654 0.008046 ** \n   PROX_SHOPPING_MALL   -220947.25   36561.83  -6.043 1.93e-09 ***\n   PROX_BUS_STOP         682482.22  134513.24   5.074 4.42e-07 ***\n   NO_Of_UNITS             -245.48      87.95  -2.791 0.005321 ** \n   FAMILY_FRIENDLY       146307.58   46893.02   3.120 0.001845 ** \n   FREEHOLD              350599.81   48506.48   7.228 7.98e-13 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 756000 on 1421 degrees of freedom\n   Multiple R-squared: 0.6507\n   Adjusted R-squared: 0.6472 \n   F-statistic: 189.1 on 14 and 1421 DF,  p-value: < 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 8.120609e+14\n   Sigma(hat): 752522.9\n   AIC:  42966.76\n   AICc:  42967.14\n   BIC:  41731.39\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 30 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                               Min.     1st Qu.      Median     3rd Qu.\n   Intercept            -1.3487e+08 -2.4669e+05  7.7928e+05  1.6194e+06\n   AREA_SQM              3.3188e+03  5.6285e+03  7.7825e+03  1.2738e+04\n   AGE                  -9.6746e+04 -2.9288e+04 -1.4043e+04 -5.6119e+03\n   PROX_CBD             -2.5330e+06 -1.6256e+05 -7.7242e+04  2.6624e+03\n   PROX_CHILDCARE       -1.2790e+06 -2.0175e+05  8.7158e+03  3.7778e+05\n   PROX_ELDERLYCARE     -1.6212e+06 -9.2050e+04  6.1029e+04  2.8184e+05\n   PROX_URA_GROWTH_AREA -7.2686e+06 -3.0350e+04  4.5869e+04  2.4613e+05\n   PROX_MRT             -4.3781e+07 -6.7282e+05 -2.2115e+05 -7.4593e+04\n   PROX_PARK            -2.9020e+06 -1.6782e+05  1.1601e+05  4.6572e+05\n   PROX_PRIMARY_SCH     -8.6418e+05 -1.6627e+05 -7.7853e+03  4.3222e+05\n   PROX_SHOPPING_MALL   -1.8272e+06 -1.3175e+05 -1.4049e+04  1.3799e+05\n   PROX_BUS_STOP        -2.0579e+06 -7.1461e+04  4.1104e+05  1.2071e+06\n   NO_Of_UNITS          -2.1993e+03 -2.3685e+02 -3.4699e+01  1.1657e+02\n   FAMILY_FRIENDLY      -5.9879e+05 -5.0927e+04  2.6173e+04  2.2481e+05\n   FREEHOLD             -1.6340e+05  4.0765e+04  1.9023e+05  3.7960e+05\n                            Max.\n   Intercept            18758355\n   AREA_SQM                23064\n   AGE                     13303\n   PROX_CBD             11346650\n   PROX_CHILDCARE        2892127\n   PROX_ELDERLYCARE      2465671\n   PROX_URA_GROWTH_AREA  7384059\n   PROX_MRT              1186242\n   PROX_PARK             2588497\n   PROX_PRIMARY_SCH      3381462\n   PROX_SHOPPING_MALL   38038564\n   PROX_BUS_STOP        12081592\n   NO_Of_UNITS              1010\n   FAMILY_FRIENDLY       2072414\n   FREEHOLD              1813995\n   ************************Diagnostic information*************************\n   Number of data points: 1436 \n   Effective number of parameters (2trace(S) - trace(S'S)): 350.3088 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 1085.691 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 41982.22 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 41546.74 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 41914.08 \n   Residual sum of squares: 2.528227e+14 \n   R-square value:  0.8912425 \n   Adjusted R-square value:  0.8561185 \n\n   ***********************************************************************\n   Program stops at: 2023-03-06 11:11:28 \n\n\nThe report shows that the AICc the adaptive distance gwr is 41982.22 which is even smaller than the AICc of the fixed distance gwr of 42263.61."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-gwr-output",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-gwr-output",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.9.3 Visualising GWR Output",
    "text": "8.9.3 Visualising GWR Output\nIn addition to regression residuals, the output feature class table includes fields for observed and predicted y values, condition number (cond), Local R2, residuals, and explanatory variable coefficients and standard errors:\n\nCondition Number: this diagnostic evaluates local collinearity. In the presence of strong local collinearity, results become unstable. Results associated with condition numbers larger than 30, may be unreliable.\nLocal R2: these values range between 0.0 and 1.0 and indicate how well the local regression model fits observed y values. Very low values indicate the local model is performing poorly. Mapping the Local R2 values to see where GWR predicts well and where it predicts poorly may provide clues about important variables that may be missing from the regression model.\nPredicted: these are the estimated (or fitted) y values 3. computed by GWR.\nResiduals: to obtain the residual values, the fitted y values are subtracted from the observed y values. Standardized residuals have a mean of zero and a standard deviation of 1. A cold-to-hot rendered map of standardized residuals can be produce by using these values.\nCoefficient Standard Error: these values measure the reliability of each coefficient estimate. Confidence in those estimates are higher when standard errors are small in relation to the actual coefficient values. Large standard errors may indicate problems with local collinearity.\n\nThey are all stored in a SpatialPointsDataFrame or SpatialPolygonsDataFrame object integrated with fit.points, GWR coefficient estimates, y value, predicted values, coefficient standard errors and t-values in its “data” slot in an object called SDF of the output list."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#converting-sdf-into-sf-data.frame",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#converting-sdf-into-sf-data.frame",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.9.4 Converting SDF into sf data.frame",
    "text": "8.9.4 Converting SDF into sf data.frame\nTo visualise the fields in SDF, we need to first covert it into sf data.frame by using the code chunk below.\n\ncondo_resale.sf.adaptive <- st_as_sf(gwr.adaptive$SDF) %>%\n  st_transform(crs=3414)\n\n\ncondo_resale.sf.adaptive.svy21 <- st_transform(condo_resale.sf.adaptive, 3414)\ncondo_resale.sf.adaptive.svy21  \n\nSimple feature collection with 1436 features and 51 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14940.85 ymin: 24765.67 xmax: 43352.45 ymax: 48382.81\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n    Intercept  AREA_SQM        AGE  PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n1   2050011.7  9561.892  -9514.634 -120681.9      319266.92       -393417.79\n2   1633128.2 16576.853 -58185.479 -149434.2      441102.18        325188.74\n3   3433608.2 13091.861 -26707.386 -259397.8     -120116.82        535855.81\n4    234358.9 20730.601 -93308.988 2426853.7      480825.28        314783.72\n5   2285804.9  6722.836 -17608.018 -316835.5       90764.78       -137384.61\n6  -3568877.4  6039.581 -26535.592  327306.1     -152531.19       -700392.85\n7  -2874842.4 16843.575 -59166.727 -983577.2     -177810.50       -122384.02\n8   2038086.0  6905.135 -17681.897 -285076.6       70259.40        -96012.78\n9   1718478.4  9580.703 -14401.128  105803.4     -657698.02       -123276.00\n10  3457054.0 14072.011 -31579.884 -234895.4       79961.45        548581.04\n   PROX_URA_GROWTH_AREA    PROX_MRT  PROX_PARK PROX_PRIMARY_SCH\n1            -159980.20  -299742.96 -172104.47        242668.03\n2            -142290.39 -2510522.23  523379.72       1106830.66\n3            -253621.21  -936853.28  209099.85        571462.33\n4           -2679297.89 -2039479.50 -759153.26       3127477.21\n5             303714.81   -44567.05  -10284.62         30413.56\n6             -28051.25   733566.47 1511488.92        320878.23\n7            1397676.38 -2745430.34  710114.74       1786570.95\n8             269368.71   -14552.99   73533.34         53359.73\n9            -361974.72  -476785.32 -132067.59        -40128.92\n10           -150024.38 -1503835.53  574155.47        108996.67\n   PROX_SHOPPING_MALL PROX_BUS_STOP  NO_Of_UNITS FAMILY_FRIENDLY  FREEHOLD\n1          300881.390     1210615.4  104.8290640       -9075.370  303955.6\n2          -87693.378     1843587.2 -288.3441183      310074.664  396221.3\n3         -126732.712     1411924.9   -9.5532945        5949.746  168821.7\n4          -29593.342     7225577.5 -161.3551620     1556178.531 1212515.6\n5           -7490.586      677577.0   42.2659674       58986.951  328175.2\n6          258583.881     1086012.6 -214.3671271      201992.641  471873.1\n7         -384251.210     5094060.5   -0.9212521      359659.512  408871.9\n8          -39634.902      735767.1   30.1741069       55602.506  347075.0\n9          276718.757     2815772.4  675.1615559      -30453.297  503872.8\n10        -454726.822     2123557.0  -21.3044311     -100935.586  213324.6\n         y    yhat    residual CV_Score Stud_residual Intercept_SE AREA_SQM_SE\n1  3000000 2886532   113468.16        0    0.38207013     516105.5    823.2860\n2  3880000 3466801   413198.52        0    1.01433140     488083.5    825.2380\n3  3325000 3616527  -291527.20        0   -0.83780678     963711.4    988.2240\n4  4250000 5435482 -1185481.63        0   -2.84614670     444185.5    617.4007\n5  1400000 1388166    11834.26        0    0.03404453    2119620.6   1376.2778\n6  1320000 1516702  -196701.94        0   -0.72065800   28572883.7   2348.0091\n7  3410000 3266881   143118.77        0    0.41291992     679546.6    893.5893\n8  1420000 1431955   -11955.27        0   -0.03033109    2217773.1   1415.2604\n9  2025000 1832799   192200.83        0    0.52018109     814281.8    943.8434\n10 2550000 2223364   326635.53        0    1.10559735    2410252.0   1271.4073\n      AGE_SE PROX_CBD_SE PROX_CHILDCARE_SE PROX_ELDERLYCARE_SE\n1   5889.782    37411.22          319111.1           120633.34\n2   6226.916    23615.06          299705.3            84546.69\n3   6510.236    56103.77          349128.5           129687.07\n4   6010.511   469337.41          304965.2           127150.69\n5   8180.361   410644.47          698720.6           327371.55\n6  14601.909  5272846.47         1141599.8          1653002.19\n7   8970.629   346164.20          530101.1           148598.71\n8   8661.309   438035.69          742532.8           399221.05\n9  11791.208    89148.35          704630.7           329683.30\n10  9941.980   173532.77          500976.2           281876.74\n   PROX_URA_GROWTH_AREA_SE PROX_MRT_SE PROX_PARK_SE PROX_PRIMARY_SCH_SE\n1                 56207.39    185181.3     205499.6            152400.7\n2                 76956.50    281133.9     229358.7            165150.7\n3                 95774.60    275483.7     314124.3            196662.6\n4                470762.12    279877.1     227249.4            240878.9\n5                474339.56    363830.0     364580.9            249087.7\n6               5496627.21    730453.2    1741712.0            683265.5\n7                371692.97    375511.9     297400.9            344602.8\n8                517977.91    423155.4     440984.4            261251.2\n9                153436.22    285325.4     304998.4            278258.5\n10               239182.57    571355.7     599131.8            331284.8\n   PROX_SHOPPING_MALL_SE PROX_BUS_STOP_SE NO_Of_UNITS_SE FAMILY_FRIENDLY_SE\n1               109268.8         600668.6       218.1258           131474.7\n2                98906.8         410222.1       208.9410           114989.1\n3               119913.3         464156.7       210.9828           146607.2\n4               177104.1         562810.8       361.7767           108726.6\n5               301032.9         740922.4       299.5034           160663.7\n6              2931208.6        1418333.3       602.5571           331727.0\n7               249969.5         821236.4       532.1978           129241.2\n8               351634.0         775038.4       338.6777           171895.1\n9               289872.7         850095.5       439.9037           220223.4\n10              265529.7         631399.2       259.0169           189125.5\n   FREEHOLD_SE Intercept_TV AREA_SQM_TV     AGE_TV PROX_CBD_TV\n1     115954.0    3.9720784   11.614302  -1.615447 -3.22582173\n2     130110.0    3.3460017   20.087361  -9.344188 -6.32792021\n3     141031.5    3.5629010   13.247868  -4.102368 -4.62353528\n4     138239.1    0.5276150   33.577223 -15.524302  5.17080808\n5     210641.1    1.0784029    4.884795  -2.152474 -0.77155660\n6     374347.3   -0.1249043    2.572214  -1.817269  0.06207388\n7     182216.9   -4.2305303   18.849348  -6.595605 -2.84136028\n8     216649.4    0.9189786    4.879056  -2.041481 -0.65080678\n9     220473.7    2.1104224   10.150733  -1.221345  1.18682383\n10    206346.2    1.4343123   11.068059  -3.176418 -1.35360852\n   PROX_CHILDCARE_TV PROX_ELDERLYCARE_TV PROX_URA_GROWTH_AREA_TV PROX_MRT_TV\n1         1.00048819          -3.2612693            -2.846248368 -1.61864578\n2         1.47178634           3.8462625            -1.848971738 -8.92998600\n3        -0.34404755           4.1319138            -2.648105057 -3.40075727\n4         1.57665606           2.4756745            -5.691404992 -7.28705261\n5         0.12990138          -0.4196596             0.640289855 -0.12249416\n6        -0.13361179          -0.4237096            -0.005103357  1.00426206\n7        -0.33542751          -0.8235874             3.760298131 -7.31116712\n8         0.09462126          -0.2405003             0.520038994 -0.03439159\n9        -0.93339393          -0.3739225            -2.359121712 -1.67102293\n10        0.15961128           1.9461735            -0.627237944 -2.63204802\n   PROX_PARK_TV PROX_PRIMARY_SCH_TV PROX_SHOPPING_MALL_TV PROX_BUS_STOP_TV\n1   -0.83749312           1.5923022            2.75358842        2.0154464\n2    2.28192684           6.7019454           -0.88662640        4.4941192\n3    0.66565951           2.9058009           -1.05686949        3.0419145\n4   -3.34061770          12.9836105           -0.16709578       12.8383775\n5   -0.02820944           0.1220998           -0.02488294        0.9145046\n6    0.86781794           0.4696245            0.08821750        0.7656963\n7    2.38773567           5.1844351           -1.53719231        6.2029165\n8    0.16674816           0.2042469           -0.11271635        0.9493299\n9   -0.43301073          -0.1442145            0.95462153        3.3123012\n10   0.95831249           0.3290120           -1.71252687        3.3632555\n   NO_Of_UNITS_TV FAMILY_FRIENDLY_TV FREEHOLD_TV  Local_R2\n1     0.480589953        -0.06902748    2.621347 0.8846744\n2    -1.380026395         2.69655779    3.045280 0.8899773\n3    -0.045279967         0.04058290    1.197050 0.8947007\n4    -0.446007570        14.31276425    8.771149 0.9073605\n5     0.141120178         0.36714544    1.557983 0.9510057\n6    -0.355762335         0.60891234    1.260522 0.9247586\n7    -0.001731033         2.78285441    2.243875 0.8310458\n8     0.089093858         0.32346758    1.602012 0.9463936\n9     1.534793921        -0.13828365    2.285410 0.8380365\n10   -0.082251138        -0.53369623    1.033819 0.9080753\n                    geometry\n1  POINT (22085.12 29951.54)\n2   POINT (25656.84 34546.2)\n3   POINT (23963.99 32890.8)\n4  POINT (27044.28 32319.77)\n5  POINT (41042.56 33743.64)\n6   POINT (39717.04 32943.1)\n7   POINT (28419.1 33513.37)\n8  POINT (40763.57 33879.61)\n9  POINT (23595.63 28884.78)\n10 POINT (24586.56 33194.31)\n\n\n\ngwr.adaptive.output <- as.data.frame(gwr.adaptive$SDF)\ncondo_resale.sf.adaptive <- cbind(condo_resale.res.sf, as.matrix(gwr.adaptive.output))\n\nNext, glimpse() is used to display the content of condo_resale.sf.adaptive sf data frame.\n\nglimpse(condo_resale.sf.adaptive)\n\nRows: 1,436\nColumns: 77\n$ POSTCODE                <dbl> 118635, 288420, 267833, 258380, 467169, 466472…\n$ SELLING_PRICE           <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ AREA_SQM                <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 1…\n$ AGE                     <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22,…\n$ PROX_CBD                <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783…\n$ PROX_CHILDCARE          <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543…\n$ PROX_ELDERLYCARE        <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.…\n$ PROX_URA_GROWTH_AREA    <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.4106…\n$ PROX_HAWKER_MARKET      <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969…\n$ PROX_KINDERGARTEN       <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076…\n$ PROX_MRT                <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.…\n$ PROX_PARK               <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.…\n$ PROX_PRIMARY_SCH        <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.…\n$ PROX_TOP_PRIMARY_SCH    <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.…\n$ PROX_SHOPPING_MALL      <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.…\n$ PROX_SUPERMARKET        <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.…\n$ PROX_BUS_STOP           <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340…\n$ NO_Of_UNITS             <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34…\n$ FAMILY_FRIENDLY         <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD                <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR          <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ LOG_SELLING_PRICE       <dbl> 14.91412, 15.17135, 15.01698, 15.26243, 14.151…\n$ MLR_RES                 <dbl> -1489099.55, 415494.57, 194129.69, 1088992.71,…\n$ Intercept               <dbl> 2050011.67, 1633128.24, 3433608.17, 234358.91,…\n$ AREA_SQM.1              <dbl> 9561.892, 16576.853, 13091.861, 20730.601, 672…\n$ AGE.1                   <dbl> -9514.634, -58185.479, -26707.386, -93308.988,…\n$ PROX_CBD.1              <dbl> -120681.94, -149434.22, -259397.77, 2426853.66…\n$ PROX_CHILDCARE.1        <dbl> 319266.925, 441102.177, -120116.816, 480825.28…\n$ PROX_ELDERLYCARE.1      <dbl> -393417.795, 325188.741, 535855.806, 314783.72…\n$ PROX_URA_GROWTH_AREA.1  <dbl> -159980.203, -142290.389, -253621.206, -267929…\n$ PROX_MRT.1              <dbl> -299742.96, -2510522.23, -936853.28, -2039479.…\n$ PROX_PARK.1             <dbl> -172104.47, 523379.72, 209099.85, -759153.26, …\n$ PROX_PRIMARY_SCH.1      <dbl> 242668.03, 1106830.66, 571462.33, 3127477.21, …\n$ PROX_SHOPPING_MALL.1    <dbl> 300881.390, -87693.378, -126732.712, -29593.34…\n$ PROX_BUS_STOP.1         <dbl> 1210615.44, 1843587.22, 1411924.90, 7225577.51…\n$ NO_Of_UNITS.1           <dbl> 104.8290640, -288.3441183, -9.5532945, -161.35…\n$ FAMILY_FRIENDLY.1       <dbl> -9075.370, 310074.664, 5949.746, 1556178.531, …\n$ FREEHOLD.1              <dbl> 303955.61, 396221.27, 168821.75, 1212515.58, 3…\n$ y                       <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1…\n$ yhat                    <dbl> 2886531.8, 3466801.5, 3616527.2, 5435481.6, 13…\n$ residual                <dbl> 113468.16, 413198.52, -291527.20, -1185481.63,…\n$ CV_Score                <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ Stud_residual           <dbl> 0.38207013, 1.01433140, -0.83780678, -2.846146…\n$ Intercept_SE            <dbl> 516105.5, 488083.5, 963711.4, 444185.5, 211962…\n$ AREA_SQM_SE             <dbl> 823.2860, 825.2380, 988.2240, 617.4007, 1376.2…\n$ AGE_SE                  <dbl> 5889.782, 6226.916, 6510.236, 6010.511, 8180.3…\n$ PROX_CBD_SE             <dbl> 37411.22, 23615.06, 56103.77, 469337.41, 41064…\n$ PROX_CHILDCARE_SE       <dbl> 319111.1, 299705.3, 349128.5, 304965.2, 698720…\n$ PROX_ELDERLYCARE_SE     <dbl> 120633.34, 84546.69, 129687.07, 127150.69, 327…\n$ PROX_URA_GROWTH_AREA_SE <dbl> 56207.39, 76956.50, 95774.60, 470762.12, 47433…\n$ PROX_MRT_SE             <dbl> 185181.3, 281133.9, 275483.7, 279877.1, 363830…\n$ PROX_PARK_SE            <dbl> 205499.6, 229358.7, 314124.3, 227249.4, 364580…\n$ PROX_PRIMARY_SCH_SE     <dbl> 152400.7, 165150.7, 196662.6, 240878.9, 249087…\n$ PROX_SHOPPING_MALL_SE   <dbl> 109268.8, 98906.8, 119913.3, 177104.1, 301032.…\n$ PROX_BUS_STOP_SE        <dbl> 600668.6, 410222.1, 464156.7, 562810.8, 740922…\n$ NO_Of_UNITS_SE          <dbl> 218.1258, 208.9410, 210.9828, 361.7767, 299.50…\n$ FAMILY_FRIENDLY_SE      <dbl> 131474.73, 114989.07, 146607.22, 108726.62, 16…\n$ FREEHOLD_SE             <dbl> 115954.0, 130110.0, 141031.5, 138239.1, 210641…\n$ Intercept_TV            <dbl> 3.9720784, 3.3460017, 3.5629010, 0.5276150, 1.…\n$ AREA_SQM_TV             <dbl> 11.614302, 20.087361, 13.247868, 33.577223, 4.…\n$ AGE_TV                  <dbl> -1.6154474, -9.3441881, -4.1023685, -15.524301…\n$ PROX_CBD_TV             <dbl> -3.22582173, -6.32792021, -4.62353528, 5.17080…\n$ PROX_CHILDCARE_TV       <dbl> 1.000488185, 1.471786337, -0.344047555, 1.5766…\n$ PROX_ELDERLYCARE_TV     <dbl> -3.26126929, 3.84626245, 4.13191383, 2.4756745…\n$ PROX_URA_GROWTH_AREA_TV <dbl> -2.846248368, -1.848971738, -2.648105057, -5.6…\n$ PROX_MRT_TV             <dbl> -1.61864578, -8.92998600, -3.40075727, -7.2870…\n$ PROX_PARK_TV            <dbl> -0.83749312, 2.28192684, 0.66565951, -3.340617…\n$ PROX_PRIMARY_SCH_TV     <dbl> 1.59230221, 6.70194543, 2.90580089, 12.9836104…\n$ PROX_SHOPPING_MALL_TV   <dbl> 2.753588422, -0.886626400, -1.056869486, -0.16…\n$ PROX_BUS_STOP_TV        <dbl> 2.0154464, 4.4941192, 3.0419145, 12.8383775, 0…\n$ NO_Of_UNITS_TV          <dbl> 0.480589953, -1.380026395, -0.045279967, -0.44…\n$ FAMILY_FRIENDLY_TV      <dbl> -0.06902748, 2.69655779, 0.04058290, 14.312764…\n$ FREEHOLD_TV             <dbl> 2.6213469, 3.0452799, 1.1970499, 8.7711485, 1.…\n$ Local_R2                <dbl> 0.8846744, 0.8899773, 0.8947007, 0.9073605, 0.…\n$ coords.x1               <dbl> 22085.12, 25656.84, 23963.99, 27044.28, 41042.…\n$ coords.x2               <dbl> 29951.54, 34546.20, 32890.80, 32319.77, 33743.…\n$ geometry                <POINT [m]> POINT (22085.12 29951.54), POINT (25656.…\n\n\n\nsummary(gwr.adaptive$SDF$yhat)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n  171347  1102001  1385528  1751842  1982307 13887901"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-local-r2",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-local-r2",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.9.5 Visualising local R2",
    "text": "8.9.5 Visualising local R2\nThe code chunks below is used to create an interactive point symbol map.\n\ntmap_mode(\"view\")\ntm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"Local_R2\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-coefficient-estimates",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#visualising-coefficient-estimates",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "8.9.6 Visualising coefficient estimates",
    "text": "8.9.6 Visualising coefficient estimates\nThe code chunks below is used to create an interactive point symbol map.\n\ntmap_mode(\"view\")\nAREA_SQM_SE <- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_SE\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\nAREA_SQM_TV <- tm_shape(mpsz_svy21)+\n  tm_polygons(alpha = 0.1) +\ntm_shape(condo_resale.sf.adaptive) +  \n  tm_dots(col = \"AREA_SQM_TV\",\n          border.col = \"gray60\",\n          border.lwd = 1) +\n  tm_view(set.zoom.limits = c(11,14))\n\ntmap_arrange(AREA_SQM_SE, AREA_SQM_TV, \n             asp=1, ncol=2,\n             sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\n8.9.6.1 By URA Planning Region\n\ntm_shape(mpsz_svy21[mpsz_svy21$REGION_N==\"CENTRAL REGION\", ])+\n  tm_polygons()+\ntm_shape(condo_resale.sf.adaptive) + \n  tm_bubbles(col = \"Local_R2\",\n           size = 0.15,\n           border.col = \"gray60\",\n           border.lwd = 1)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex08/Hands-on_Ex08.html#reference",
    "title": "Hands-on Exercise 8: Calibrating Hedonic Pricing Model for Private Highrise Property with Geographically Weighted Regression (GWR) Method",
    "section": "13.10 Reference",
    "text": "13.10 Reference\nGollini I, Lu B, Charlton M, Brunsdon C, Harris P (2015) “GWmodel: an R Package for exploring Spatial Heterogeneity using Geographically Weighted Models”. Journal of Statistical Software, 63(17):1-50, http://www.jstatsoft.org/v63/i17/\nLu B, Harris P, Charlton M, Brunsdon C (2014) “The GWmodel R Package: further topics for exploring Spatial Heterogeneity using GeographicallyWeighted Models”. Geo-spatial Information Science 17(2): 85-101, http://www.tandfonline.com/doi/abs/10.1080/1009502.2014.917453"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "href": "Hands-on_Ex/Hands-on_Ex07/Hands-on_Ex07.html",
    "title": "Hands-on Exercise 7: Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "7.1 Overview"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "title": "In-class Exercise 8: Global and Local Spatial Autocorrelation",
    "section": "",
    "text": "1 Overview\n\n\n2 The Data\n\n\n3 Getting Started\n\n# install corrplot manually\npacman::p_load(olsrr, readr, ggpubr, sf, spdep, GWmodel, tmap, tidyr, dyplr, tidyverse, gtsummary)\n\n\nmpsz = st_read(dsn = \"data/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\") %>% st_transform(crs=3414)\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\valtyl\\IS415-GAA\\In-class_Ex\\In-class_Ex08\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\ncondo_resale = read_csv(\"data/aspatial/Condo_resale_2015.csv\")\n\n\ndplyr::glimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             <dbl> 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            <dbl> 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             <dbl> 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        <dbl> 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             <dbl> 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  <dbl> 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             <dbl> 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       <dbl> 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     <dbl> 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA <dbl> 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   <dbl> 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    <dbl> 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             <dbl> 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            <dbl> 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     <dbl> 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH <dbl> 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   <dbl> 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     <dbl> 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        <dbl> 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          <dbl> 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      <dbl> 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\ncondo_resale.sf <- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %>%\n  st_transform(crs=3414)\n\n\ncondo_resale.sf <- condo_resale.sf %>%\n  dplyr::mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\n\ncondo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#preparing-nearest-neighbours-list",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#preparing-nearest-neighbours-list",
    "title": "In-class Exercise 5: Advanced Spatial Point Patterns Analysis: Local Co-Location Quotient",
    "section": "1.5.1 Preparing nearest neighbours list",
    "text": "1.5.1 Preparing nearest neighbours list\nIn the code chunk below, st_knn() of sfdep package is used to determine the k (i.e. 6) nearest neighbours for given point geometry.\n\nnb <- include_self(\n  st_knn(st_geometry(stores), 6)\n)\n\n\nnb: nearest neighbours list\n6: search for the 6 nearest neighbours (good to use even numbers when use include_self)\ninclude_self: so it will include myself and the neighbours (6+1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-kernel-weights",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-kernel-weights",
    "title": "In-class Exercise 5: Advanced Spatial Point Patterns Analysis: Local Co-Location Quotient",
    "section": "1.5.2 Computing kernel weights",
    "text": "1.5.2 Computing kernel weights\nIn the code chunk below, st_kernel_weights() of sfdep package is used to derive a weights list by using a kernel function.\n\nwt <- st_kernel_weights(nb,\n                        stores,\n                        \"gaussian\",\n                        adaptive = TRUE)\n\n\nstores is the target\nst_kernel_weights: convert into a weights matrix\nnearer get higher weights, further get lower weights"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#preparing-the-vector-list",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#preparing-the-vector-list",
    "title": "In-class Exercise 5: Advanced Spatial Point Patterns Analysis: Local Co-Location Quotient",
    "section": "1.5.3 Preparing the vector list",
    "text": "1.5.3 Preparing the vector list\nTo compute LCLQ by using sfdep package, the reference point data must be in either character or vector list. The code chunks below are used to prepare two vector lists. One of Family Mart and for 7-11 and are called A and B respectively.\n\nFamilyMart <- stores %>%\n  filter(Name == \"Family Mart\")\nA <- FamilyMart$Name\n\n\nlat, long in the data is not important since we alr have the geometry column. lat, long can be dropped if want to\n\n\nSevenEleven <- stores %>%\n  filter(Name == \"7-Eleven\")\nB <- SevenEleven$Name"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-lclq",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#computing-lclq",
    "title": "In-class Exercise 5: Advanced Spatial Point Patterns Analysis: Local Co-Location Quotient",
    "section": "1.5.4 Computing LCLQ",
    "text": "1.5.4 Computing LCLQ\nIn the code chunk below local_colocation() us used to compute the LCLQ values for each Family Mart point event.\n\nLCLQ <- local_colocation(A, B, nb, wt, 49)\n\n\nA: the target\nB: the neighbour\nnb: neighbours list\nwt: weights\nwant to find out if target is colocated with the neighbour\n49: running 50 simulations\noutput (click LCLQ datatable): first col is whether there is a neighbour or not, second col is p-values. there are different levels of p-values. NA indicates that they cannot find useful indexes to work with"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#joining-output-table",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#joining-output-table",
    "title": "In-class Exercise 5: Advanced Spatial Point Patterns Analysis: Local Co-Location Quotient",
    "section": "1.5.5 Joining output table",
    "text": "1.5.5 Joining output table\nBefore we can plot the LCLQ values their p-values, we need to join the output of local_colocation() to the stores sf data.frame. However, a quick check of LCLQ data-frame, we can't find any field can be used as the join field. As a result, cbind() of Base R is used.\n\nLCLQ_stores <- cbind(stores, LCLQ)\n\n\ntotal points is 1409\n563 (family mart) + 846 (7-11)\ncbind(): combining the stores and the local colocation quotient table (make sure the results of both are NOT SORTED before using cbind() else will append wrong info)\ncannot do relational join like left.join() or right.join() bc both dont have unique identifier\ncbind()’s first variable should be stores so that they will inherit the property of stores (which is geometry). they always inherit the property of the first variable"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#plotting-lclq-values",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#plotting-lclq-values",
    "title": "In-class Exercise 5: Advanced Spatial Point Patterns Analysis: Local Co-Location Quotient",
    "section": "Plotting LCLQ values",
    "text": "Plotting LCLQ values\nIn the code chunk below, tmap functions are used to plot the LCLQ analysis.\n\ntmap_mode(\"view\")\ntm_shape(studyArea) +\n  tm_polygons() +\n  tm_shape(LCLQ_stores) +\n  tm_dots(col = \"X7.Eleven\",\n          size = 0.01,\n          border.col = \"black\",\n          border.lwd = 0.5) +\n  tm_view(set.zoom.limits = c(12,16))"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Prices using Geographically Weighted Methods",
    "section": "",
    "text": "Housing is an essential component of household wealth worldwide. Buying a housing has always been a major investment for most people. The price of housing is affected by many factors. Some of them are global in nature such as the general economy of a country or inflation rate. Others can be more specific to the properties themselves. These factors can be further divided to structural and locational factors. Structural factors are variables related to the property themselves such as the size, fitting, and tenure of the property. Locational factors are variables related to the neighbourhood of the properties such as proximity to childcare centre, public transport service and shopping centre.\nConventional, housing resale prices predictive models were built by using Ordinary Least Square (OLS) method. However, this method failed to take into consideration that spatial autocorrelation and spatial heterogeneity exist in geographic data sets such as housing transactions. With the existence of spatial autocorrelation, the OLS estimation of predictive housing resale pricing models could lead to biased, inconsistent, or inefficient results (Anselin 1998). In view of this limitation, Geographical Weighted Models were introduced for calibrating predictive model for housing resale prices."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#aspatial-data",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Prices using Geographically Weighted Methods",
    "section": "3.1 Aspatial Data",
    "text": "3.1 Aspatial Data\nFor the purpose of this take-home exercise, HDB Resale Flat Prices provided by Data.gov.sg should be used as the core data set. The study should focus on either three-room, four-room or five-room flat and transaction period should be from 1st January 2021 to 31st December 2022. The test data should be January and February 2023 resale prices."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#geospatial-data",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Prices using Geographically Weighted Methods",
    "section": "3.2 Geospatial Data",
    "text": "3.2 Geospatial Data\nWe can consider the following predictors/independent variables to see how they affect the HDB resale prices:\n\nLocational factors\n\nProximity to CBD\nProximity to eldercare services\nProximity to hawker centres\nProximity to MRT\nProximity to park\nProximity to good primary school\nProximity to shopping mall\nProximity to supermarket\nProximity to CHAS clinics\nNumbers of kindergartens within 350m\nNumbers of childcare centres within 350m\nNumbers of bus stop within 350m\nNumbers of primary school within 1km\n\n\nBased on the factors above, we will gather the following data:\n\n\nShow the code!\n# initialise a dataframe of our aspatial and geospatial dataset details\ndatasets <- data.frame(\n  Type=c(\"Aspatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n         \"Geospatial\",\n\n         \"Geospatial\",\n         \"Geospatial\",\n         \n         \"Geospatial\",\n         \"Geospatial\",\n         \n         \"Geospatial - Selfsourced\",\n         \"Geospatial - Selfsourced\"),\n  \n  Name=c(\"Resale Flat Prices\",\n         \"Singapore National Boundary\",\n         \"Master Plan 2014 Subzone Boundary (Web)\",\n         \"Eldercare Services\",\n         \"Hawker Centres\",\n         \"Supermarkets\",\n         \"Parks\",\n         \n         \"Childcare Services and Kindergartens\",\n         \"Community Health Assistance Scheme (CHAS) Clinics\",\n         \n         \n         \"Bus Stop Locations Feb 2023\",\n         \"Shopping Mall SVY21 Coordinates\",\n         \"MRT Locations Feb 2023\",\n         \"Primary Schools\"),\n  \n  Format=c(\".csv\", \n           \".shp\", \n           \".shp\",\n           \".shp\",\n           \".kml\",\n           \".kml\",\n           \".kml\",\n           \n           \".kml\",\n           \".kml\", \n           \n           \".shp\",\n           \n           \".csv\",\n           \".xlsx\",\n           \".xlsx\"),\n  \n  Source=c(\"https://data.gov.sg/dataset/resale-flat-prices\",\n           \"https://data.gov.sg/dataset/national-map-polygon\",\n           \"https://data.gov.sg/dataset/master-plan-2014-subzone-boundary-web\",\n           \"https://data.gov.sg/dataset/eldercare-services\",\n           \"https://data.gov.sg/dataset/hawker-centres\",\n           \"https://data.gov.sg/dataset/supermarkets\",\n           \"https://data.gov.sg/dataset/nparks-parks-and-nature-reserves\",\n           \n           \n           \"https://dataportal.asia/dataset/203030733_pre-schools-location\",\n           \"https://dataportal.asia/ne/dataset/192501037_chas-clinics/resource/21dace06-c4d1-4128-9424-aba7668050dc\",\n           \n           \"https://datamall.lta.gov.sg/content/datamall/en/search_datasets.html?searchText=bus%20stop\",\n           \"https://github.com/ValaryLim/Mall-Coordinates-Web-Scraper\",\n           \"https://www.lta.gov.sg/content/ltagov/en/getting_around/public_transport/rail_network.html\",\n           \n           \"https://www.moe.gov.sg/about-us/organisation-structure/sd/school-clusters\"\n           )\n  )\n\n# with reference to this guide on kableExtra:\n# https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html\n# kable_material is the name of the kable theme\n# 'hover' for to highlight row when hovering, 'scale_down' to adjust table to fit page width\nlibrary(knitr)\nlibrary(kableExtra)\nkable(datasets, caption=\"Datasets Used\") %>%\n  kable_material(\"hover\", latex_options=\"scale_down\")\n\n\n\n\nDatasets Used\n \n  \n    Type \n    Name \n    Format \n    Source \n  \n \n\n  \n    Aspatial \n    Resale Flat Prices \n    .csv \n    https://data.gov.sg/dataset/resale-flat-prices \n  \n  \n    Geospatial \n    Singapore National Boundary \n    .shp \n    https://data.gov.sg/dataset/national-map-polygon \n  \n  \n    Geospatial \n    Master Plan 2014 Subzone Boundary (Web) \n    .shp \n    https://data.gov.sg/dataset/master-plan-2014-subzone-boundary-web \n  \n  \n    Geospatial \n    Eldercare Services \n    .shp \n    https://data.gov.sg/dataset/eldercare-services \n  \n  \n    Geospatial \n    Hawker Centres \n    .kml \n    https://data.gov.sg/dataset/hawker-centres \n  \n  \n    Geospatial \n    Supermarkets \n    .kml \n    https://data.gov.sg/dataset/supermarkets \n  \n  \n    Geospatial \n    Parks \n    .kml \n    https://data.gov.sg/dataset/nparks-parks-and-nature-reserves \n  \n  \n    Geospatial \n    Childcare Services and Kindergartens \n    .kml \n    https://dataportal.asia/dataset/203030733_pre-schools-location \n  \n  \n    Geospatial \n    Community Health Assistance Scheme (CHAS) Clinics \n    .kml \n    https://dataportal.asia/ne/dataset/192501037_chas-clinics/resource/21dace06-c4d1-4128-9424-aba7668050dc \n  \n  \n    Geospatial \n    Bus Stop Locations Feb 2023 \n    .shp \n    https://datamall.lta.gov.sg/content/datamall/en/search_datasets.html?searchText=bus%20stop \n  \n  \n    Geospatial \n    Shopping Mall SVY21 Coordinates \n    .csv \n    https://github.com/ValaryLim/Mall-Coordinates-Web-Scraper \n  \n  \n    Geospatial - Selfsourced \n    MRT Locations Feb 2023 \n    .xlsx \n    https://www.lta.gov.sg/content/ltagov/en/getting_around/public_transport/rail_network.html \n  \n  \n    Geospatial - Selfsourced \n    Primary Schools \n    .xlsx \n    https://www.moe.gov.sg/about-us/organisation-structure/sd/school-clusters \n  \n\n\n\n\n\n\n3.2.1 Self Sourced Primary Schools\nFor the data on Primary Schools, I manually obtained the list of primary schools from the website in the above table.\nTo determine whether a primary school is good or not, I used schlah’s ranking which was calculated by assigning weights to the following:\n\nGifted Education Programme (GEP): 20%\nPopularity in Primary 1 (P1) Registration: 20%\nSpecial Assistance Plan (SAP): 15%\nSingapore Youth Festival Arts Presentation: 15%\nSingapore National School Games: 15%\nSingapore Uniformed Groups Unit Recognition: 15%\n\nI labelled the top 10 primary schools according to schlah’s ranking in the excel file with the list of all primary school names\n\n\n3.2.2 Self Sourced MRT & LRT locations\nFor the data on MRT & LRT, I manually obtained the list of MRT & LRT locations from the System Map (last updated 9 November 2022) from the website in the above table as well.\n\n\n\n\n\nI decided to pick out the names of the MRT & LRT stations instead of downloading the data from LTA mall as the data does not seem to be updated. There are a total of 171 stations in the MRT and LRT lines excluding Teck Lee of Punggol LRT as it is Not in Service. Only existing stations are included in the data. Future stations are not included."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-and-loading-r-packages",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#installing-and-loading-r-packages",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Prices using Geographically Weighted Methods",
    "section": "4.1 Installing and Loading R packages",
    "text": "4.1 Installing and Loading R packages\n\nsf: to import, manage, and process geospatial data\ntidyverse: a collection of packages (readr for importing delimited text file, tidyr for tidying data, dplyr for wrangling data)\ntmap: provides functions for plotting cartographic quality static point patterns maps or interactive maps\nreadxl: for importing Excel worksheets(.xlsx)\nplyr: for splitting data, applying functions and combining results\nkableExtra: for table customisation\nplotly for creating interactive web-based graphs\n\n\n\nShow the code!\npacman::p_load(sf, spdep, tmap, onemapsgapi, units, httr, rvest, sp, broom, matrixStats, readxl, jsonlite, olsrr, corrplot, ggpubr, GWmodel, devtools, kableExtra, plotly, ggthemes, tidyverse)\n\n\n\n\nShow the code!\n# reference for manipulating output messages: https://yihui.org/knitr/demo/output/\ndevtools::install_github(\"gadenbuie/xaringanExtra\")\nlibrary(xaringanExtra)\nxaringanExtra::use_panelset()"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wrangling-geospatial-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wrangling-geospatial-data",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Prices using Geographically Weighted Methods",
    "section": "4.3 Data Wrangling: Geospatial Data",
    "text": "4.3 Data Wrangling: Geospatial Data\n\n4.3.1 Importing the Geospatial Data\nUsing st_read() of sf to read simple features or layers from file, read_csv() to read csv and read_xlsx() for xlsx:\n\n\nShow the code!\nsg_sf <- st_read(dsn = \"data/geospatial/SingaporeNationalBoundary-shp\", layer=\"CostalOutline\")\n\n\nReading layer `CostalOutline' from data source \n  `C:\\valtyl\\IS415-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\SingaporeNationalBoundary-shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\nShow the code!\nmpsz_sf <- st_read(dsn = \"data/geospatial/master-plan-2014-subzone-boundary-web-shp\", layer = \"MP14_SUBZONE_WEB_PL\")\n\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\valtyl\\IS415-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\master-plan-2014-subzone-boundary-web-shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nShow the code!\nelder_sf <- st_read(\"data/geospatial/eldercare-services-shp\", layer=\"ELDERCARE\")\n\n\nReading layer `ELDERCARE' from data source \n  `C:\\valtyl\\IS415-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\eldercare-services-shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 133 features and 18 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 14481.92 ymin: 28218.43 xmax: 41665.14 ymax: 46804.9\nProjected CRS: SVY21\n\n\nShow the code!\nbusstop_sf <- st_read(\"data/geospatial/busstop-shp\", layer = \"BusStop\")\n\n\nReading layer `BusStop' from data source \n  `C:\\valtyl\\IS415-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\busstop-shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 5159 features and 3 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 3970.122 ymin: 26482.1 xmax: 48284.56 ymax: 52983.82\nProjected CRS: SVY21\n\n\nShow the code!\nchildcare_kindergarten_sf <- st_read(\"data/geospatial/preschools-kml/preschools-location.kml\")\n\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\valtyl\\IS415-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\preschools-kml\\preschools-location.kml' \n  using driver `KML'\nSimple feature collection with 1925 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nShow the code!\nchas_sf <- st_read(\"data/geospatial/chasclinics-kml/moh-chas-clinics.kml\")\n\n\nReading layer `MOH_CHAS_CLINICS' from data source \n  `C:\\valtyl\\IS415-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\chasclinics-kml\\moh-chas-clinics.kml' \n  using driver `KML'\nSimple feature collection with 1064 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.5818 ymin: 1.016264 xmax: 103.9903 ymax: 1.456037\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nShow the code!\nhawker_sf <- st_read(\"data/geospatial/hawker-centres-kml/hawker-centres-kml.kml\")\n\n\nReading layer `HAWKERCENTRE' from data source \n  `C:\\valtyl\\IS415-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\hawker-centres-kml\\hawker-centres-kml.kml' \n  using driver `KML'\nSimple feature collection with 125 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6974 ymin: 1.272716 xmax: 103.9882 ymax: 1.449217\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nShow the code!\npark_sf <- st_read(\"data/geospatial/parks-kml/nparks-parks-and-nature-reserves-kml.kml\")\n\n\nReading layer `NParks_Parks' from data source \n  `C:\\valtyl\\IS415-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\parks-kml\\nparks-parks-and-nature-reserves-kml.kml' \n  using driver `KML'\nSimple feature collection with 421 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XYZ\nBounding box:  xmin: 103.6925 ymin: 1.2115 xmax: 104.0544 ymax: 1.46419\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nShow the code!\nsupermarket_sf <- st_read(\"data/geospatial/supermarkets-kml/supermarkets-kml.kml\")\n\n\nReading layer `SUPERMARKETS' from data source \n  `C:\\valtyl\\IS415-GAA\\Take-home_Ex\\Take-home_Ex03\\data\\geospatial\\supermarkets-kml\\supermarkets-kml.kml' \n  using driver `KML'\nSimple feature collection with 526 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6258 ymin: 1.24715 xmax: 104.0036 ymax: 1.461526\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nShow the code!\nprisch_xlsx <- read_xlsx(\"data/geospatial/primary-schools-xlsx/primaryschools.xlsx\")\nmall_csv <- read_csv(\"data/geospatial/shopping-mall-csv/mall_coordinates_updated.csv\")\ntrainstation_xlsx <- read_xlsx(\"data/geospatial/trainstation-xlsx/trainstations.xlsx\")\n\n\nFrom the output above, we can see that some of the datasets (childcare_kindergarten_sf, chas_sf, hawker_sf, park_sf, supermarket_sf) are in WGS84 hence we will need to change them to SVY21 (EPSG Code 3414) later on. (section 4.3.3)\nAdditionally, these same datasets (childcare_kindergarten_sf, chas_sf, hawker_sf, park_sf, supermarket_sf) also have dimensions listed as ‘XYZ’. They all have a z-dimension has seen from z_range in the outputs where zmin and zmax are both 0. This z-dimension is irrelevant to our analysis and we will drop them with st_zm() in our pre-processing later. (section 4.3.2.1)\n\n4.3.1.1 Convert CSV to sf for Shopping Malls\nConverting the CSV to sf object using st_as_sf():\n\n\nShow the code!\nmall_sf <- st_as_sf(mall_csv, coords = c(\"longitude\", \"latitude\"), crs=4326)\n\n\n\n\n4.3.1.2 Retrieve Primary School postal code and coordinates\nAs I have manually obtained the list of the names of primary schools, we still need to retrieve the postal codes and coordinates of the primary schools to calculate the proximity.\nCreating a list to store the sorted unique primary school names using sort() and unique():\n\n\nShow the code!\nprisch_list <- sort(unique(prisch_xlsx$name))\n\n\nCalling get_coords function to retrieve primary school coordinates:\n\n\nShow the code!\nprisch_coords <- get_coords(prisch_list)\n\n\nChecking if there are NA or “NIL” values in postal, latitude and longitude columns using is.na() of base R:\n\n\nShow the code!\nprisch_coords[(is.na(prisch_coords$postal) | is.na(prisch_coords$latitude) | is.na(prisch_coords$longitude) | prisch_coords$postal==\"NIL\"), ]\n\n\n\n\n\n\n\nFrom the output, we can see 5 schools that did not manage to get their postal code, latitude and longitude successfully from OneMapSG API.\nLet’s fix this by manually searching Google Map / One Map and inputting the values:\n\n\nShow the code!\n# CHIJ Toa Payoh\nprisch_coords[28,]$postal <- \"319765\"\nprisch_coords[28,]$latitude <- \"1.33275263726147\"\nprisch_coords[28,]$longitude <- \"103.841847268953\"\n\n# St Anthony’s Canossian Primary School\nprisch_coords[140,]$postal <- \"469701\"\nprisch_coords[140,]$latitude <- \"1.3347253730189\"\nprisch_coords[140,]$longitude <- \"103.941234868202\"\n  \n# St Gabriel’s Primary School\nprisch_coords[141,]$postal <- \"556742\"\nprisch_coords[141,]$latitude <- \"1.34947192653862\"\nprisch_coords[141,]$longitude <- \"103.862561037707\"\n\n# St Stephen's Primary School\nprisch_coords[142,]$postal <- \"455789\"\nprisch_coords[142,]$latitude <- \"1.31878997295135\"\nprisch_coords[142,]$longitude <- \"103.917258129598\"\n  \n# St. Hilda’s Primary School\nprisch_coords[145,]$postal <- \"529706\"\nprisch_coords[145,]$latitude <- \"1.34938565036336\"\nprisch_coords[145,]$longitude <- \"103.937007133662\"\n\n\nChecking if the values have been changed:\n\n\nShow the code!\nprisch_coords[(is.na(prisch_coords$postal) | is.na(prisch_coords$latitude) | is.na(prisch_coords$longitude) | prisch_coords$postal==\"NIL\"), ]\n\n\n\n\n\n\n\nThere are no more rows with NA values hence the change is successful.\nCombining primary school and its coordinates data\n\n\nShow the code!\nprisch_df <- left_join(prisch_xlsx, prisch_coords, by=c('name' = 'address'))\n\n\nWriting primary school file to rds to prevent running too many GET requests:\n\n\nShow the code!\nprisch_rds <- write_rds(prisch_df, \"data/geospatial/primary-schools-xlsx/prisch_rds.rds\")\n\n\nReading prisch_rds RDS file:\n\n\nShow the code!\nprischs <- read_rds(\"data/geospatial/primary-schools-xlsx/prisch_rds.rds\")\n\n\nAssigning and Transforming CRS:\n\n\nShow the code!\nprisch_sf <- st_as_sf(prischs,\n                    coords = c(\"longitude\", \n                               \"latitude\"),\n                    crs=4326) %>%\n  st_transform(crs = 3414)\n\n\nNow we have proper primary school data in sf format with the coordinates!\n\n\n4.3.1.3 Retrieve MRT & LRT postal code and coordinates\nAs I have manually obtained the list of the names of MRT & LRT stations, we still need to retrieve the postal codes and coordinates of the stations to calculate the proximity.\nCreating a list to store the sorted unique MRT & LRT names using sort() and unique():\n\n\nShow the code!\nmrtlrt_list <- sort(unique(trainstation_xlsx$name))\n\n\nCalling get_coords function to retrieve MRT & LRT stations coordinates:\n\n\nShow the code!\nmrtlrt_coords <- get_coords(mrtlrt_list)\n\n\nChecking if there are NA or “NIL” values in postal, latitude and longitude columns using is.na() of base R:\n\n\nShow the code!\nmrtlrt_coords[(is.na(mrtlrt_coords$postal) | is.na(mrtlrt_coords$latitude) | is.na(mrtlrt_coords$longitude) | mrtlrt_coords$postal==\"NIL\"), ]\n\n\n\n\n\n\n\nThe output shows that KALLANG MRT STATION was not able to get its postal code and coordinates successfully from OneMap’s API.\nLet’s fix this by manually searching Google Map / One Map and inputting the values:\n\n\nShow the code!\nmrtlrt_coords[72,]$postal <- \"387405\"\nmrtlrt_coords[72,]$latitude <- \"1.31148890998818\"\nmrtlrt_coords[72,]$longitude <- \"103.871386541754\"\n\n\nChecking if the values have been changed:\n\n\nShow the code!\nmrtlrt_coords[(is.na(mrtlrt_coords$postal) | is.na(mrtlrt_coords$latitude) | is.na(mrtlrt_coords$longitude) | mrtlrt_coords$postal==\"NIL\"), ]\n\n\n\n\n\n\n\nThere are no more rows with NA values. This means that the postal code and coordinates have been updated.\nCombining train stations and its coordinates data\n\n\nShow the code!\ntrainstation_df <- left_join(trainstation_xlsx, mrtlrt_coords, by=c('name' = 'address'))\n\n\nWriting train stations file to rds to prevent running too many GET requests:\n\n\nShow the code!\ntrainstation_rds <- write_rds(trainstation_df, \"data/geospatial/trainstation-xlsx/trainstation_rds.rds\")\n\n\nReading trainstation_rds RDS file:\n\n\nShow the code!\ntrainstations <- read_rds(\"data/geospatial/trainstation-xlsx/trainstation_rds.rds\")\n\n\nAssigning and Transforming CRS:\n\n\nShow the code!\ntrainstation_sf <- st_as_sf(trainstations,\n                    coords = c(\"longitude\", \n                               \"latitude\"),\n                    crs=4326) %>%\n  st_transform(crs = 3414)\n\n\nNow we have proper MRT & LRT stations data in sf format with the coordinates!\n\n\n\n4.3.2 Data Pre-processing\nWe need to check and tweak the following: Remove Z-Dimension (for childcare_kindergarten_sf, chas_sf, hawker_sf, park_sf, supermarket_sf) Removing unnecessary columns Check for invalid geometries Check for missing values\n\n4.3.2.1 Remove Z-Dimensions\nDropping Z-Dimensions from the 5 datasets using st_zm():\n\n\nShow the code!\nchildcare_kindergarten_sf <- st_zm(childcare_kindergarten_sf)\nchas_sf <- st_zm(chas_sf)\nhawker_sf <- st_zm(hawker_sf)\npark_sf <- st_zm(park_sf)\nsupermarket_sf <- st_zm(supermarket_sf)\n\n\nDisplay to check if Z-Dimension has been dropped:\n\n\nShow the code!\nchildcare_kindergarten_sf\nchas_sf\nhawker_sf\npark_sf\nsupermarket_sf\n\n\nThe below screenshot of the first portion of the output shows that the dropping is successful. (A screenshot is used instead as the length of the output is very long)\n\n\n\n\n\n\n\n4.3.2.2 Remove unnecessary columns\nFor some of the locational factor dataframes, the only thing we need to know is the name of the facility and its geometry column, hence we only need to keep the name column using select():\n\n\nShow the code!\nelder_sf <- elder_sf %>% select(c(11))\nbusstop_sf <- busstop_sf %>% select(c(1))\ntrainstation_sf <- trainstation_sf %>% select(c(1))\n\nchildcare_kindergarten_sf <- childcare_kindergarten_sf %>% select(c(1))\nchas_sf <- chas_sf %>% select(c(1))\nhawker_sf <- hawker_sf %>% select(c(1))\npark_sf <- park_sf %>% select(c(1))\nsupermarket_sf <- supermarket_sf %>% select(c(1))\n\nprisch_sf <- prisch_sf %>% select(c(1,2))\nmall_sf <- mall_sf %>% select(c(2))\n\n\n\n\n4.3.2.3 Remove invalid geometries\nChecking for the number of geometries that are NOT valid:\n\n\nShow the code!\nlength(which(st_is_valid(sg_sf) == FALSE))\n\n\n[1] 1\n\n\nShow the code!\nlength(which(st_is_valid(mpsz_sf) == FALSE))\n\n\n[1] 9\n\n\nShow the code!\nlength(which(st_is_valid(elder_sf) == FALSE))\n\n\n[1] 0\n\n\nShow the code!\nlength(which(st_is_valid(busstop_sf) == FALSE))\n\n\n[1] 0\n\n\nShow the code!\nlength(which(st_is_valid(trainstation_sf) == FALSE))\n\n\n[1] 0\n\n\nShow the code!\nlength(which(st_is_valid(childcare_kindergarten_sf) == FALSE))\n\n\n[1] 0\n\n\nShow the code!\nlength(which(st_is_valid(chas_sf) == FALSE))\n\n\n[1] 0\n\n\nShow the code!\nlength(which(st_is_valid(hawker_sf) == FALSE))\n\n\n[1] 0\n\n\nShow the code!\nlength(which(st_is_valid(park_sf) == FALSE))\n\n\n[1] 2\n\n\nShow the code!\nlength(which(st_is_valid(supermarket_sf) == FALSE))\n\n\n[1] 0\n\n\nShow the code!\nlength(which(st_is_valid(prisch_sf) == FALSE))\n\n\n[1] 0\n\n\nShow the code!\nlength(which(st_is_valid(mall_sf) == FALSE))\n\n\n[1] 0\n\n\nFrom the output, we can see that sg_sf, mpsz_sf, park_sf have invalid geometries and we need to address them.\nAddressing and re-checking for invalid geometries:\n\n\nShow the code!\n# st_make_valid takes in an invalid geometry and outputs a valid one with the lwgeom_makevalid method\n\nsg_sf <- st_make_valid(sg_sf)\nlength(which(st_is_valid(sg_sf) == FALSE))\n\n\n[1] 0\n\n\nShow the code!\nmpsz_sf <- st_make_valid(mpsz_sf)\nlength(which(st_is_valid(mpsz_sf) == FALSE))\n\n\n[1] 0\n\n\nShow the code!\npark_sf <- st_make_valid(park_sf)\nlength(which(st_is_valid(park_sf) == FALSE))\n\n\n[1] 0\n\n\n\n\n4.3.2.4 Dealing with missing values\nBefore we move on to checking and transforming of CRS, let’s check if there are any missing values\n\n\nShow the code!\n# the rowSums(is.na(sg_sf))!=0 checks every row if there are NA values, returning TRUE or FALSE\n# the sg_sf [] 'wrapper' prints said rows that contain NA values\n\nsg_sf[rowSums(is.na(sg_sf))!=0,]\n\n\nSimple feature collection with 0 features and 4 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21\n[1] GDO_GID    MSLINK     MAPID      COSTAL_NAM geometry  \n<0 rows> (or 0-length row.names)\n\n\nShow the code!\nmpsz_sf[rowSums(is.na(mpsz_sf))!=0,]\n\n\nSimple feature collection with 0 features and 15 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21\n [1] OBJECTID   SUBZONE_NO SUBZONE_N  SUBZONE_C  CA_IND     PLN_AREA_N\n [7] PLN_AREA_C REGION_N   REGION_C   INC_CRC    FMEL_UPD_D X_ADDR    \n[13] Y_ADDR     SHAPE_Leng SHAPE_Area geometry  \n<0 rows> (or 0-length row.names)\n\n\nShow the code!\nelder_sf[rowSums(is.na(elder_sf))!=0,]\n\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21\n[1] NAME     geometry\n<0 rows> (or 0-length row.names)\n\n\nShow the code!\nbusstop_sf[rowSums(is.na(busstop_sf))!=0,]\n\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21\n[1] BUS_STOP_N geometry  \n<0 rows> (or 0-length row.names)\n\n\nShow the code!\ntrainstation_sf[rowSums(is.na(trainstation_sf))!=0,]\n\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 0 × 2\n# … with 2 variables: name <chr>, geometry <GEOMETRY [m]>\n\n\nShow the code!\nchildcare_kindergarten_sf[rowSums(is.na(childcare_kindergarten_sf))!=0,]\n\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nGeodetic CRS:  WGS 84\n[1] Name     geometry\n<0 rows> (or 0-length row.names)\n\n\nShow the code!\nchas_sf[rowSums(is.na(chas_sf))!=0,]\n\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nGeodetic CRS:  WGS 84\n[1] Name     geometry\n<0 rows> (or 0-length row.names)\n\n\nShow the code!\nhawker_sf[rowSums(is.na(hawker_sf))!=0,]\n\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nGeodetic CRS:  WGS 84\n[1] Name     geometry\n<0 rows> (or 0-length row.names)\n\n\nShow the code!\npark_sf[rowSums(is.na(park_sf))!=0,]\n\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nGeodetic CRS:  WGS 84\n[1] Name     geometry\n<0 rows> (or 0-length row.names)\n\n\nShow the code!\nsupermarket_sf[rowSums(is.na(supermarket_sf))!=0,]\n\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nGeodetic CRS:  WGS 84\n[1] Name     geometry\n<0 rows> (or 0-length row.names)\n\n\nShow the code!\nprisch_sf[rowSums(is.na(prisch_sf))!=0,]\n\n\nSimple feature collection with 0 features and 2 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 0 × 3\n# … with 3 variables: name <chr>, good <chr>, geometry <GEOMETRY [m]>\n\n\nShow the code!\nmall_sf[rowSums(is.na(mall_sf))!=0,]\n\n\nSimple feature collection with 0 features and 1 field\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nGeodetic CRS:  WGS 84\n# A tibble: 0 × 2\n# … with 2 variables: name <chr>, geometry <GEOMETRY [°]>\n\n\nSince we already removed unnecessary columns in the previous sub sections, we did not get a lot of NA values across our datasets. If we did not remove those columns, we would probably get quite a number of rows with NA values since the other columns could have had missing values.\nThe output shows that there are no missing values (output shows 0 features) in all our datasets hence we are good to proceed!\nOur geospatial data pre-processing is done! Time to move on to transformation of CRS\n\n\n\n4.3.3 Verify + Transform Coordinate System\nWhen we imported the data (section 4.3.1), we made a note to verify and transform the projected CRS.\nChecking CRS for all datasets:\n\n\nShow the code!\nst_crs(sg_sf)\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nShow the code!\nst_crs(mpsz_sf)\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nShow the code!\nst_crs(elder_sf)\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nShow the code!\nst_crs(busstop_sf)\n\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"WGS 84\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nShow the code!\nst_crs(trainstation_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nShow the code!\nst_crs(childcare_kindergarten_sf)\n\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nShow the code!\nst_crs(chas_sf)\n\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nShow the code!\nst_crs(hawker_sf)\n\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nShow the code!\nst_crs(park_sf)\n\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nShow the code!\nst_crs(supermarket_sf)\n\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\nShow the code!\nst_crs(prisch_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nShow the code!\nst_crs(mall_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:4326 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n        MEMBER[\"World Geodetic System 1984 (Transit)\"],\n        MEMBER[\"World Geodetic System 1984 (G730)\"],\n        MEMBER[\"World Geodetic System 1984 (G873)\"],\n        MEMBER[\"World Geodetic System 1984 (G1150)\"],\n        MEMBER[\"World Geodetic System 1984 (G1674)\"],\n        MEMBER[\"World Geodetic System 1984 (G1762)\"],\n        MEMBER[\"World Geodetic System 1984 (G2139)\"],\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]],\n        ENSEMBLEACCURACY[2.0]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"geodetic latitude (Lat)\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"geodetic longitude (Lon)\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    USAGE[\n        SCOPE[\"Horizontal component of 3D system.\"],\n        AREA[\"World.\"],\n        BBOX[-90,-180,90,180]],\n    ID[\"EPSG\",4326]]\n\n\nFrom the output, it does not show the projected CRS and ESPG code that we want. We want projected CRS to be SVY21 and ESPG code to be 3414. However, some of the data shows projected CRS to be SVY21 but ESPG code to be 9001. Additionally, other data are in WGS84 and its ESPG code are 4326. We need to make the appropriate modifications.\nAssigning the correct ESPG code:\n\n\nShow the code!\n# with st_set_crs(), we can assign the appropriate ESPG Code\nsg_sf <- st_set_crs(sg_sf, 3414)\nmpsz_sf <- st_set_crs(mpsz_sf, 3414)\nelder_sf <- st_set_crs(elder_sf, 3414)\nbusstop_sf <- st_set_crs(busstop_sf, 3414)\n\n# with st_transform(), we can change from one CRS to another\nchildcare_kindergarten_sf <- st_transform(childcare_kindergarten_sf, crs=3414)\nchas_sf <- st_transform(chas_sf, crs=3414)\nhawker_sf <- st_transform(hawker_sf, crs=3414)\npark_sf <- st_transform(park_sf, crs=3414)\nsupermarket_sf <- st_transform(supermarket_sf, crs=3414)\nmall_sf <- st_transform(mall_sf, crs=3414)\n\n# trainstation_sf and prisch_sf are in the correct CRS and ESPG code\n\n\nRe-checking if the transformation is successful:\n\n\nShow the code!\nst_crs(sg_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nShow the code!\nst_crs(mpsz_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nShow the code!\nst_crs(elder_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nShow the code!\nst_crs(busstop_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nShow the code!\nst_crs(trainstation_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nShow the code!\nst_crs(childcare_kindergarten_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nShow the code!\nst_crs(chas_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nShow the code!\nst_crs(hawker_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nShow the code!\nst_crs(park_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nShow the code!\nst_crs(supermarket_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nShow the code!\nst_crs(prisch_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nShow the code!\nst_crs(mall_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nFrom the output, it shows that all the transformation have been done successfully."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wrangling-aspatial-data",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-wrangling-aspatial-data",
    "title": "Take-home Exercise 3: Predicting HDB Public Housing Resale Prices using Geographically Weighted Methods",
    "section": "4.2 Data Wrangling: Aspatial Data",
    "text": "4.2 Data Wrangling: Aspatial Data\n\n4.2.1 Importing the Aspatial Data\nImporting resale flat prices using read_csv() of readr:\n\n\nShow the code!\nresale <- read_csv(\"data/aspatial/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv\")\n\n\nDisplaying the data structure using glimpse() of dplyr:\n\n\nShow the code!\nglimpse(resale)\n\n\nRows: 148,098\nColumns: 11\n$ month               <chr> \"2017-01\", \"2017-01\", \"2017-01\", \"2017-01\", \"2017-…\n$ town                <chr> \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO …\n$ flat_type           <chr> \"2 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", \"3 ROOM\", …\n$ block               <chr> \"406\", \"108\", \"602\", \"465\", \"601\", \"150\", \"447\", \"…\n$ street_name         <chr> \"ANG MO KIO AVE 10\", \"ANG MO KIO AVE 4\", \"ANG MO K…\n$ storey_range        <chr> \"10 TO 12\", \"01 TO 03\", \"01 TO 03\", \"04 TO 06\", \"0…\n$ floor_area_sqm      <dbl> 44, 67, 67, 68, 67, 68, 68, 67, 68, 67, 68, 67, 67…\n$ flat_model          <chr> \"Improved\", \"New Generation\", \"New Generation\", \"N…\n$ lease_commence_date <dbl> 1979, 1978, 1980, 1980, 1980, 1981, 1979, 1976, 19…\n$ remaining_lease     <chr> \"61 years 04 months\", \"60 years 07 months\", \"62 ye…\n$ resale_price        <dbl> 232000, 250000, 262000, 265000, 265000, 275000, 28…\n\n\nThe HDB Resale Flat Prices data set contains the following Structural factors that we would like to explore further:\n\nArea of the unit (floor_area_sqm)\nFloor level (storey_range)\nRemaining lease (remaining_lease)\n\nAnother structural factor we can consider is ‘Age of the unit’ which can be calculated using the year now minus lease_commence_date\nUsing the attributes street_name and block, we would have to get the coordinates of the HDB flats later on.\n\n\n4.2.2 Filter resale data\nFor this study we are only interested in 4 room flats from 1st January 2021 to 31st December 2022 hence we will need to filter the data.\nFiltering flat_type and month of the data using filter() of dplyr:\n\n\nShow the code!\nrs_subset <-  filter(resale, flat_type == \"4 ROOM\") %>% \n              filter(month >= \"2021-01\" & month <= \"2022-12\")\n\n\nDisplaying the filtered resale data:\n\n\nShow the code!\nglimpse(rs_subset)\n\n\nRows: 23,657\nColumns: 11\n$ month               <chr> \"2021-01\", \"2021-01\", \"2021-01\", \"2021-01\", \"2021-…\n$ town                <chr> \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO …\n$ flat_type           <chr> \"4 ROOM\", \"4 ROOM\", \"4 ROOM\", \"4 ROOM\", \"4 ROOM\", …\n$ block               <chr> \"547\", \"414\", \"509\", \"467\", \"571\", \"134\", \"204\", \"…\n$ street_name         <chr> \"ANG MO KIO AVE 10\", \"ANG MO KIO AVE 10\", \"ANG MO …\n$ storey_range        <chr> \"04 TO 06\", \"01 TO 03\", \"01 TO 03\", \"07 TO 09\", \"0…\n$ floor_area_sqm      <dbl> 92, 92, 91, 92, 92, 98, 92, 92, 92, 92, 92, 109, 9…\n$ flat_model          <chr> \"New Generation\", \"New Generation\", \"New Generatio…\n$ lease_commence_date <dbl> 1981, 1979, 1980, 1979, 1979, 1978, 1977, 1978, 19…\n$ remaining_lease     <chr> \"59 years\", \"57 years 09 months\", \"58 years 06 mon…\n$ resale_price        <dbl> 370000, 375000, 380000, 385000, 410000, 410000, 41…\n\n\nThe output shows that there are 23657 transactions for 4 room flats in Singapore from January 2021 to December 2022.\nChecking if flat_type and month have been extracted successfully using unique() of base R:\n\n\nShow the code!\nunique(rs_subset$month)\n\n\n [1] \"2021-01\" \"2021-02\" \"2021-03\" \"2021-04\" \"2021-05\" \"2021-06\" \"2021-07\"\n [8] \"2021-08\" \"2021-09\" \"2021-10\" \"2021-11\" \"2021-12\" \"2022-01\" \"2022-02\"\n[15] \"2022-03\" \"2022-04\" \"2022-05\" \"2022-06\" \"2022-07\" \"2022-08\" \"2022-09\"\n[22] \"2022-10\" \"2022-11\" \"2022-12\"\n\n\n\n\nShow the code!\nunique(rs_subset$flat_type)\n\n\n[1] \"4 ROOM\"\n\n\nThe output shows that we have correctly extracted month and flat_type.\n\n\n4.2.3 Transform resale data\n\n4.2.3.1 Create new columns\nIn this section, we would like to transform the data by creating the following columns:\n\naddress: concatenation of block and street_name using paste() of base R\nremaining_lease_yr & remaining_lease_mth: split remaining_lease into years and months using str_sub() of stringr, then convert character to integer using as.integer() of base R\n\nTransforming the date using mutate() of dplyr:\n\n\nShow the code!\nrs_transform <- rs_subset %>%\n  mutate(rs_subset, address = paste(block,street_name)) %>%\n  mutate(rs_subset, remaining_lease_yr = as.integer(str_sub(remaining_lease, 0, 2))) %>%\n  mutate(rs_subset, remaining_lease_mth = as.integer(str_sub(remaining_lease, 9, 11)))\n\n\nDisplaying the head of the transformed data:\n\n\nShow the code!\nhead(rs_transform)\n\n\n# A tibble: 6 × 14\n  month   town     flat_…¹ block stree…² store…³ floor…⁴ flat_…⁵ lease…⁶ remai…⁷\n  <chr>   <chr>    <chr>   <chr> <chr>   <chr>     <dbl> <chr>     <dbl> <chr>  \n1 2021-01 ANG MO … 4 ROOM  547   ANG MO… 04 TO …      92 New Ge…    1981 59 yea…\n2 2021-01 ANG MO … 4 ROOM  414   ANG MO… 01 TO …      92 New Ge…    1979 57 yea…\n3 2021-01 ANG MO … 4 ROOM  509   ANG MO… 01 TO …      91 New Ge…    1980 58 yea…\n4 2021-01 ANG MO … 4 ROOM  467   ANG MO… 07 TO …      92 New Ge…    1979 57 yea…\n5 2021-01 ANG MO … 4 ROOM  571   ANG MO… 07 TO …      92 New Ge…    1979 57 yea…\n6 2021-01 ANG MO … 4 ROOM  134   ANG MO… 07 TO …      98 New Ge…    1978 56 yea…\n# … with 4 more variables: resale_price <dbl>, address <chr>,\n#   remaining_lease_yr <int>, remaining_lease_mth <int>, and abbreviated\n#   variable names ¹​flat_type, ²​street_name, ³​storey_range, ⁴​floor_area_sqm,\n#   ⁵​flat_model, ⁶​lease_commence_date, ⁷​remaining_lease\n\n\n\n\n4.2.3.2 Sum up remaining lease in months\nFor the new remaining_lease_mth column, there are NA values for flats that only have years in their remaining_lease hence we will need to convert the NA values to 0 using is.na() of base R:\n\n\nShow the code!\nrs_transform$remaining_lease_mth[is.na(rs_transform$remaining_lease_mth)] <- 0\n\n\nTo make things easier, we can convert remaining_lease_yr into months then combine its value with remaining_lease_mth so that we will have 1 remaining_lease column in units of months:\n\n\nShow the code!\nrs_transform$remaining_lease_yr <- rs_transform$remaining_lease_yr * 12\n\nrs_transform <- rs_transform %>% \n  mutate(rs_transform, remaining_lease_mths = rowSums(rs_transform[, c(\"remaining_lease_yr\", \"remaining_lease_mth\")]))\n\n\nAfter, we will retain only the columns that we want:\n\n\nShow the code!\nrs_transform <- rs_transform %>% select(month, town, address, block, street_name, flat_type, storey_range, floor_area_sqm, flat_model, lease_commence_date, remaining_lease_mths, resale_price)\n\n\n\n\n\n4.2.4 Retrieve Postal Codes and Coordinates of Addresses\nWe will need to retrieve postal codes and coordinates of the addresses as these are required to calculate the proximity to the locational factors.\n\n4.2.4.1 Create a list storing unique addresses\nCreating a list to store sorted unique addresses using unique() and sort() of base R to ensure that we do not run the GET request more than what is necessary:\n\n\nShow the code!\nadd_list <- sort(unique(rs_transform$address))\n\n\n\n\n4.2.4.2 Create a function to retrieve the coordinates from OneMap.sg API\nBelow are the steps to creating the function:\n\nFirstly, create a dataframe to store all the final retrieved coordinates.\nSecondly, use GET() function of httr to make a GET request using OneMap’s search function.\n\nOneMap’s search function allows us to query spatial data using the API in a tidy format and provides us additional functionalities for easy manipulation of data.\nWe will use the REST API to retrieve the coordinates of the locations we want.\nThe GET request requires the following variables:\n\nsearchVal: keywords entered by the user to search for the results\nreturnGeom{Y/N}: Y if user wants to return the geometry\ngetAddrDetails{Y/N}: Y if user wants to return address details for the location\nThe returned JSON response will contain multiple fields but we are only interested in Postal Code, Longitude and Latitude\n\n\nThirdly, create a dataframe to store each final set of coordinates retrieved during the loop\nFourthly, check the number of responses returned and append to the main dataframe accordingly as some locations may return multiple results (the search value could be too generic) and some locations may return no results (addresses could be invalid)\nLastly, append the returned response with the necessary fields to the main dataframe using rbind() of base R\n\n\n\nShow the code!\nget_coords <- function(add_list){\n  \n  # Create a data frame to store all retrieved coordinates\n  postal_coords <- data.frame()\n  \n  # loop to go through each address in the list  \n  for (i in add_list){\n    #print(i)\n    \n    # response from OneMap API\n    r <- GET('https://developers.onemap.sg/commonapi/search?',\n           query=list(searchVal=i,\n                     returnGeom='Y',\n                     getAddrDetails='Y'))\n    data <- fromJSON(rawToChar(r$content))\n    found <- data$found\n    res <- data$results\n    \n    # Create a new data frame for each address\n    new_row <- data.frame()\n    \n    # If single result, append \n    if (found == 1){\n      postal <- res$POSTAL \n      lat <- res$LATITUDE\n      lng <- res$LONGITUDE\n      new_row <- data.frame(address= i, postal = postal, latitude = lat, longitude = lng)\n    }\n    \n    # If multiple results, drop NIL and append top 1\n    else if (found > 1){\n      # Remove those with NIL as postal\n      res_sub <- res[res$POSTAL != \"NIL\", ]\n      \n      # Set as NA first if no Postal\n      if (nrow(res_sub) == 0) {\n          new_row <- data.frame(address= i, postal = NA, latitude = NA, longitude = NA)\n      }\n      \n      else{\n        top1 <- head(res_sub, n = 1)\n        postal <- top1$POSTAL \n        lat <- top1$LATITUDE\n        lng <- top1$LONGITUDE\n        new_row <- data.frame(address= i, postal = postal, latitude = lat, longitude = lng)\n      }\n    }\n\n    else {\n      new_row <- data.frame(address= i, postal = NA, latitude = NA, longitude = NA)\n    }\n    \n    # Add the row to the main dataframe\n    postal_coords <- rbind(postal_coords, new_row)\n  }\n  return(postal_coords)\n}\n\n\n\n\n4.2.4.3 Call get_coords function to retrieve resale coordinates\n\n\nShow the code!\ncoords <- get_coords(add_list)\n\n\nNote: The above code and the following code till saving the coordinates in a RDS file will not be evaluated. Image outputs are used instead to prevent too many GET requests from being run repeatedly so that the browser does not take too long to render.\n\n\n4.2.4.4 Inspect the results\nChecking if there are NA or “NIL” values in postal, latitude and longitude columns using is.na() of base R\n\n\nShow the code!\ncoords[(is.na(coords$postal) | is.na(coords$latitude) | is.na(coords$longitude) | coords$postal==\"NIL\"), ]\n\n\n\n\n\n\n\nFrom the output, we can see that 215 CHOA CHU KANG CTRL has “NIL” for its postal code. This means that the postal code cannot be found on OneMap.\nGoing to the OneMap API itself, we can see that searching 215 CHOA CHU KANG CTRL gives the following output: {“found”:1,“totalNumPages”:1,“pageNum”:1,“results”:[{“SEARCHVAL”: “BLK 216 AND 215 CHOA CHU KANG CENTRAL”, “BLK_NO”: ““,”ROAD_NAME”: “NIL”, “BUILDING”: “BLK 216 AND 215 CHOA CHU KANG CENTRAL”, “ADDRESS”: “BLK 216 AND 215 CHOA CHU KANG CENTRAL”, “POSTAL”:“NIL”, “X”: “18402.3645474631”, “Y”: “40559.9837618358”, “LATITUDE”: “1.38308302434129”, “LONGITUDE”: “103.747076627693”, “LONGTITUDE”: “103.747076627693”}]}\nThis means that searching 215 CHOA CHU KANG CTRL gives the result BLK 216 AND 215 CHOA CHU KANG CENTRAL and “POSTAL” of “NIL”.\nFurther research on Google shows that its postal code should be ‘680215’.\nChanging the “NIL” value to 680215:\n\n\nShow the code!\ncoords[1305,]$postal <- \"680215\"\n\n\nChecking if the value has been changed:\n\n\nShow the code!\ncoords[(is.na(coords$postal) | is.na(coords$latitude) | is.na(coords$longitude) | coords$postal==\"NIL\"), ]\n\n\n\n\n\n\n\nThere are no more rows with “NIL” values for postal code.\n\n\n4.2.4.5 Combine resale and coordinates data\nCombining the retrieved coordinates with the transformed resale data using left_join() of dplyr:\n\n\nShow the code!\nrs_coords <- left_join(rs_transform, coords, by = c('address' = 'address'))\n\n\n\n\n\n4.2.5 Write file to rds\nWe should save the resale dataset as an rds file since we have obtained the coordinates so that we do not have to repeatedly run the GET request\n\n\nShow the code!\nrs_coords_rds <- write_rds(rs_coords, \"data/aspatial/rs_coords.rds\")\n\n\n\n\n4.2.6 Read rs_coords RDS file\n\n\nShow the code!\nrs_coords <- read_rds(\"data/aspatial/rs_coords.rds\")\n\n\nDisplaying the RDS file:\n\n\nShow the code!\nglimpse(rs_coords)\n\n\nRows: 23,657\nColumns: 15\n$ month                <chr> \"2021-01\", \"2021-01\", \"2021-01\", \"2021-01\", \"2021…\n$ town                 <chr> \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO KIO\", \"ANG MO…\n$ address              <chr> \"547 ANG MO KIO AVE 10\", \"414 ANG MO KIO AVE 10\",…\n$ block                <chr> \"547\", \"414\", \"509\", \"467\", \"571\", \"134\", \"204\", …\n$ street_name          <chr> \"ANG MO KIO AVE 10\", \"ANG MO KIO AVE 10\", \"ANG MO…\n$ flat_type            <chr> \"4 ROOM\", \"4 ROOM\", \"4 ROOM\", \"4 ROOM\", \"4 ROOM\",…\n$ storey_range         <chr> \"04 TO 06\", \"01 TO 03\", \"01 TO 03\", \"07 TO 09\", \"…\n$ floor_area_sqm       <dbl> 92, 92, 91, 92, 92, 98, 92, 92, 92, 92, 92, 109, …\n$ flat_model           <chr> \"New Generation\", \"New Generation\", \"New Generati…\n$ lease_commence_date  <dbl> 1981, 1979, 1980, 1979, 1979, 1978, 1977, 1978, 1…\n$ remaining_lease_mths <dbl> 708, 693, 702, 695, 689, 681, 661, 682, 692, 692,…\n$ resale_price         <dbl> 370000, 375000, 380000, 385000, 410000, 410000, 4…\n$ postal               <chr> \"560547\", \"560414\", \"560509\", \"560467\", \"560571\",…\n$ latitude             <chr> \"1.37420951743562\", \"1.36390466431674\", \"1.374000…\n$ longitude            <chr> \"103.858209667888\", \"103.853913839503\", \"103.8501…\n\n\n\n4.2.6.1 Assign and Transform CRS\nSince the coordinates are Latitude and Longitude which are in decimal degrees, the projected CRS will be WGS84.\nTo transform to the EPSG code for SVY21, which is 3414, we need to assign them to EPSG code 4236 first.\nUsing st_as_sf() of sf to convert data frame into sf object and st_transform() of sf to transform the coordinates of the sf object:\n\n\nShow the code!\nrs_coords_sf <- st_as_sf(rs_coords,\n                    coords = c(\"longitude\", \n                               \"latitude\"),\n                    crs=4326) %>%\n  st_transform(crs = 3414)\n\n\nChecking the CRS of the sf object:\n\n\nShow the code!\nst_crs(rs_coords_sf)\n\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nThe output shows that the transformation is successful.\n\n\n4.2.6.2 Check for invalid geometries\nChecking using st_is_valid() of sf:\n\n\nShow the code!\nlength(which(st_is_valid(rs_coords_sf) == FALSE))\n\n\n[1] 0\n\n\nThere are no invalid geometries\n\n\n4.2.6.3 Check for missing values\n\n\nShow the code!\nrs_coords_sf[rowSums(is.na(rs_coords_sf))!=0,]\n\n\nSimple feature collection with 0 features and 13 fields\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 0 × 14\n# … with 14 variables: month <chr>, town <chr>, address <chr>, block <chr>,\n#   street_name <chr>, flat_type <chr>, storey_range <chr>,\n#   floor_area_sqm <dbl>, flat_model <chr>, lease_commence_date <dbl>,\n#   remaining_lease_mths <dbl>, resale_price <dbl>, postal <chr>,\n#   geometry <GEOMETRY [m]>\n\n\nThere are no missing values.\n\n\n4.2.6.4 Plot HDB resale points\nPlotting the HDB resale locations:\n\n\nShow the code!\ntmap_mode(\"view\")\ntm_shape(rs_coords_sf)+\n  tm_dots(col=\"blue\", size = 0.02) +\n  tm_view(set.zoom.limits = c(10,16))\n\n\n\n\n\n\n\nShow the code!\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#install-and-load-r-packages",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#install-and-load-r-packages",
    "title": "In-class Exercise 9: Geospatial Predictive",
    "section": "3.1 Install and load R packages",
    "text": "3.1 Install and load R packages\n\npacman::p_load(sf, spdep, GWmodel, SpatialML, rsample, tidyverse, #this line of packages is enough for model calibration\n               tmap, ggpubr, olsrr, devtools, tidymodels)\n\npackage 'tidymodels' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n    C:\\Users\\User\\AppData\\Local\\Temp\\Rtmp40AtBW\\downloaded_packages\n\n\n\nGWmodel: calibrate geographical models\nSpatialML: calibrate spatial random forest tidyverse: manipulate dataframes\nggpubr: stitch multiple graphs together\nolsrr: used for model diagnostic purposes eg computing VIF and checking multi-collinearity\ndevtools: import packages that are not in CRAN\ntidymodels: advanced way to create ml modelling workflow"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#preparing-data",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#preparing-data",
    "title": "In-class Exercise 9: Geospatial Predictive",
    "section": "3.2 Preparing data",
    "text": "3.2 Preparing data\n\n3.2.1 Reading data file to rds\nReading the data file. It is in simple feature data frame.\n\nmdata <- read_rds(\"data/aspatial/mdata.rds\")\n\n\n\n3.2.2 Data Sampling\nThe entire data are split into training and test data of 65% and 35% respectively.\n\nset.seed(1234)\nresale_split <- initial_split(mdata,\n                              prop = 6.5/10)\ntrain_data <- training(resale_split)\ntest_data <- testing(resale_split)\n\nWrite the result out so that we don’t have to keep running the randomization step again\n\nwrite_rds(train_data, \"data/model/train_data.rds\")\nwrite_rds(test_data, \"data/model/test_data.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#computing-correlation-matrix",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#computing-correlation-matrix",
    "title": "In-class Exercise 9: Geospatial Predictive",
    "section": "3.3 Computing Correlation Matrix",
    "text": "3.3 Computing Correlation Matrix\n\nmdata_nogeo <- mdata %>%\n  st_drop_geometry()\ncorrplot::corrplot(cor(mdata_nogeo[, 2:17]),\n                   diag = FALSE,\n                   )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#retrieving-the-stored-data",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#retrieving-the-stored-data",
    "title": "In-class Exercise 9: Geospatial Predictive",
    "section": "3.4 Retrieving the Stored Data",
    "text": "3.4 Retrieving the Stored Data\n\ntrain_data <- read_rds(\"data/model/train_data.rds\")\ntest_data <- read_rds(\"data/model/test_data.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#building-a-non-spatial-multiple-linear-regression",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#building-a-non-spatial-multiple-linear-regression",
    "title": "In-class Exercise 9: Geospatial Predictive",
    "section": "3.5 Building a non-spatial multiple linear regression",
    "text": "3.5 Building a non-spatial multiple linear regression\n\nprice_mlr <- lm(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n                data = train_data)\nsummary(price_mlr)\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + \n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + \n    PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(>|t|)    \n(Intercept)              107601.073  10601.261  10.150  < 2e-16 ***\nfloor_area_sqm             2780.698     90.579  30.699  < 2e-16 ***\nstorey_order              14299.298    339.115  42.167  < 2e-16 ***\nremaining_lease_mths        344.490      4.592  75.027  < 2e-16 ***\nPROX_CBD                 -16930.196    201.254 -84.124  < 2e-16 ***\nPROX_ELDERLYCARE         -14441.025    994.867 -14.516  < 2e-16 ***\nPROX_HAWKER              -19265.648   1273.597 -15.127  < 2e-16 ***\nPROX_MRT                 -32564.272   1744.232 -18.670  < 2e-16 ***\nPROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\nPROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\nPROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\nWITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  < 2e-16 ***\nWITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  < 2e-16 ***\nWITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\nWITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61650 on 10320 degrees of freedom\nMultiple R-squared:  0.7373,    Adjusted R-squared:  0.737 \nF-statistic:  2069 on 14 and 10320 DF,  p-value: < 2.2e-16\n\n\nFor predictive model, we need to load the training data. Statistics obtained is not important for predictive model.\nResidual standard error from above output ^ is not the same as OOB prediction error (MSE) in section 3.8 to make it the same, need to manually square root OOB prediction error (MSE)\nwe can compare Residual standard error from above output ^ and R squared (OOB) in section 3.8 to see which model does better. Section 3.8 has a bigger value hence random forest model does better. But this way of comparing is not as accurate as comparing with the manually square rooted value of OOB prediction error (MSE) from section 3.8\n\nwrite_rds(price_mlr, \"data/model/price_mlr.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#gwr-predictive-method",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#gwr-predictive-method",
    "title": "In-class Exercise 9: Geospatial Predictive",
    "section": "3.6 GWR predictive method",
    "text": "3.6 GWR predictive method\n\n3.6.1 Converting the sf data.frame to SpatialPointDataFrame\n\ntrain_data_sp <- as_Spatial(train_data)\ntrain_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 10335 \nextent      : 11597.31, 42623.63, 28217.39, 48741.06  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,          PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       218000,             74,            1,                  555, 0.999393538715878, 1.98943787433087e-08, 0.0333358643817954, 0.0220407324774434, 0.0441643212802781, 0.0652540365486641,                0, 6.20621206270077e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1186888,            133,           17,                 1164,  19.6500691667807,     3.30163731686804,   2.86763031236184,   2.13060636038504,   2.41313695915468,   10.6223726149914, 2.27100643784442,    0.808332738794272,     1.57131703651196,                        7,                    20, ... \n\n\n\n\n3.6.2 Computing adaptive bandwidth\n\nbw_adaptive <- bw.gwr(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n                data = train_data_sp,\n                approach = \"CV\",\n                kernel=\"gaussian\", \n                adaptive=FALSE, \n                longlat=FALSE)\n\n\n\n3.6.3 Constructing the adaptive"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#preparing-coordinates-data",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#preparing-coordinates-data",
    "title": "In-class Exercise 9: Geospatial Predictive",
    "section": "3.7 Preparing coordinates data",
    "text": "3.7 Preparing coordinates data\n\n3.7.1 Extracting coordinates data\nextract coordinates data from simple feature file and put into a vector table for ranger (ranger does not accept simple feature format so need to change train and test data)\n\ncoords <- st_coordinates(mdata)\ncoords_train <- st_coordinates(train_data)\ncoords_test <- st_coordinates(test_data)\n\n\ncoords_train <- write_rds(coords_train, \"data/model/coords_train.rds\")\ncoords_test <- write_rds(coords_test, \"data/model/coords_test.rds\")\n\n\ncoords_train <- read_rds(\"data/model/coords_train.rds\")\ncoords_test <- read_rds(\"data/model/coords_test.rds\")\n\n\n\n3.7.2 Dropping geometry field\n\ntrain_data <- train_data %>%\n  st_drop_geometry()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#calibrating-random-forest",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#calibrating-random-forest",
    "title": "In-class Exercise 9: Geospatial Predictive",
    "section": "3.8 Calibrating Random Forest",
    "text": "3.8 Calibrating Random Forest\n\nset.seed(1234)\nrf <- ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n                data = train_data)\n\nThis random forest is the base ranger. We can calibrate many different kinds of model\n\nprint(rf)\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       728602496 \nR squared (OOB):                  0.9495728"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#calibrating-geographically-weighted-random-forest-model",
    "href": "In-class_Ex/In-class_Ex09/In-class_Ex09.html#calibrating-geographically-weighted-random-forest-model",
    "title": "In-class Exercise 9: Geospatial Predictive",
    "section": "3.9 Calibrating Geographically Weighted Random Forest Model",
    "text": "3.9 Calibrating Geographically Weighted Random Forest Model\n\n3.9.1 Calibrating using training data\n\nset.seed(1234)\ngwRF_adaptive <- grf(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,\n                dframe = train_data,\n                bw = 55, #bandwidth\n                kernel = \"adaptive\", #meaning 55 nearest transactions\n                coords = coords_train)\n\n\ntrain_data is a dataframe without coordinates, hence we need to tell what are the coordinates (which is coords_train)\nif we use adaptive kernel, then bandwidth is the number of observations/neighbours (eg. closest 55 neighbours, closes 55 transaction points)\nif we use fixed bandwidth, then bandwidth is the distance\nlook at grf() of SpatialML documentation\nhow to determine the bandwidth?\n\nborrow bandwidth from GWR method\nuse grf.bw() to calculate the best bandwidth to work with (see in class ex 8)\n\n\nThe Report (output) has 2 parts:\n\nusing as explanatory variable - Mean squared error (OOB) and 3 lines after\nusing as predictive model - Mean squared error Predicted (OOB) and 3 lines after (AICc and AIC would be v close if there is no biasness in terms of the sampling)\n\nSaving the model output:\n\nwrite_rds(gwRF_adaptive, \"data/model/gwRF_adaptive.rds\")\n\n\ngwRF_adaptive <- read_rds(\"data/model/gwRF_adaptive.rds\")\n\ninside gwRF_adaptive: gwRF_adaptive$Global.Model, gwRF_adpative$Global.Model$variable.importance (use this to find out which predictor contributes the most) (make it into a dataframe so we can use it: vi_df <- as.data.frame(gwRF_adaptive$Global.Model$variable.importance))\n\nvi_df <- as.data.frame(gwRF_adaptive$Global.Model$variable.importance)\nvi_df\n\n^ takes awhile to run\n\n\n\n\n\nPredicting using test data\n\nPreparing the test data\ncombine test data with its corresponding coordinates data. coords_test contains x and y so will add 2 more variables. st_drop_geometry will drop geometry column. thus 18 variables + 2 - 1 = 19 variables\n\ntest_data <- cbind(test_data, coords_test) %>%\n  st_drop_geometry()\n\n\n\nPredicting with test data\n\ngwRF_pred <- predict.grf(gwRF_adaptive,\n                         test_data,\n                         x.var.name = \"X\", # x coordinate\n                         y.var.name = \"Y\", # y coordinate\n                         local.w=1,\n                         global.w=0)\n\n^ takes awhile to run coordinates must be projected coordinates system (SVY21), decimal degree coodinates will not work. local.w = 1 means that we want it to calibrate the local version of the model the output is a VECTOR\n\n\nConverting the predicting output into a dataframe\nconvert the vector into a dataframe so that the dataframe can be combined with the original test data so that we can do further analysis like plotting predicted value and actual value to see how well they fit together\n\ngwRF_pred_df <- as.data.frame(gwRF_pred)\n\n\ngwRF_test_predict <- cbind(test_data, predict_grf_df)\n\n\nwrite_rds(test_predict, \"data/model/test_predict.rds\")\n\n\nggplot(data = test_predict,\n       aes(x = predict_grf,\n           y = resale_price)) +\n  geom_point()\n\n\nsqrt(mean((test_predict$resale_price - test_predict$predict_grf)^2))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex09/data/geospatial/MPSZ-2019.html",
    "href": "In-class_Ex/In-class_Ex09/data/geospatial/MPSZ-2019.html",
    "title": "IS415-GAA",
    "section": "",
    "text": "<!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’>     dataset\n\n\n        0 0     false"
  }
]